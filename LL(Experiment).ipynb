{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LL(Experiment).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPd9M5ihIIx6KvP54q04KEQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d964ed66d1a7400ab7ab186f8aaed938": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bbf83f01e2a646ca931d1b9e058e07b7",
              "IPY_MODEL_2a9ab2e8444e405092291f672d8f05d7",
              "IPY_MODEL_233e3ee87558499aaacfb0b3c15e5385"
            ],
            "layout": "IPY_MODEL_b4482525e66743138ae4e0b0ae9153b8"
          }
        },
        "bbf83f01e2a646ca931d1b9e058e07b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56685e6c0c2144c5b9df831554ceea15",
            "placeholder": "​",
            "style": "IPY_MODEL_658c914e5d154eecbb88e7945d531d58",
            "value": ""
          }
        },
        "2a9ab2e8444e405092291f672d8f05d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_611fd37c32934c9aabdeacb816431f57",
            "max": 182040794,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_61878bdb275b41548f23a87c0f0afdcc",
            "value": 182040794
          }
        },
        "233e3ee87558499aaacfb0b3c15e5385": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ce2729f61c74cea81b09b3080d0fb66",
            "placeholder": "​",
            "style": "IPY_MODEL_1cc64d03afb54abc9b36d1b9e5989eb8",
            "value": " 182041600/? [00:15&lt;00:00, 16212272.93it/s]"
          }
        },
        "b4482525e66743138ae4e0b0ae9153b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56685e6c0c2144c5b9df831554ceea15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "658c914e5d154eecbb88e7945d531d58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "611fd37c32934c9aabdeacb816431f57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61878bdb275b41548f23a87c0f0afdcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0ce2729f61c74cea81b09b3080d0fb66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1cc64d03afb54abc9b36d1b9e5989eb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab7bd7eb80d74e9084a62d1d599e955c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d430850cda764bb085f762e9bb654a0f",
              "IPY_MODEL_e573fb6858b1475984812a7d1361de47",
              "IPY_MODEL_c3630c9255c1429fbbb9d248e91c9ebf"
            ],
            "layout": "IPY_MODEL_e2d75d64ce194295a712189ae26679dd"
          }
        },
        "d430850cda764bb085f762e9bb654a0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d36e2e09a5934143a5770545e52ba486",
            "placeholder": "​",
            "style": "IPY_MODEL_106e5c43034c4e7583db2fa4d1aad491",
            "value": ""
          }
        },
        "e573fb6858b1475984812a7d1361de47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aafaeb037afe4f83883d978ad5a2a866",
            "max": 64275384,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5c4f502b557d4c258c2ef9e50527deb8",
            "value": 64275384
          }
        },
        "c3630c9255c1429fbbb9d248e91c9ebf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20e968f2d655407cb6c358115ccb7646",
            "placeholder": "​",
            "style": "IPY_MODEL_6e4040f1be654833b84f5fa3ba397921",
            "value": " 64275456/? [00:08&lt;00:00, 16972064.67it/s]"
          }
        },
        "e2d75d64ce194295a712189ae26679dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d36e2e09a5934143a5770545e52ba486": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "106e5c43034c4e7583db2fa4d1aad491": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aafaeb037afe4f83883d978ad5a2a866": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c4f502b557d4c258c2ef9e50527deb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "20e968f2d655407cb6c358115ccb7646": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e4040f1be654833b84f5fa3ba397921": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ni7070/lifelong_learning/blob/master/LL(Experiment).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jl01EJUTKHSo"
      },
      "outputs": [],
      "source": [
        "#tensor_set.py \n",
        "\n",
        "import os\n",
        "\n",
        "import torch\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "class TensorDataset(Dataset):\n",
        "    def __init__(self, path):\n",
        "        data = torch.load(path)\n",
        "        self.rows, self.labels = data[:, :-1], data[:, -1]\n",
        "        self.n = len(self.labels)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.rows[index], self.labels[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n\n",
        "\n",
        "\n",
        "def extract_features(image_dataset: Dataset, extractor: torch.nn.Module, out_path: str, device='cpu'):\n",
        "    print('Extracting features...')\n",
        "    loader = torch.utils.data.DataLoader(image_dataset, batch_size=256, num_workers=4)\n",
        "    n = len(image_dataset)\n",
        "    init = False\n",
        "    all_data = None\n",
        "\n",
        "    i = 0\n",
        "    for inputs, labels in tqdm(loader):\n",
        "        with torch.no_grad():\n",
        "            print('in', inputs.shape)\n",
        "            features = extractor(inputs.to(device)).cpu()\n",
        "            print('out', features.shape)\n",
        "            if not init:\n",
        "                all_data = torch.zeros((n, features.shape[1] + 1))\n",
        "                init = True\n",
        "\n",
        "            all_data[i:i + len(features), :-1] = features\n",
        "            all_data[i:i + len(features), -1] = labels\n",
        "\n",
        "        i += len(features)\n",
        "        print(i)\n",
        "\n",
        "    print(f'Saving to {out_path}')\n",
        "    os.makedirs(os.path.join(*out_path.split('/')[:-1]), exist_ok=True)\n",
        "    torch.save(all_data, out_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#learners/model/resnext.py \n",
        "\n",
        "from __future__ import division\n",
        "\n",
        "import torch\n",
        "\n",
        "\"\"\" \n",
        "Creates a ResNeXt Model as defined in:\n",
        "Xie, S., Girshick, R., Dollar, P., Tu, Z., & He, K. (2016). \n",
        "Aggregated residual transformations for deep neural networks. \n",
        "arXiv preprint arXiv:1611.05431.\n",
        "import from https://github.com/prlz77/ResNeXt.pytorch/blob/master/models/model.py\n",
        "\"\"\"\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import init\n",
        "\n",
        "__all__ = ['resnext']\n",
        "\n",
        "\n",
        "class ResNeXtBottleneck(nn.Module):\n",
        "    \"\"\"\n",
        "    RexNeXt bottleneck type C (https://github.com/facebookresearch/ResNeXt/blob/master/models/resnext.lua)\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, stride, cardinality, widen_factor):\n",
        "        \"\"\" Constructor\n",
        "        Args:\n",
        "            in_channels: input channel dimensionality\n",
        "            out_channels: output channel dimensionality\n",
        "            stride: conv stride. Replaces pooling layer.\n",
        "            cardinality: num of convolution groups.\n",
        "            widen_factor: factor to reduce the input dimensionality before convolution.\n",
        "        \"\"\"\n",
        "        super(ResNeXtBottleneck, self).__init__()\n",
        "        D = cardinality * out_channels // widen_factor\n",
        "        self.conv_reduce = nn.Conv2d(in_channels, D, kernel_size=1, stride=1, padding=0, bias=False)\n",
        "        self.bn_reduce = nn.BatchNorm2d(D)\n",
        "        self.conv_conv = nn.Conv2d(D, D, kernel_size=3, stride=stride, padding=1, groups=cardinality, bias=False)\n",
        "        self.bn = nn.BatchNorm2d(D)\n",
        "        self.conv_expand = nn.Conv2d(D, out_channels, kernel_size=1, stride=1, padding=0, bias=False)\n",
        "        self.bn_expand = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if in_channels != out_channels:\n",
        "            self.shortcut.add_module('shortcut_conv', nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, padding=0, bias=False))\n",
        "            self.shortcut.add_module('shortcut_bn', nn.BatchNorm2d(out_channels))\n",
        "\n",
        "    def forward(self, x):\n",
        "        bottleneck = self.conv_reduce.forward(x)\n",
        "        bottleneck = F.relu(self.bn_reduce.forward(bottleneck), inplace=True)\n",
        "        bottleneck = self.conv_conv.forward(bottleneck)\n",
        "        bottleneck = F.relu(self.bn.forward(bottleneck), inplace=True)\n",
        "        bottleneck = self.conv_expand.forward(bottleneck)\n",
        "        bottleneck = self.bn_expand.forward(bottleneck)\n",
        "        residual = self.shortcut.forward(x)\n",
        "        return F.relu(residual + bottleneck, inplace=True)\n",
        "\n",
        "\n",
        "class CifarResNeXt(nn.Module):\n",
        "    \"\"\"\n",
        "    ResNext optimized for the Cifar dataset, as specified in\n",
        "    https://arxiv.org/pdf/1611.05431.pdf\n",
        "    \"\"\"\n",
        "    def __init__(self, cardinality, depth, num_classes, widen_factor=4, dropRate=0):\n",
        "        \"\"\" Constructor\n",
        "        Args:\n",
        "            cardinality: number of convolution groups.\n",
        "            depth: number of layers.\n",
        "            num_classes: number of classes\n",
        "            widen_factor: factor to adjust the channel dimensionality\n",
        "        \"\"\"\n",
        "        super(CifarResNeXt, self).__init__()\n",
        "        self.cardinality = cardinality\n",
        "        self.depth = depth\n",
        "        self.block_depth = (self.depth - 2) // 9\n",
        "        self.widen_factor = widen_factor\n",
        "        self.num_classes = num_classes\n",
        "        self.output_size = 64\n",
        "        self.stages = [64, 64 * self.widen_factor, 128 * self.widen_factor, 256 * self.widen_factor]\n",
        "\n",
        "        self.conv_1_3x3 = nn.Conv2d(3, 64, 3, 1, 1, bias=False)\n",
        "        self.bn_1 = nn.BatchNorm2d(64)\n",
        "        self.stage_1 = self.block('stage_1', self.stages[0], self.stages[1], 1)\n",
        "        self.stage_2 = self.block('stage_2', self.stages[1], self.stages[2], 2)\n",
        "        self.stage_3 = self.block('stage_3', self.stages[2], self.stages[3], 2)\n",
        "        self.classifier = nn.Linear(1024, num_classes)\n",
        "        init.kaiming_normal(self.classifier.weight)\n",
        "\n",
        "        for key in self.state_dict():\n",
        "            if key.split('.')[-1] == 'weight':\n",
        "                if 'conv' in key:\n",
        "                    init.kaiming_normal(self.state_dict()[key], mode='fan_out')\n",
        "                if 'bn' in key:\n",
        "                    self.state_dict()[key][...] = 1\n",
        "            elif key.split('.')[-1] == 'bias':\n",
        "                self.state_dict()[key][...] = 0\n",
        "\n",
        "    def block(self, name, in_channels, out_channels, pool_stride=2):\n",
        "        \"\"\" Stack n bottleneck modules where n is inferred from the depth of the network.\n",
        "        Args:\n",
        "            name: string name of the current block.\n",
        "            in_channels: number of input channels\n",
        "            out_channels: number of output channels\n",
        "            pool_stride: factor to reduce the spatial dimensionality in the first bottleneck of the block.\n",
        "        Returns: a Module consisting of n sequential bottlenecks.\n",
        "        \"\"\"\n",
        "        block = nn.Sequential()\n",
        "        for bottleneck in range(self.block_depth):\n",
        "            name_ = '%s_bottleneck_%d' % (name, bottleneck)\n",
        "            if bottleneck == 0:\n",
        "                block.add_module(name_, ResNeXtBottleneck(in_channels, out_channels, pool_stride, self.cardinality,\n",
        "                                                          self.widen_factor))\n",
        "            else:\n",
        "                block.add_module(name_,\n",
        "                                 ResNeXtBottleneck(out_channels, out_channels, 1, self.cardinality, self.widen_factor))\n",
        "        return block\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_1_3x3.forward(x)\n",
        "        x = F.relu(self.bn_1.forward(x), inplace=True)\n",
        "        x = self.stage_1.forward(x)\n",
        "        x = self.stage_2.forward(x)\n",
        "        x = self.stage_3.forward(x)\n",
        "        x = F.avg_pool2d(x, 8, 1)\n",
        "        x = x.view(-1, 1, 1024)\n",
        "\n",
        "        # todo: remove\n",
        "        x = F.avg_pool1d(x, 2)\n",
        "        x = x.view(-1, 512)\n",
        "\n",
        "        return x\n",
        "        #return self.classifier(x)\n",
        "\n",
        "\n",
        "def create_cifar_resnext(model_path: str):\n",
        "    checkpoint = torch.load(model_path)\n",
        "    state_dict = checkpoint['state_dict']\n",
        "\n",
        "    # new_state_dict = OrderedDict()\n",
        "    # for k, v in state_dict.items():\n",
        "    #     if 'module' not in k:\n",
        "    #         k = 'module.'+k\n",
        "    #     else:\n",
        "    #         k = k.replace('features.module.', 'module.features.')\n",
        "    #     new_state_dict[k] = v\n",
        "\n",
        "    net = CifarResNeXt(depth=29, cardinality=8, num_classes=100, widen_factor=4)\n",
        "    net = torch.nn.DataParallel(net)\n",
        "    net.load_state_dict(state_dict)\n",
        "\n",
        "    return net"
      ],
      "metadata": {
        "id": "C6CoVsoJKTrb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Data_Utils\n",
        "import collections\n",
        "import os\n",
        "import zipfile\n",
        "from typing import Optional, Callable, Dict\n",
        "import torch\n",
        "from typing import Sequence\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import Dataset, Subset, DataLoader\n",
        "from torch.utils.data.dataset import T_co\n",
        "\n",
        "\n",
        "class IndexDataset(Dataset):\n",
        "\n",
        "    def __init__(self, dataset: Dataset):\n",
        "        self.dataset = dataset\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        data, target = self.dataset.__getitem__(index)\n",
        "        return data, target, index\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.dataset.__len__()\n",
        "\n",
        "\n",
        "class ClassSubset(Subset):\n",
        "\n",
        "    def __init__(self, dataset: Dataset[T_co], indices: Sequence[int], classes: Sequence[int]) -> None:\n",
        "        super().__init__(dataset, indices)\n",
        "        self.cls_map = {c: i for i, c in enumerate(classes)}\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img, target = self.dataset[self.indices[idx]]\n",
        "        return img, self.cls_map[target]\n",
        "\n",
        "\n",
        "class DataUtils:\n",
        "\n",
        "    @staticmethod\n",
        "    def create_dataset_subset(dataset: Dataset, classes: list, indices_path: str):\n",
        "        if os.path.exists(indices_path):\n",
        "            print(f'Loading indices from {indices_path}')\n",
        "            return ClassSubset(dataset, torch.load(indices_path), classes)\n",
        "\n",
        "        indices_per_class = DataUtils.get_class_indices(IndexDataset(dataset))\n",
        "\n",
        "        indices = []\n",
        "        for c in classes:\n",
        "            indices.extend(indices_per_class[c])\n",
        "\n",
        "        print(f'Writing indices to {indices_path}')\n",
        "        torch.save(indices, indices_path)\n",
        "\n",
        "        return ClassSubset(dataset, indices, classes)\n",
        "\n",
        "    @staticmethod\n",
        "    def create_dataset(root: str, dir_name: str, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None,\n",
        "                       download: bool = False, download_func: Optional[Callable] = None, zip_file: str = None, post_func: Optional[Callable] = None):\n",
        "        input_folder = os.path.join(root, dir_name)\n",
        "\n",
        "        if not os.path.exists(input_folder):\n",
        "            if download and download_func is not None:\n",
        "                print('Downloading the dataset')\n",
        "                download_func()\n",
        "\n",
        "                if os.path.exists(f'{root}/{zip_file}'):\n",
        "                    print(f'Extracting from {zip_file}')\n",
        "\n",
        "                    with zipfile.ZipFile(f'{root}/{zip_file}', 'r') as zip_ref:\n",
        "                        zip_ref.extractall(root)\n",
        "            else:\n",
        "                raise RuntimeError('Dataset not found. You can use download=True to download it')\n",
        "\n",
        "        if post_func is not None:\n",
        "            post_func(input_folder)\n",
        "\n",
        "        return ImageFolder(input_folder, transform, target_transform)\n",
        "\n",
        "    @staticmethod\n",
        "    def get_class_indices(dataset: IndexDataset) -> Dict[int, list]:\n",
        "        class_indices = collections.defaultdict(list)\n",
        "\n",
        "        for inputs, labels, indices in DataLoader(dataset, batch_size=1024, num_workers=4):\n",
        "            for label, idx in zip(labels.tolist(), indices.tolist()):\n",
        "                class_indices[label].append(idx)\n",
        "\n",
        "        return class_indices"
      ],
      "metadata": {
        "id": "ftP_hr6LKWmg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install wget"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naBSnRQEKXZx",
        "outputId": "94d1c0d4-06c2-455e-8043-1903e55fe17f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9675 sha256=029918dc0dc74dbbb0a9e1bc063dbef3f379a01446a37dd3eb1b18212b6726b8\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENkpOeC8KbA9",
        "outputId": "219e2094-5874-45f5-e0fa-80efd333ca06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_cifar_resnext29_pth_tar = '/content/drive/MyDrive/pth files/cifar_resnext29.pth.tar'\n",
        "svhn_train_save_path1 = '/content/drive/MyDrive/pth files/svhn10-2-train.pt'\n",
        "svhn_test_save_path1 = '/content/drive/MyDrive/pth files/svhn10-2-test.pt'\n",
        "svhn_train_save_path2 = '/content/drive/MyDrive/pth files/svhn10-train.pt'\n",
        "svhn_test_save_path2 = '/content/drive/MyDrive/pth files/svhn10-test.pt'"
      ],
      "metadata": {
        "id": "CgkQloV9Kdge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data.data_collection\n",
        "\n",
        "import torch\n",
        "import wget\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from PIL import Image\n",
        "\n",
        "# from data.cifar100_coarse import CIFAR100Coarse\n",
        "# from data.data_utils import DataUtils\n",
        "# from data.post_funcs import imagenet200_val_post\n",
        "# from data.tensor_set import TensorDataset\n",
        "\n",
        "pytorch_data_root = './pytorch_data'\n",
        "arff_data_root = './arff_data'\n",
        "\n",
        "\n",
        "\n",
        "data_creators = {\n",
        "    # 'MNIST-TRAIN': lambda: datasets.MNIST(pytorch_data_root, train=True, download=True, transform=transforms.Compose([transforms.ToTensor()])),\n",
        "    # 'MNIST-TEST': lambda: datasets.MNIST(pytorch_data_root, train=False, download=True, transform=transforms.Compose([transforms.ToTensor()])),\n",
        "    # 'MNIST-TRAIN-FLAT': lambda: datasets.MNIST(pytorch_data_root, train=True, download=True, transform=transforms.Compose([transforms.ToTensor(), transforms.Lambda(lambda x: torch.flatten(x))])),\n",
        "    # 'MNIST-TEST-FLAT': lambda: datasets.MNIST(pytorch_data_root, train=False, download=True, transform=transforms.Compose([transforms.ToTensor(), transforms.Lambda(lambda x: torch.flatten(x))])),\n",
        "    # 'MNIST-TRAIN-TENSOR': lambda: TensorDataset(f'{pytorch_data_root}/extracted/mnist10-train.pt'),\n",
        "    # 'MNIST-TEST-TENSOR': lambda: TensorDataset(f'{pytorch_data_root}/extracted/mnist10-test.pt'),\n",
        "    # 'FASHION-TRAIN': lambda: datasets.FashionMNIST(pytorch_data_root, train=True, download=True, transform=transforms.Compose([transforms.RandomHorizontalFlip(), transforms.ToTensor()])),\n",
        "    # 'FASHION-TEST': lambda: datasets.FashionMNIST(pytorch_data_root, train=False, download=True, transform=transforms.Compose([transforms.ToTensor()])),\n",
        "    # 'FASHION-TRAIN-FLAT': lambda: datasets.FashionMNIST(pytorch_data_root, train=True, download=True, transform=transforms.Compose([transforms.RandomHorizontalFlip(), transforms.ToTensor(), transforms.Lambda(lambda x: torch.flatten(x))])),\n",
        "    # 'FASHION-TEST-FLAT': lambda: datasets.FashionMNIST(pytorch_data_root, train=False, download=True, transform=transforms.Compose([transforms.ToTensor(), transforms.Lambda(lambda x: torch.flatten(x))])),\n",
        "    # 'FASHION-TRAIN-TENSOR': lambda: TensorDataset(f'{pytorch_data_root}/extracted/fashion10-train.pt'),\n",
        "    # 'FASHION-TEST-TENSOR': lambda: TensorDataset(f'{pytorch_data_root}/extracted/fashion10-test.pt'),\n",
        "    'SVHN-TRAIN': lambda: datasets.SVHN(pytorch_data_root, split='train', transform=transforms.Compose([transforms.ToTensor()]), download=True),\n",
        "    'SVHN-TEST': lambda: datasets.SVHN(pytorch_data_root, split='test', transform=transforms.Compose([transforms.ToTensor()]), download=True),\n",
        "    'SVHN-TRAIN-TENSOR': lambda: TensorDataset(svhn_train_save_path1),\n",
        "    'SVHN-TEST-TENSOR': lambda: TensorDataset(svhn_test_save_path1),\n",
        "    # 'SVHN-TRAIN-TENSOR': lambda: TensorDataset(svhn_train_save_path2),\n",
        "    # 'SVHN-TEST-TENSOR': lambda: TensorDataset(svhn_train_save_path2),\n",
        "    \n",
        "    # 'CIFAR10-TRAIN': lambda: datasets.CIFAR10(pytorch_data_root, True, transform=transforms.Compose([transforms.RandomHorizontalFlip(), transforms.ToTensor()]), download=True),\n",
        "    # 'CIFAR10-TEST': lambda: datasets.CIFAR10(pytorch_data_root, False, transform=transforms.Compose([transforms.ToTensor()]), download=True),\n",
        "    # 'CIFAR10-TRAIN-TENSOR': lambda: TensorDataset(f'{pytorch_data_root}/extracted/cifar10-train.pt'),\n",
        "    # 'CIFAR10-TEST-TENSOR': lambda: TensorDataset(f'{pytorch_data_root}/extracted/cifar10-test.pt'),\n",
        "    # 'CIFAR100-TRAIN': lambda: datasets.CIFAR100(pytorch_data_root, True, transform=transforms.Compose([transforms.RandomHorizontalFlip(), transforms.ToTensor()]), download=True),\n",
        "    # 'CIFAR100-TEST': lambda: datasets.CIFAR100(pytorch_data_root, False, transform=transforms.Compose([transforms.ToTensor()]), download=True),\n",
        "    # 'CIFAR20C-TRAIN': lambda: CIFAR100Coarse(pytorch_data_root, train=True, transform=transforms.Compose([transforms.RandomHorizontalFlip(), transforms.ToTensor()]), download=True),\n",
        "    # 'CIFAR20C-TEST': lambda: CIFAR100Coarse(pytorch_data_root, train=False, transform=transforms.Compose([transforms.ToTensor()]), download=True),\n",
        "    # 'CIFAR20C-TRAIN-TENSOR': lambda: TensorDataset(f'{pytorch_data_root}/extracted/cifar20c-train.pt'),\n",
        "    # 'CIFAR20C-TEST-TENSOR': lambda: TensorDataset(f'{pytorch_data_root}/extracted/cifar20c-test.pt'),\n",
        "    # 'IMAGENET200-TRAIN': lambda: DataUtils.create_dataset(pytorch_data_root, 'tiny-imagenet-200/train',\n",
        "    #                                                       transform=transforms.Compose([transforms.Resize((224, 224), interpolation=Image.NEAREST), transforms.ToTensor()]),\n",
        "    #                                             download=True, download_func=lambda: wget.download('http://cs231n.stanford.edu/tiny-imagenet-200.zip', pytorch_data_root),\n",
        "    #                                             zip_file='tiny-imagenet-200.zip',),\n",
        "    # 'IMAGENET200-TEST': lambda: DataUtils.create_dataset(pytorch_data_root, 'tiny-imagenet-200/val',\n",
        "    #                                                      transform=transforms.Compose([transforms.Resize((224, 224), interpolation=Image.NEAREST), transforms.ToTensor()]),\n",
        "    #                                            download=True, download_func=lambda: wget.download('http://cs231n.stanford.edu/tiny-imagenet-200.zip', pytorch_data_root),\n",
        "    #                                            zip_file='tiny-imagenet-200.zip', post_func=imagenet200_val_post),\n",
        "    # 'IMAGENET10-TRAIN': lambda: DataUtils.create_dataset_subset(get('IMAGENET200-TRAIN'), [0, 22, 25, 68, 117, 145, 153, 176, 188, 198], f'{pytorch_data_root}/imagenet10-train-indices.pt'),\n",
        "    # 'IMAGENET10-TEST': lambda: DataUtils.create_dataset_subset(get('IMAGENET200-TEST'), [0, 22, 25, 68, 117, 145, 153, 176, 188, 198], f'{pytorch_data_root}/imagenet10-test-indices.pt'),\n",
        "    # 'IMAGENET10-TRAIN-TENSOR': lambda: TensorDataset(f'{pytorch_data_root}/extracted/imagenet10-train.pt'),\n",
        "    # 'IMAGENET10-TEST-TENSOR': lambda: TensorDataset(f'{pytorch_data_root}/extracted/imagenet10-test.pt'),\n",
        "    # 'IMAGENET20A-TRAIN': lambda: DataUtils.create_dataset_subset(get('IMAGENET200-TRAIN'), [i * 10 - 1 for i in range(1, 21)], f'{pytorch_data_root}/imagenet20a-train-indices.pt'),\n",
        "    # 'IMAGENET20A-TEST': lambda: DataUtils.create_dataset_subset(get('IMAGENET200-TEST'), [i * 10 - 1 for i in range(1, 21)], f'{pytorch_data_root}/imagenet20a-test-indices.pt'),\n",
        "    # 'IMAGENET20A-TRAIN-TENSOR': lambda: TensorDataset(f'{pytorch_data_root}/extracted/imagenet20a-train.pt'),\n",
        "    # 'IMAGENET20A-TEST-TENSOR': lambda: TensorDataset(f'{pytorch_data_root}/extracted/imagenet20a-test.pt'),\n",
        "    # 'IMAGENET20B-TRAIN': lambda: DataUtils.create_dataset_subset(get('IMAGENET200-TRAIN'), [i * 10 - 5 for i in range(1, 21)], f'{pytorch_data_root}/imagenet20b-train-indices.pt'),\n",
        "    # 'IMAGENET20B-TEST': lambda: DataUtils.create_dataset_subset(get('IMAGENET200-TEST'), [i * 10 - 5 for i in range(1, 21)], f'{pytorch_data_root}/imagenet20b-test-indices.pt'),\n",
        "    # 'IMAGENET20B-TRAIN-TENSOR': lambda: TensorDataset(f'{pytorch_data_root}/extracted/imagenet20b-train.pt'),\n",
        "    # 'IMAGENET20B-TEST-TENSOR': lambda: TensorDataset(f'{pytorch_data_root}/extracted/imagenet20b-test.pt'),\n",
        "    # 'CELEB-TRAIN': lambda: datasets.CelebA(pytorch_data_root, split='train', target_type='identity', transform=transforms.Compose([transforms.ToTensor()]), download=True),\n",
        "    # 'CELEB-TEST': lambda: datasets.CelebA(pytorch_data_root, split='test', target_type='identity', transform=transforms.Compose([transforms.ToTensor()]), download=True)\n",
        "\n",
        "    # TODO:\n",
        "    # CORE50: https://vlomonaco.github.io/core50/index.html#dataset\n",
        "    # IMAGENET1000 (64): https://patrykchrabaszcz.github.io/Imagenet32/\n",
        "\n",
        "    # A) MNIST, FASHION, SVHN, CIFAR10, IMG10\n",
        "    # B) CORE50, CIFAR100, IMG200\n",
        "    # C) CELEB, IMG1000\n",
        "}\n",
        "\n",
        "class data_collection():\n",
        "  def get(name: str):\n",
        "      return data_creators[name]()"
      ],
      "metadata": {
        "id": "T-FTbEMsKhAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchsummary import summary\n",
        "\n",
        "# from data.tensor_set import extract_features\n",
        "# from learners.models.resnext import create_cifar_resnext\n",
        "# import data.data_collection as data_col\n",
        "\n",
        "\n",
        "def extract(last):\n",
        "    print('Running')\n",
        "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # cifar_resnext29.pth.tar -> https://github.com/bearpaw/pytorch-classification/blob/master/models/cifar/resnext.py\n",
        "\n",
        "    extractor = create_cifar_resnext(path_cifar_resnext29_pth_tar)\n",
        "    extractor.classifier = torch.nn.Identity()\n",
        "    extractor.eval().to(device)\n",
        "    summary(extractor.to(device), (3, 32, 32))\n",
        "    dataset = data_collection.get('SVHN-TRAIN')\n",
        "    extract_features(dataset, extractor, svhn_train_save_path1, device=device)\n",
        "    dataset = data_collection.get('SVHN-TEST')\n",
        "    extract_features(dataset, extractor, svhn_test_save_path1, device=device)\n",
        "\n",
        "    # extractor = create_cifar_resnext(path_cifar_resnext29_pth_tar)\n",
        "    # extractor.classifier = torch.nn.Identity()\n",
        "    # extractor.eval().to(device)\n",
        "    # summary(extractor.to(device), (3, 32, 32))\n",
        "    # dataset = data_collection.get('CIFAR20C-TRAIN')\n",
        "    # extract_features(dataset, extractor, f'pytorch_data/extracted/cifar20c-train.pt', device=device)\n",
        "    # dataset = data_collection.get('CIFAR20C-TEST')\n",
        "    # extract_features(dataset, extractor, f'pytorch_data/extracted/cifar20c-test.pt', device=device)\n",
        "\n",
        "    # extractor = torchvision.models.resnet18(pretrained=True)\n",
        "    # fc1 = extractor.fc\n",
        "    # extractor.fc = torch.nn.Sequential(fc1, torch.nn.Linear(1000, 256), torch.nn.ReLU(), torch.nn.Linear(256, 20))\n",
        "    # extractor.load_state_dict(torch.load('pytorch_models/imgnet20a-2f.pth'))\n",
        "    # if not last: extractor.fc = torch.nn.Identity()\n",
        "    # extractor.eval().to(device)\n",
        "    # dataset = data_collection.get('IMAGENET20A-TRAIN')\n",
        "    # extract_features(dataset, extractor, f'pytorch_data/extracted/imagenet20a-train.pt', device=device)\n",
        "    # dataset = data_collection.get('IMAGENET20A-TEST')\n",
        "    # extract_features(dataset, extractor, f'pytorch_data/extracted/imagenet20a-test.pt', device=device)\n",
        "\n",
        "    # extractor = torchvision.models.resnet18(pretrained=True)\n",
        "    # fc1 = extractor.fc\n",
        "    # extractor.fc = torch.nn.Sequential(fc1, torch.nn.Linear(1000, 256), torch.nn.ReLU(), torch.nn.Linear(256, 20))\n",
        "    # extractor.load_state_dict(torch.load('pytorch_models/imgnet20b-2f.pth'))\n",
        "    # if not last: extractor.fc = torch.nn.Identity()\n",
        "    # extractor.eval().to(device)\n",
        "    # dataset = data_collection.get('IMAGENET20B-TRAIN')\n",
        "    # extract_features(dataset, extractor, f'pytorch_data/extracted/imagenet20b-train.pt', device=device)\n",
        "    # dataset = data_collection.get('IMAGENET20B-TEST')\n",
        "    # extract_features(dataset, extractor, f'pytorch_data/extracted/imagenet20b-test.pt', device=device)"
      ],
      "metadata": {
        "id": "9rcA7IlCKjDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extract(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d964ed66d1a7400ab7ab186f8aaed938",
            "bbf83f01e2a646ca931d1b9e058e07b7",
            "2a9ab2e8444e405092291f672d8f05d7",
            "233e3ee87558499aaacfb0b3c15e5385",
            "b4482525e66743138ae4e0b0ae9153b8",
            "56685e6c0c2144c5b9df831554ceea15",
            "658c914e5d154eecbb88e7945d531d58",
            "611fd37c32934c9aabdeacb816431f57",
            "61878bdb275b41548f23a87c0f0afdcc",
            "0ce2729f61c74cea81b09b3080d0fb66",
            "1cc64d03afb54abc9b36d1b9e5989eb8",
            "ab7bd7eb80d74e9084a62d1d599e955c",
            "d430850cda764bb085f762e9bb654a0f",
            "e573fb6858b1475984812a7d1361de47",
            "c3630c9255c1429fbbb9d248e91c9ebf",
            "e2d75d64ce194295a712189ae26679dd",
            "d36e2e09a5934143a5770545e52ba486",
            "106e5c43034c4e7583db2fa4d1aad491",
            "aafaeb037afe4f83883d978ad5a2a866",
            "5c4f502b557d4c258c2ef9e50527deb8",
            "20e968f2d655407cb6c358115ccb7646",
            "6e4040f1be654833b84f5fa3ba397921"
          ]
        },
        "id": "2usr5gC5Km8F",
        "outputId": "f865c756-bb83-4470-ab71-060330c491f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:87: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:92: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1          [-1, 256, 32, 32]          16,384\n",
            "       BatchNorm2d-2          [-1, 256, 32, 32]             512\n",
            " ResNeXtBottleneck-3          [-1, 256, 32, 32]               0\n",
            " ResNeXtBottleneck-4          [-1, 256, 32, 32]               0\n",
            " ResNeXtBottleneck-5          [-1, 256, 32, 32]               0\n",
            "            Conv2d-6          [-1, 512, 16, 16]         131,072\n",
            "       BatchNorm2d-7          [-1, 512, 16, 16]           1,024\n",
            " ResNeXtBottleneck-8          [-1, 512, 16, 16]               0\n",
            " ResNeXtBottleneck-9          [-1, 512, 16, 16]               0\n",
            "ResNeXtBottleneck-10          [-1, 512, 16, 16]               0\n",
            "           Conv2d-11           [-1, 1024, 8, 8]         524,288\n",
            "      BatchNorm2d-12           [-1, 1024, 8, 8]           2,048\n",
            "ResNeXtBottleneck-13           [-1, 1024, 8, 8]               0\n",
            "ResNeXtBottleneck-14           [-1, 1024, 8, 8]               0\n",
            "ResNeXtBottleneck-15           [-1, 1024, 8, 8]               0\n",
            "     CifarResNeXt-16                  [-1, 512]               0\n",
            "================================================================\n",
            "Total params: 675,328\n",
            "Trainable params: 675,328\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 17.50\n",
            "Params size (MB): 2.58\n",
            "Estimated Total Size (MB): 20.09\n",
            "----------------------------------------------------------------\n",
            "Downloading http://ufldl.stanford.edu/housenumbers/train_32x32.mat to ./pytorch_data/train_32x32.mat\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/182040794 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d964ed66d1a7400ab7ab186f8aaed938"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/287 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 1/287 [00:01<04:57,  1.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "256\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 2/287 [00:01<03:50,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "512\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 3/287 [00:02<03:32,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "768\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|▏         | 4/287 [00:03<03:20,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "1024\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 5/287 [00:03<03:15,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "1280\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 6/287 [00:04<03:11,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "1536\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 7/287 [00:05<03:09,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "1792\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 8/287 [00:05<03:06,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "2048\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 9/287 [00:06<03:05,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "2304\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 10/287 [00:06<03:04,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "2560\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 11/287 [00:07<03:04,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "2816\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 12/287 [00:08<03:03,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "3072\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▍         | 13/287 [00:08<03:02,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "3328\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▍         | 14/287 [00:09<03:01,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "3584\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 15/287 [00:10<03:01,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "3840\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 16/287 [00:10<03:01,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "4096\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 17/287 [00:11<03:00,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "4352\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▋         | 18/287 [00:12<03:00,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "4608\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 19/287 [00:13<02:59,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "4864\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 20/287 [00:13<02:59,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "5120\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 21/287 [00:14<02:58,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "5376\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 22/287 [00:15<02:57,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "5632\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 23/287 [00:15<02:57,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "5888\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 24/287 [00:16<02:56,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "6144\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▊         | 25/287 [00:17<02:55,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "6400\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 26/287 [00:17<02:55,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "6656\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 27/287 [00:18<02:54,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "6912\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|▉         | 28/287 [00:19<02:53,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "7168\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 29/287 [00:19<02:52,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "7424\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 30/287 [00:20<02:52,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "7680\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 31/287 [00:21<02:51,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "7936\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 32/287 [00:21<02:51,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "8192\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█▏        | 33/287 [00:22<02:50,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "8448\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 34/287 [00:23<02:49,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "8704\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 35/287 [00:23<02:49,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "8960\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 36/287 [00:24<02:48,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "9216\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 37/287 [00:25<02:47,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "9472\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 38/287 [00:25<02:47,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "9728\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▎        | 39/287 [00:26<02:46,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "9984\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 40/287 [00:27<02:46,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "10240\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 41/287 [00:27<02:46,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "10496\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▍        | 42/287 [00:28<02:45,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "10752\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▍        | 43/287 [00:29<02:44,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "11008\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 44/287 [00:29<02:45,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "11264\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 45/287 [00:30<02:44,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "11520\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 46/287 [00:31<02:44,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "11776\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▋        | 47/287 [00:31<02:44,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "12032\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 48/287 [00:32<02:44,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "12288\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 49/287 [00:33<02:43,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "12544\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 50/287 [00:33<02:42,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "12800\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 51/287 [00:34<02:42,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "13056\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 52/287 [00:35<02:41,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "13312\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 53/287 [00:36<02:41,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "13568\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▉        | 54/287 [00:36<02:41,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "13824\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▉        | 55/287 [00:37<02:40,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "14080\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|█▉        | 56/287 [00:38<02:40,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "14336\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|█▉        | 57/287 [00:38<02:38,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "14592\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 58/287 [00:39<02:38,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "14848\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██        | 59/287 [00:40<02:37,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "15104\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██        | 60/287 [00:40<02:36,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "15360\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██▏       | 61/287 [00:41<02:37,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "15616\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 62/287 [00:42<02:36,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "15872\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 63/287 [00:42<02:36,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "16128\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 64/287 [00:43<02:35,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "16384\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 65/287 [00:44<02:35,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "16640\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 66/287 [00:45<02:35,  1.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "16896\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 67/287 [00:45<02:35,  1.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "17152\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▎       | 68/287 [00:46<02:34,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "17408\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 69/287 [00:47<02:34,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "17664\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 70/287 [00:47<02:33,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "17920\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▍       | 71/287 [00:48<02:33,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "18176\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 72/287 [00:49<02:32,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "18432\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 73/287 [00:50<02:32,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "18688\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 74/287 [00:50<02:31,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "18944\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 75/287 [00:51<02:31,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "19200\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▋       | 76/287 [00:52<02:28,  1.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "19456\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 77/287 [00:52<02:28,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "19712\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 78/287 [00:53<02:28,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "19968\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 79/287 [00:54<02:26,  1.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "20224\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 80/287 [00:55<02:25,  1.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "20480\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 81/287 [00:55<02:25,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "20736\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▊       | 82/287 [00:56<02:25,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "20992\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▉       | 83/287 [00:57<02:24,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "21248\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▉       | 84/287 [00:57<02:23,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "21504\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|██▉       | 85/287 [00:58<02:23,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "21760\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|██▉       | 86/287 [00:59<02:22,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "22016\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 87/287 [00:59<02:22,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "22272\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███       | 88/287 [01:00<02:21,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "22528\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███       | 89/287 [01:01<02:20,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "22784\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███▏      | 90/287 [01:02<02:20,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "23040\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 91/287 [01:02<02:19,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "23296\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 92/287 [01:03<02:18,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "23552\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 93/287 [01:04<02:17,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "23808\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 94/287 [01:04<02:17,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "24064\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 95/287 [01:05<02:16,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "24320\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 96/287 [01:06<02:15,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "24576\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 97/287 [01:07<02:15,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "24832\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 98/287 [01:07<02:14,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "25088\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 99/287 [01:08<02:13,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "25344\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▍      | 100/287 [01:09<02:13,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "25600\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 101/287 [01:09<02:12,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "25856\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 102/287 [01:10<02:13,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "26112\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 103/287 [01:11<02:11,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "26368\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 104/287 [01:12<02:12,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "26624\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 105/287 [01:12<02:10,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "26880\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 106/287 [01:13<02:10,  1.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "27136\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 107/287 [01:14<02:10,  1.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "27392\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 108/287 [01:15<02:10,  1.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "27648\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 109/287 [01:15<02:09,  1.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "27904\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 110/287 [01:16<02:09,  1.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "28160\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 39%|███▊      | 111/287 [01:17<02:08,  1.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "28416\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 39%|███▉      | 112/287 [01:17<02:07,  1.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "28672\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 39%|███▉      | 113/287 [01:18<02:07,  1.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "28928\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|███▉      | 114/287 [01:19<02:06,  1.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "29184\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 115/287 [01:20<02:06,  1.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "29440\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 116/287 [01:20<02:05,  1.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "29696\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████      | 117/287 [01:21<02:04,  1.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "29952\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████      | 118/287 [01:22<02:04,  1.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "30208\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████▏     | 119/287 [01:23<02:03,  1.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "30464\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 120/287 [01:23<02:03,  1.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "30720\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 121/287 [01:24<02:03,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "30976\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 122/287 [01:25<02:03,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "31232\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 123/287 [01:26<02:02,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "31488\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 124/287 [01:26<02:02,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "31744\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▎     | 125/287 [01:27<02:01,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "32000\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 126/287 [01:28<02:01,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "32256\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 127/287 [01:29<02:00,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "32512\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▍     | 128/287 [01:29<01:59,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "32768\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▍     | 129/287 [01:30<01:58,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "33024\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▌     | 130/287 [01:31<01:58,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "33280\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 131/287 [01:32<01:57,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "33536\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 132/287 [01:32<01:56,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "33792\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▋     | 133/287 [01:33<01:56,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "34048\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 134/287 [01:34<01:55,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "34304\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 135/287 [01:35<01:55,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "34560\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 136/287 [01:35<01:54,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "34816\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 137/287 [01:36<01:54,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "35072\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 138/287 [01:37<01:53,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "35328\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 139/287 [01:38<01:52,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "35584\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▉     | 140/287 [01:39<01:52,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "35840\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▉     | 141/287 [01:39<01:51,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "36096\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▉     | 142/287 [01:40<01:50,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "36352\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|████▉     | 143/287 [01:41<01:50,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "36608\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 144/287 [01:42<01:50,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "36864\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████     | 145/287 [01:42<01:49,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "37120\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████     | 146/287 [01:43<01:48,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "37376\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████     | 147/287 [01:44<01:46,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "37632\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 148/287 [01:45<01:46,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "37888\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 149/287 [01:45<01:45,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "38144\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 150/287 [01:46<01:44,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "38400\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 151/287 [01:47<01:43,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "38656\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 152/287 [01:48<01:43,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "38912\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 153/287 [01:48<01:42,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "39168\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▎    | 154/287 [01:49<01:41,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "39424\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 155/287 [01:50<01:40,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "39680\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 156/287 [01:51<01:40,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "39936\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▍    | 157/287 [01:52<01:39,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "40192\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▌    | 158/287 [01:52<01:39,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "40448\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▌    | 159/287 [01:53<01:38,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "40704\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 160/287 [01:54<01:37,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "40960\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 161/287 [01:55<01:37,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "41216\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▋    | 162/287 [01:55<01:36,  1.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "41472\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 163/287 [01:56<01:36,  1.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "41728\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 164/287 [01:57<01:35,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "41984\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 165/287 [01:58<01:35,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "42240\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 166/287 [01:59<01:34,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "42496\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 167/287 [01:59<01:33,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "42752\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▊    | 168/287 [02:00<01:33,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "43008\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▉    | 169/287 [02:01<01:32,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "43264\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▉    | 170/287 [02:02<01:31,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "43520\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|█████▉    | 171/287 [02:02<01:31,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "43776\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|█████▉    | 172/287 [02:03<01:30,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "44032\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 173/287 [02:04<01:29,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "44288\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 61%|██████    | 174/287 [02:05<01:29,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "44544\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 61%|██████    | 175/287 [02:06<01:28,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "44800\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 61%|██████▏   | 176/287 [02:06<01:27,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "45056\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 177/287 [02:07<01:26,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "45312\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 178/287 [02:08<01:26,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "45568\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 179/287 [02:09<01:25,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "45824\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 180/287 [02:10<01:24,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "46080\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 181/287 [02:10<01:24,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "46336\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 182/287 [02:11<01:23,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "46592\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 183/287 [02:12<01:22,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "46848\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 184/287 [02:13<01:22,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "47104\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 185/287 [02:14<01:21,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "47360\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▍   | 186/287 [02:14<01:20,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "47616\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 187/287 [02:15<01:20,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "47872\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 188/287 [02:16<01:19,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "48128\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 189/287 [02:17<01:18,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "48384\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 190/287 [02:18<01:18,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "48640\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 191/287 [02:18<01:17,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "48896\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 192/287 [02:19<01:16,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "49152\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 193/287 [02:20<01:15,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "49408\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 194/287 [02:21<01:15,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "49664\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 195/287 [02:22<01:14,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "49920\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 196/287 [02:22<01:13,  1.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "50176\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▊   | 197/287 [02:23<01:12,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "50432\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▉   | 198/287 [02:24<01:12,  1.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "50688\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▉   | 199/287 [02:25<01:11,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "50944\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|██████▉   | 200/287 [02:26<01:10,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "51200\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 201/287 [02:26<01:09,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "51456\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 202/287 [02:27<01:08,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "51712\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████   | 203/287 [02:28<01:07,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "51968\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████   | 204/287 [02:29<01:07,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "52224\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████▏  | 205/287 [02:30<01:06,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "52480\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 206/287 [02:31<01:05,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "52736\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 207/287 [02:31<01:04,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "52992\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 208/287 [02:32<01:03,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "53248\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 209/287 [02:33<01:03,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "53504\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 210/287 [02:34<01:02,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "53760\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▎  | 211/287 [02:35<01:01,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "54016\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 212/287 [02:35<01:00,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "54272\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 213/287 [02:36<00:59,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "54528\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▍  | 214/287 [02:37<00:58,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "54784\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▍  | 215/287 [02:38<00:57,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "55040\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 216/287 [02:39<00:57,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "55296\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 217/287 [02:39<00:56,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "55552\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 218/287 [02:40<00:55,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "55808\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▋  | 219/287 [02:41<00:54,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "56064\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 220/287 [02:42<00:53,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "56320\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 221/287 [02:43<00:52,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "56576\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 222/287 [02:43<00:51,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "56832\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 223/287 [02:44<00:51,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "57088\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 224/287 [02:45<00:50,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "57344\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 225/287 [02:46<00:49,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "57600\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▊  | 226/287 [02:47<00:48,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "57856\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▉  | 227/287 [02:47<00:47,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "58112\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▉  | 228/287 [02:48<00:46,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "58368\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|███████▉  | 229/287 [02:49<00:46,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "58624\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 230/287 [02:50<00:45,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "58880\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 231/287 [02:51<00:44,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "59136\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|████████  | 232/287 [02:51<00:43,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "59392\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|████████  | 233/287 [02:52<00:42,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "59648\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 234/287 [02:53<00:42,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "59904\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 235/287 [02:54<00:41,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "60160\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 236/287 [02:54<00:40,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "60416\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 237/287 [02:55<00:39,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "60672\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 238/287 [02:56<00:38,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "60928\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 239/287 [02:57<00:38,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "61184\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▎ | 240/287 [02:58<00:37,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "61440\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 241/287 [02:58<00:36,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "61696\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 242/287 [02:59<00:35,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "61952\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▍ | 243/287 [03:00<00:34,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "62208\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 244/287 [03:01<00:34,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "62464\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 245/287 [03:02<00:33,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "62720\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 246/287 [03:02<00:32,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "62976\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 247/287 [03:03<00:31,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "63232\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▋ | 248/287 [03:04<00:30,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "63488\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 249/287 [03:05<00:30,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "63744\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 250/287 [03:06<00:29,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "64000\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 251/287 [03:06<00:28,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "64256\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 252/287 [03:07<00:27,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "64512\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 253/287 [03:08<00:26,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "64768\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▊ | 254/287 [03:09<00:26,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "65024\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▉ | 255/287 [03:10<00:25,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "65280\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▉ | 256/287 [03:10<00:24,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "65536\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|████████▉ | 257/287 [03:11<00:23,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "65792\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|████████▉ | 258/287 [03:12<00:22,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "66048\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 259/287 [03:13<00:22,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "66304\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████ | 260/287 [03:13<00:21,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "66560\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████ | 261/287 [03:14<00:20,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "66816\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████▏| 262/287 [03:15<00:19,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "67072\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 263/287 [03:16<00:18,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "67328\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 264/287 [03:17<00:18,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "67584\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 265/287 [03:17<00:17,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "67840\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 266/287 [03:18<00:16,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "68096\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 267/287 [03:19<00:15,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "68352\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 268/287 [03:20<00:15,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "68608\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▎| 269/287 [03:21<00:14,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "68864\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 270/287 [03:21<00:13,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "69120\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 271/287 [03:22<00:12,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "69376\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▍| 272/287 [03:23<00:11,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "69632\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 273/287 [03:24<00:11,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "69888\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 274/287 [03:25<00:10,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "70144\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 275/287 [03:25<00:09,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "70400\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 276/287 [03:26<00:08,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "70656\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 277/287 [03:27<00:07,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "70912\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 278/287 [03:28<00:07,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "71168\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 279/287 [03:29<00:06,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "71424\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 280/287 [03:29<00:05,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "71680\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 281/287 [03:30<00:04,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "71936\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 282/287 [03:31<00:03,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "72192\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▊| 283/287 [03:32<00:03,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "72448\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▉| 284/287 [03:33<00:02,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "72704\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▉| 285/287 [03:33<00:01,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "72960\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 287/287 [03:34<00:00,  1.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "73216\n",
            "in torch.Size([41, 3, 32, 32])\n",
            "out torch.Size([41, 512])\n",
            "73257\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r100%|██████████| 287/287 [03:34<00:00,  1.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving to /content/drive/MyDrive/pth files/svhn10-2-train.pt\n",
            "Downloading http://ufldl.stanford.edu/housenumbers/test_32x32.mat to ./pytorch_data/test_32x32.mat\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/64275384 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab7bd7eb80d74e9084a62d1d599e955c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/102 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 1/102 [00:01<01:49,  1.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "256\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 2/102 [00:01<01:29,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "512\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 3/102 [00:02<01:22,  1.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "768\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 4/102 [00:03<01:19,  1.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "1024\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▍         | 5/102 [00:04<01:17,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "1280\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 6/102 [00:04<01:15,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "1536\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 7/102 [00:05<01:14,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "1792\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 8/102 [00:06<01:13,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "2048\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 9/102 [00:07<01:12,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "2304\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|▉         | 10/102 [00:08<01:12,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "2560\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 11/102 [00:08<01:11,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "2816\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 12/102 [00:09<01:10,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "3072\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 13/102 [00:10<01:10,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "3328\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▎        | 14/102 [00:11<01:09,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "3584\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▍        | 15/102 [00:12<01:08,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "3840\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 16/102 [00:12<01:08,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "4096\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 17/102 [00:13<01:07,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "4352\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 18/102 [00:14<01:07,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "4608\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▊        | 19/102 [00:15<01:06,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "4864\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|█▉        | 20/102 [00:16<01:05,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "5120\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██        | 21/102 [00:16<01:05,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "5376\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 22/102 [00:17<01:05,  1.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "5632\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 23/102 [00:18<01:04,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "5888\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▎       | 24/102 [00:19<01:03,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "6144\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▍       | 25/102 [00:20<01:03,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "6400\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 26/102 [00:21<01:02,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "6656\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▋       | 27/102 [00:21<01:02,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "6912\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 28/102 [00:22<01:01,  1.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "7168\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 29/102 [00:23<01:00,  1.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "7424\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▉       | 30/102 [00:24<01:00,  1.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "7680\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 31/102 [00:25<00:59,  1.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "7936\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███▏      | 32/102 [00:26<00:59,  1.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "8192\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 33/102 [00:26<00:58,  1.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "8448\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 34/102 [00:27<00:57,  1.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "8704\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 35/102 [00:28<00:57,  1.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "8960\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 36/102 [00:29<00:56,  1.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "9216\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▋      | 37/102 [00:30<00:55,  1.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "9472\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 38/102 [00:31<00:54,  1.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "9728\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 39/102 [00:32<00:53,  1.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "9984\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 39%|███▉      | 40/102 [00:32<00:52,  1.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "10240\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 41/102 [00:33<00:51,  1.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "10496\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████      | 42/102 [00:34<00:50,  1.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "10752\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 43/102 [00:35<00:49,  1.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "11008\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 44/102 [00:36<00:48,  1.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "11264\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 45/102 [00:37<00:48,  1.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "11520\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▌     | 46/102 [00:37<00:46,  1.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "11776\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 47/102 [00:38<00:45,  1.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "12032\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 48/102 [00:39<00:44,  1.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "12288\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 49/102 [00:40<00:44,  1.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "12544\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▉     | 50/102 [00:41<00:43,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "12800\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 51/102 [00:42<00:42,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "13056\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████     | 52/102 [00:42<00:41,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "13312\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 53/102 [00:43<00:40,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "13568\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 54/102 [00:44<00:39,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "13824\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 55/102 [00:45<00:38,  1.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "14080\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▍    | 56/102 [00:46<00:37,  1.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "14336\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 57/102 [00:46<00:36,  1.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "14592\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 58/102 [00:47<00:35,  1.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "14848\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 59/102 [00:48<00:34,  1.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "15104\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▉    | 60/102 [00:49<00:33,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "15360\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|█████▉    | 61/102 [00:50<00:33,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "15616\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 61%|██████    | 62/102 [00:50<00:32,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "15872\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 63/102 [00:51<00:31,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "16128\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 64/102 [00:52<00:30,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "16384\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▎   | 65/102 [00:53<00:29,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "16640\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▍   | 66/102 [00:54<00:28,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "16896\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 67/102 [00:54<00:27,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "17152\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 68/102 [00:55<00:26,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "17408\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 69/102 [00:56<00:26,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "17664\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▊   | 70/102 [00:57<00:25,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "17920\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|██████▉   | 71/102 [00:58<00:24,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "18176\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████   | 72/102 [00:58<00:23,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "18432\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 73/102 [00:59<00:22,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "18688\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 74/102 [01:00<00:22,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "18944\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▎  | 75/102 [01:01<00:21,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "19200\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▍  | 76/102 [01:02<00:20,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "19456\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 77/102 [01:02<00:19,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "19712\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▋  | 78/102 [01:03<00:18,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "19968\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 79/102 [01:04<00:18,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "20224\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 80/102 [01:05<00:17,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "20480\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▉  | 81/102 [01:05<00:16,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "20736\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 82/102 [01:06<00:15,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "20992\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|████████▏ | 83/102 [01:07<00:14,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "21248\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 84/102 [01:08<00:14,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "21504\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 85/102 [01:09<00:13,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "21760\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 86/102 [01:09<00:12,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "22016\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 87/102 [01:10<00:11,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "22272\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▋ | 88/102 [01:11<00:10,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "22528\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 89/102 [01:12<00:10,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "22784\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 90/102 [01:13<00:09,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "23040\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▉ | 91/102 [01:13<00:08,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "23296\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 92/102 [01:14<00:07,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "23552\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████ | 93/102 [01:15<00:07,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "23808\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 94/102 [01:16<00:06,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "24064\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 95/102 [01:16<00:05,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "24320\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 96/102 [01:17<00:04,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "24576\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 97/102 [01:18<00:03,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "24832\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 98/102 [01:19<00:03,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "25088\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 99/102 [01:20<00:02,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "25344\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 100/102 [01:20<00:01,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "25600\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▉| 101/102 [01:21<00:00,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "25856\n",
            "in torch.Size([176, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 102/102 [01:22<00:00,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([176, 512])\n",
            "26032\n",
            "Saving to /content/drive/MyDrive/pth files/svhn10-2-test.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LL_DT.Runner"
      ],
      "metadata": {
        "id": "N7eGPrnnKrp-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install river"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5ttVpkEKtqN",
        "outputId": "d179fbe4-672f-4150-cf64-1b2320c6f57f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting river\n",
            "  Downloading river-0.10.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 41.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from river) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.7/dist-packages (from river) (1.21.6)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from river) (1.3.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->river) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->river) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.0.1->river) (1.15.0)\n",
            "Installing collected packages: river\n",
            "Successfully installed river-0.10.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ray"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJYKDO_lKuQz",
        "outputId": "94f9e663-5a57-4a7b-8e58-74bdcc078308"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ray\n",
            "  Downloading ray-1.12.1-cp37-cp37m-manylinux2014_x86_64.whl (53.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 53.2 MB 245 kB/s \n",
            "\u001b[?25hRequirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray) (1.0.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray) (3.13)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ray) (2.23.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray) (4.3.3)\n",
            "Collecting grpcio<=1.43.0,>=1.28.1\n",
            "  Downloading grpcio-1.43.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1 MB 68.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray) (7.1.2)\n",
            "Collecting frozenlist\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 74.3 MB/s \n",
            "\u001b[?25hCollecting virtualenv\n",
            "  Downloading virtualenv-20.14.1-py2.py3-none-any.whl (8.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8 MB 52.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray) (3.7.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from ray) (21.4.0)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from ray) (1.21.6)\n",
            "Collecting aiosignal\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: protobuf>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray) (3.17.3)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio<=1.43.0,>=1.28.1->ray) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray) (4.2.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray) (5.7.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray) (4.11.3)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray) (0.18.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema->ray) (3.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (3.0.4)\n",
            "Collecting platformdirs<3,>=2\n",
            "  Downloading platformdirs-2.5.2-py3-none-any.whl (14 kB)\n",
            "Collecting distlib<1,>=0.3.1\n",
            "  Downloading distlib-0.3.4-py2.py3-none-any.whl (461 kB)\n",
            "\u001b[K     |████████████████████████████████| 461 kB 62.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: platformdirs, frozenlist, distlib, virtualenv, grpcio, aiosignal, ray\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.46.1\n",
            "    Uninstalling grpcio-1.46.1:\n",
            "      Successfully uninstalled grpcio-1.46.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0+zzzcolab20220506162203 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\u001b[0m\n",
            "Successfully installed aiosignal-1.2.0 distlib-0.3.4 frozenlist-1.3.0 grpcio-1.43.0 platformdirs-2.5.2 ray-1.12.1 virtualenv-20.14.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from utils.calc_utils import CalculationsUtils. This is the CalculationsUtils class     \n",
        "\n",
        "import math\n",
        "\n",
        "import torch\n",
        "# from torch.tensor import Tensor\n",
        "from torch import Tensor\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class CalculationsUtils:\n",
        "\n",
        "    @staticmethod\n",
        "    def div(a: float, b: float):\n",
        "        return a / b if b else 0.0\n",
        "\n",
        "    @staticmethod\n",
        "    def div_tensor(t: Tensor, d: float):\n",
        "        return t / d if d else torch.zeros(len(t))\n",
        "\n",
        "    @staticmethod\n",
        "    def normalize(t: Tensor):\n",
        "        s = t.sum()\n",
        "        return t / s if s > 0.0 else t\n",
        "\n",
        "    @staticmethod\n",
        "    def sum_arrays(arrays):\n",
        "        out = []\n",
        "        active = set(range(len(arrays)))\n",
        "\n",
        "        i = 0\n",
        "        while active:\n",
        "            out.append(0.0)\n",
        "            to_remove = set()\n",
        "\n",
        "            for a_idx in active:\n",
        "                if i > len(arrays[a_idx]) - 1:\n",
        "                    to_remove.add(a_idx)\n",
        "                else:\n",
        "                    out[-1] += arrays[a_idx][i]\n",
        "\n",
        "            active -= to_remove\n",
        "            i += 1\n",
        "\n",
        "        return np.array(out[:-1])\n",
        "\n",
        "    @staticmethod\n",
        "    def log(x):\n",
        "        if x > 0.0: return math.log(x)\n",
        "        return float('-inf') if x == 0.0 else float('NaN')"
      ],
      "metadata": {
        "id": "SAf--yLgKy_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from utils.coll_utils import CollectionUtils  This is the 'CollectionUtils' class\n",
        "\n",
        "import itertools\n",
        "from functools import reduce\n",
        "from typing import Callable\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class CollectionUtils:\n",
        "\n",
        "    @staticmethod\n",
        "    def ensure_arr_size(arr: np.ndarray, y: int):\n",
        "        if len(arr.shape) == 1:\n",
        "            return np.hstack((arr, np.zeros(y - len(arr) + 1))) if len(arr) - 1 < y else arr\n",
        "        else:\n",
        "            return np.hstack((arr, np.zeros((arr.shape[0], y - arr.shape[1] + 1, arr.shape[2])))) if arr.shape[1] - 1 < y else arr\n",
        "\n",
        "    @staticmethod\n",
        "    def ensure_list2d_size(lst: list, y: int, element_creator: Callable[[], any]):\n",
        "        if len(lst[0]) > y:\n",
        "            return lst\n",
        "\n",
        "        for l in lst:\n",
        "            l_len = len(l) - 1\n",
        "            for _ in range(y - l_len):\n",
        "                l.append(element_creator())\n",
        "\n",
        "        return lst\n",
        "\n",
        "    @staticmethod\n",
        "    def split_list(lst, chunk_size: int):\n",
        "        return [lst[i:i + chunk_size] for i in range(0, len(lst), chunk_size)]\n",
        "\n",
        "    @staticmethod\n",
        "    def flatten_list(lst):\n",
        "        return list(itertools.chain.from_iterable(lst))"
      ],
      "metadata": {
        "id": "-rVEewVNK1r6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hoeffding Tree"
      ],
      "metadata": {
        "id": "0cgLQPm8K5Cg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# From core.clean import ContinualLearner this is the ContinualLearner class\n",
        "\n",
        "from abc import ABC, abstractmethod\n",
        "\n",
        "\n",
        "class ContinualLearner(ABC):\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def initialize(self, x_batch, y_batch, **kwargs):\n",
        "        self.update(x_batch, y_batch, **kwargs)\n",
        "\n",
        "    @abstractmethod\n",
        "    def predict(self, x_batch):\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def predict_prob(self, x_batch):\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def update(self, x_batch, y_batch, **kwargs):\n",
        "        pass"
      ],
      "metadata": {
        "id": "ypLTpM4_K4Qs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from utils.stat_utils import Statistics, GaussianEstimator  Here is the Statistics and GaussianEstimator classes\n",
        "\n",
        "\n",
        "from abc import ABC, abstractmethod\n",
        "from typing import Callable\n",
        "import math\n",
        "import numpy as np\n",
        "from scipy.stats import entropy\n",
        "import copy\n",
        "\n",
        "# from utils.calc_utils import CalculationsUtils as cu\n",
        "# from utils.coll_utils import CollectionUtils as clu\n",
        "\n",
        "SQ2 = math.sqrt(2.0)\n",
        "NC = math.sqrt(2.0 * math.pi)\n",
        "\n",
        "\n",
        "class ValueEstimator(ABC):\n",
        "\n",
        "    @abstractmethod\n",
        "    def update(self, v: float, w: float):\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def get_count(self):\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def get_mean(self):\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def get_var(self):\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def get_std(self):\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def copy(self):\n",
        "        pass\n",
        "\n",
        "\n",
        "class ForgettingEstimator(ValueEstimator):\n",
        "    def __init__(self, decay: float, count: float=0.0, linear_sum: float=0.0, squared_sum: float=0.0, timestamp: int=0):\n",
        "        self.decay = decay\n",
        "        self.count = count\n",
        "        self.linear_sum = linear_sum\n",
        "        self.squared_sum = squared_sum\n",
        "        self.timestamp = timestamp\n",
        "\n",
        "    def update(self, v: float, t: int):\n",
        "        d = self.decay ** (t - self.timestamp)\n",
        "        self.count = d * self.count + 1\n",
        "        self.linear_sum = d * self.linear_sum + v\n",
        "        self.squared_sum = d * self.squared_sum + v**2\n",
        "\n",
        "        self.timestamp = t\n",
        "\n",
        "    def get_count(self):\n",
        "        return self.count\n",
        "\n",
        "    def get_mean(self):\n",
        "        if self.count == 0.0:\n",
        "            return float('NaN')\n",
        "        print(self.linear_sum, self.count)\n",
        "        return self.linear_sum / self.count\n",
        "\n",
        "    def get_var(self):\n",
        "        if self.count == 0.0:\n",
        "            return float('NaN')\n",
        "        return max(self.squared_sum / self.count - (self.linear_sum / self.count) ** 2, 0.0)\n",
        "\n",
        "    def get_std(self):\n",
        "        if self.count == 0.0:\n",
        "            return float('NaN')\n",
        "        return math.sqrt(self.get_var())\n",
        "\n",
        "    def copy(self):\n",
        "        return ForgettingEstimator(self.decay, self.count, self.linear_sum, self.squared_sum, self.timestamp)\n",
        "\n",
        "\n",
        "class DistributionEstimator(ValueEstimator):\n",
        "\n",
        "    @abstractmethod\n",
        "    def get_cdf(self, x: float):\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def get_pdf(self, x: float):\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def split(self, **kwargs):\n",
        "        pass\n",
        "\n",
        "\n",
        "class GaussianEstimator(DistributionEstimator):\n",
        "    def __init__(self, count: float=0.0, mean: float=0.0, var: float=0.0, std: float=0.0):\n",
        "        self.count = count\n",
        "        self.mean = mean\n",
        "        self.var = var\n",
        "        self.std = std\n",
        "\n",
        "    def update(self, v: float, w: float):\n",
        "        pm = self.mean\n",
        "        self.count += w\n",
        "        self.mean = pm + (w / self.count) * (v - pm)\n",
        "        self.var = self.var + w * (v - pm) * (v - self.mean)\n",
        "        self.std = math.sqrt(self.var / self.count)\n",
        "\n",
        "    def get_count(self):\n",
        "        return self.count\n",
        "\n",
        "    def get_mean(self):\n",
        "        return self.mean\n",
        "\n",
        "    def get_var(self):\n",
        "        return self.var\n",
        "\n",
        "    def get_std(self):\n",
        "        return self.std\n",
        "\n",
        "    def get_cdf(self, x: float):\n",
        "        z = (x - self.mean) / self.std\n",
        "        return (1.0 + math.erf(z / SQ2)) / 2.0\n",
        "\n",
        "    def get_pdf(self, x: float):\n",
        "        if self.std == 0:\n",
        "            return 1.0 if x == self.mean else 0.0\n",
        "\n",
        "        z = (x - self.mean) / self.std\n",
        "        return math.exp(-0.5 * z * z) / (NC * self.std)\n",
        "\n",
        "    def split(self, **kwargs):\n",
        "        return GaussianEstimator(self.count, self.mean, self.var, self.std), \\\n",
        "               GaussianEstimator(self.count, self.mean, self.var, self.std)\n",
        "\n",
        "    def copy(self):\n",
        "        return GaussianEstimator(self.count, self.mean, self.var, self.std)\n",
        "\n",
        "\n",
        "class Statistics:\n",
        "    def __init__(self, atts: list, num_cls: int, estimator_creator: Callable[[], DistributionEstimator], att_split_est=False,\n",
        "                 cls_counts=None, att_stats=None, att_extr_stats=None):\n",
        "        self.atts = atts\n",
        "        self.att_map = {att_idx: i for i, att_idx in enumerate(self.atts)}\n",
        "        self.num_cls = num_cls\n",
        "        self.estimator_creator = estimator_creator\n",
        "        self.att_split_est = att_split_est\n",
        "\n",
        "        self.att_stats = att_stats if att_stats is not None else [[self.estimator_creator() for _ in range(num_cls)] for _ in range(len(self.atts))]\n",
        "        self.att_extr_stats = att_extr_stats if att_extr_stats is not None else np.array([[float('inf'), float('-inf')] for _ in range(len(self.atts))])\n",
        "        self.cls_counts = cls_counts if cls_counts is not None else np.zeros(num_cls)\n",
        "        self.all_count = self.cls_counts.sum()\n",
        "\n",
        "    def update(self, x, y: int, w: float):\n",
        "        self.cls_counts = CollectionUtils.ensure_arr_size(self.cls_counts, y)\n",
        "        self.att_stats = CollectionUtils.ensure_list2d_size(self.att_stats, y, self.estimator_creator)\n",
        "        self.num_cls = max(self.num_cls, y + 1)\n",
        "\n",
        "        self.all_count += w\n",
        "        self.cls_counts[y] += w\n",
        "\n",
        "        for i, att_idx in enumerate(self.atts):\n",
        "            self.att_stats[i][y].update(x[att_idx], w)\n",
        "            self.att_extr_stats[i][0] = min(self.att_extr_stats[i][0], x[att_idx])\n",
        "            self.att_extr_stats[i][1] = max(self.att_extr_stats[i][1], x[att_idx])\n",
        "\n",
        "    def get_estimator(self, att_idx: int, cls_idx: int):\n",
        "        return self.att_stats[self.att_map[att_idx]][cls_idx]\n",
        "\n",
        "    def get_cls_count(self, cls_idx: int=-1):\n",
        "        return self.all_count if cls_idx < 0 else self.cls_counts[cls_idx]\n",
        "\n",
        "    def get_att_extr(self, att_idx: int):\n",
        "        return self.att_extr_stats[self.att_map[att_idx]]\n",
        "\n",
        "    def get_stats(self):\n",
        "        return self.cls_counts, self.att_stats, self.att_extr_stats\n",
        "\n",
        "    def split(self, split_att_idx: int, s: float, l_prob, r_prob):\n",
        "        l_cls_counts, r_cls_counts = self.all_count * l_prob, self.all_count * r_prob\n",
        "        l_att_stats, r_att_stats = None, None\n",
        "        l_att_extr, r_att_extr = None, None\n",
        "\n",
        "        if self.att_split_est:\n",
        "            l_att_stats, r_att_stats = [], []\n",
        "            for i, att_idx in enumerate(self.atts):\n",
        "                lstats, rstats = [], []\n",
        "\n",
        "                for cls_idx in range(self.num_cls):\n",
        "                    lest, rest = self.get_estimator(i, cls_idx).split(lc=l_cls_counts[cls_idx], rc=r_cls_counts[cls_idx])\n",
        "                    lstats.append(lest)\n",
        "                    rstats.append(rest)\n",
        "\n",
        "                l_att_stats.append(lstats)\n",
        "                r_att_stats.append(rstats)\n",
        "\n",
        "            l_att_extr, r_att_extr = copy.deepcopy(self.att_extr_stats), copy.deepcopy(self.att_extr_stats)\n",
        "            l_att_extr[split_att_idx][1] = s\n",
        "            r_att_extr[split_att_idx][0] = s\n",
        "\n",
        "        return Statistics(self.atts, self.num_cls, self.estimator_creator, self.att_split_est, l_cls_counts, l_att_stats, l_att_extr), \\\n",
        "               Statistics(self.atts, self.num_cls, self.estimator_creator, self.att_split_est, r_cls_counts, r_att_stats, r_att_extr)\n",
        "\n",
        "    @staticmethod\n",
        "    def calc_split_weighted_entropy(stats, att_idx: int, s: float, num_cls: int):\n",
        "        l_prob, r_prob = np.zeros(num_cls), np.zeros(num_cls)\n",
        "        lp_sum, rp_sum = 0.0, 0.0\n",
        "\n",
        "        for cls_idx in range(num_cls):\n",
        "            est = stats.get_estimator(att_idx, cls_idx)\n",
        "\n",
        "            if est.get_count() == 0:\n",
        "                continue\n",
        "            elif est.get_var() == 0:\n",
        "                lp = 1.0 if s >= est.get_mean() else 0.0\n",
        "            else:\n",
        "                lp = est.get_cdf(s)\n",
        "\n",
        "            lp_sum += lp\n",
        "            rp = 1.0 - lp\n",
        "            rp_sum += rp\n",
        "\n",
        "            cp = stats.get_cls_count(cls_idx) / stats.get_cls_count()\n",
        "            l_prob[cls_idx] = lp * cp\n",
        "            r_prob[cls_idx] = rp * cp\n",
        "\n",
        "        wl, wr = l_prob.sum(), r_prob.sum()\n",
        "        l_ent = entropy(CalculationsUtils.div_tensor(l_prob, lp_sum)) if wl > 0.0 else 0.0\n",
        "        r_ent = entropy(CalculationsUtils.div_tensor(r_prob, rp_sum)) if wr > 0.0 else 0.0\n",
        "        ent = wl * l_ent + wr * r_ent\n",
        "\n",
        "        return ent, l_prob, r_prob"
      ],
      "metadata": {
        "id": "KhoScDSbK_HK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikit-multiflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBVWYx2SLA_G",
        "outputId": "883c8341-2be1-4631-cfae-628d0851b472"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-multiflow\n",
            "  Downloading scikit_multiflow-0.5.3-cp37-cp37m-manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 30.8 MB/s eta 0:00:01\r\u001b[K     |▋                               | 20 kB 38.8 MB/s eta 0:00:01\r\u001b[K     |▉                               | 30 kB 41.2 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40 kB 44.8 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51 kB 36.2 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 61 kB 40.2 MB/s eta 0:00:01\r\u001b[K     |██                              | 71 kB 27.9 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 81 kB 28.7 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 92 kB 30.7 MB/s eta 0:00:01\r\u001b[K     |███                             | 102 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 112 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 122 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 133 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |████                            | 143 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 153 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 163 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |█████                           | 174 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 184 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 194 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 204 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 215 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 225 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 235 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |███████                         | 245 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 256 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 266 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |████████                        | 276 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 286 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 296 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 307 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 317 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 327 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 337 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 348 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 358 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 368 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 378 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 389 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 399 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 409 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 419 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 430 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 440 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 450 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 460 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 471 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 481 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 491 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 501 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 512 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 522 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 532 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 542 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 552 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 563 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 573 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 583 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 593 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 604 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 614 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 624 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 634 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 645 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 655 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 665 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 675 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 686 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 696 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 706 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 716 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 727 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 737 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 747 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 757 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 768 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 778 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 788 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 798 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 808 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 819 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 829 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 839 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 849 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 860 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 870 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 880 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 890 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 901 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 911 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 921 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 931 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 942 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 952 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 962 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 972 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 983 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 993 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.0 MB 32.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.0 MB 32.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.0 MB 32.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.0 MB 32.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.0 MB 32.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.1 MB 32.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.1 MB 32.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.1 MB 32.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.1 MB 32.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.1 MB 32.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.1 MB 32.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.1 MB 32.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1 MB 32.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from scikit-multiflow) (1.21.6)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-multiflow) (3.2.2)\n",
            "Requirement already satisfied: sortedcontainers>=1.5.7 in /usr/local/lib/python3.7/dist-packages (from scikit-multiflow) (2.4.0)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.7/dist-packages (from scikit-multiflow) (1.0.2)\n",
            "Requirement already satisfied: pandas>=0.25.3 in /usr/local/lib/python3.7/dist-packages (from scikit-multiflow) (1.3.5)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-multiflow) (1.4.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->scikit-multiflow) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->scikit-multiflow) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->scikit-multiflow) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->scikit-multiflow) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=2.0.0->scikit-multiflow) (4.2.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.3->scikit-multiflow) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=2.0.0->scikit-multiflow) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20->scikit-multiflow) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20->scikit-multiflow) (3.1.0)\n",
            "Installing collected packages: scikit-multiflow\n",
            "Successfully installed scikit-multiflow-0.5.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from utils.cls_utils import ClassificationUtils This is the 'ClassificationUtils' class\n",
        "\n",
        "import math\n",
        "\n",
        "from river.base import Classifier\n",
        "from skmultiflow.core import ClassifierMixin\n",
        "from torch import Tensor\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "# from core.clearn import ContinualLearner\n",
        "# from utils.calc_utils import CalculationsUtils\n",
        "# from utils.stat_utils import Statistics\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "class ClassificationUtils:\n",
        "\n",
        "    @staticmethod\n",
        "    def majority_class_prob(counts, all_count):\n",
        "        return np.zeros(len(counts)) if all_count == 0 else counts / all_count\n",
        "\n",
        "    @staticmethod\n",
        "    def naive_bayes_prob(x, stats: Statistics, use_prior=True):\n",
        "        probs = np.zeros(stats.num_cls, dtype=np.double)\n",
        "        if stats.get_cls_count() == 0: return probs\n",
        "        p = 0.0\n",
        "\n",
        "        for cls_idx in range(stats.num_cls):\n",
        "            prob = stats.get_cls_count(cls_idx) / stats.get_cls_count() if use_prior else 1.0\n",
        "\n",
        "            for att_idx in stats.atts:\n",
        "                pr = stats.get_estimator(att_idx, cls_idx).get_pdf(x[att_idx])\n",
        "                prob *= (pr if not np.isnan(pr) else 1.0)\n",
        "\n",
        "            p += prob\n",
        "            probs[cls_idx] = prob\n",
        "\n",
        "        return probs if p == 0.0 else probs / p\n",
        "\n",
        "    @staticmethod\n",
        "    def naive_bayes_log_prob(x, stats: Statistics, use_prior=True):\n",
        "        log_probs = np.zeros(stats.num_cls, dtype=np.double)\n",
        "        if stats.get_cls_count() == 0: return log_probs\n",
        "        lps, lp_max = [], float('-inf')\n",
        "\n",
        "        for cls_idx in range(stats.num_cls):\n",
        "            log_prob = CalculationsUtils.log(stats.get_cls_count(cls_idx) / stats.get_cls_count()) if use_prior else 0.0\n",
        "\n",
        "            for att_idx in stats.atts:\n",
        "                pr = stats.get_estimator(att_idx, cls_idx).get_pdf(x[att_idx])\n",
        "                log_prob += (CalculationsUtils.log(pr) if not np.isnan(pr) else 0.0)\n",
        "\n",
        "            lps.append(log_prob)\n",
        "            lp_max = max(lp_max, log_prob)\n",
        "            log_probs[cls_idx] = log_prob\n",
        "\n",
        "        # https://stats.stackexchange.com/questions/105602/example-of-how-the-log-sum-exp-trick-works-in-naive-bayes/253319#253319\n",
        "        lps_sum = 0.0\n",
        "        zero_prob_indices = []\n",
        "        for i, lp in enumerate(lps):\n",
        "            if lp != float('-inf'):\n",
        "                lps_sum += math.exp(lp - lp_max)\n",
        "            else:\n",
        "                zero_prob_indices.append(i)\n",
        "\n",
        "        if not (np.isfinite(lps_sum) and np.isfinite(lp_max)):\n",
        "            return np.zeros(stats.num_cls)\n",
        "\n",
        "        lps_sum = math.log(lps_sum)\n",
        "        lps_sum += lp_max\n",
        "\n",
        "        probs = np.exp(log_probs - lps_sum)\n",
        "        probs[zero_prob_indices] = 0.0\n",
        "\n",
        "        return probs"
      ],
      "metadata": {
        "id": "JReTa4vSLD4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ht.py Hoeffding Tree main code\n",
        "import math\n",
        "from scipy.stats import entropy\n",
        "import numpy as np\n",
        "\n",
        "# from core.clearn import ContinualLearner\n",
        "# from utils.cls_utils import ClassificationUtils as cu\n",
        "# from utils.stat_utils import Statistics, GaussianEstimator\n",
        "\n",
        "\n",
        "class HoeffdingTree(ContinualLearner):\n",
        "    def __init__(self, split_step=0.1, split_wait=100, hb_delta=0.01, tie_thresh=0.05, rnd=False, subspaces=False,\n",
        "                 att_split_est=False, log_prob=True, num_atts=0, num_cls=0):\n",
        "        super().__init__()\n",
        "        self.root = TreeNode(split_step, split_wait, hb_delta, tie_thresh, rnd, subspaces, None, None, att_split_est, log_prob,\n",
        "                             num_atts, num_cls)\n",
        "\n",
        "    def predict(self, x_batch):\n",
        "        return np.array([np.argmax(ya) for ya in self.predict_prob(x_batch)])\n",
        "\n",
        "    def predict_prob(self, x_batch):\n",
        "        return np.array([self.find_leaf(x).predict_prob(x) for x in x_batch], dtype=object)\n",
        "\n",
        "    def update(self, x_batch, y_batch, **kwargs):\n",
        "        weights = kwargs.get('weights', np.ones(len(y_batch)))\n",
        "        y_batch = y_batch.astype(int) if isinstance(y_batch, np.ndarray) else y_batch.int()\n",
        "\n",
        "        for x, y, w in zip(x_batch, y_batch, weights):\n",
        "            leaf = self.find_leaf(x)\n",
        "            leaf.update(x, y, w if w > 0.0 else 1.0)\n",
        "            leaf.attempt_split()\n",
        "\n",
        "    def find_leaf(self, x):\n",
        "        node = self.root\n",
        "        while not node.is_leaf:\n",
        "            att, thresh = node.split\n",
        "            node = node.left if x[att] <= thresh else node.right\n",
        "\n",
        "        return node\n",
        "\n",
        "\n",
        "class TreeNode:\n",
        "    def __init__(self, split_step=0.1, split_wait=100, hb_delta=0.01, tie_thresh=0.05, rnd=False, subspaces=False,\n",
        "                 split_atts=None, stats=None, att_split_est=False, log_prob=True, num_atts=0, num_cls=0):\n",
        "        self.is_leaf = True\n",
        "        self.left = None\n",
        "        self.right = None\n",
        "        self.split = (None, None)\n",
        "        self.split_step = split_step\n",
        "        self.split_wait = split_wait\n",
        "        self.last_split_try = 0.0\n",
        "        self.cnt = 0.0\n",
        "        self.hb_delta = hb_delta\n",
        "        self.tie_thresh = tie_thresh\n",
        "\n",
        "        self.mc_correct = 0.0\n",
        "        self.nb_correct = 0.0\n",
        "\n",
        "        self.rnd = rnd\n",
        "        self.subspaces = subspaces\n",
        "        self.split_atts = split_atts\n",
        "        self.att_split_est = att_split_est\n",
        "        self.log_prob = log_prob\n",
        "        self.nb_pred = ClassificationUtils.naive_bayes_log_prob if self.log_prob else ClassificationUtils.naive_bayes_prob\n",
        "\n",
        "        if num_atts > 0:\n",
        "            self.init(num_atts, num_cls, stats)\n",
        "        else:\n",
        "            self.num_atts = 0\n",
        "            self.num_cls = 0\n",
        "            self.split_atts = None\n",
        "            self.stat_atts = []\n",
        "            self.att_map = None\n",
        "            self.stats = None\n",
        "\n",
        "    def init(self, num_atts, num_cls, stats):\n",
        "        self.num_atts = num_atts\n",
        "        self.num_cls = num_cls\n",
        "\n",
        "        if self.rnd or (self.subspaces and self.split_atts is None):\n",
        "            self.split_atts = np.random.permutation(num_atts)[:int(math.sqrt(num_atts)) + 1]\n",
        "        elif not self.subspaces:\n",
        "            self.split_atts = np.arange(0, num_atts)\n",
        "\n",
        "        self.stat_atts = self.split_atts if not self.att_split_est else np.arange(0, num_atts)\n",
        "\n",
        "        if stats is not None:\n",
        "            s = stats.get_stats()\n",
        "            self.stats = Statistics(self.stat_atts, self.num_cls, GaussianEstimator, self.att_split_est, *s)\n",
        "        else:\n",
        "            self.stats = Statistics(self.stat_atts, self.num_cls, GaussianEstimator, self.att_split_est)\n",
        "\n",
        "    def update(self, x, y: int, w: float):\n",
        "        if not self.stats:\n",
        "            self.init(len(x), y + 1, None)\n",
        "\n",
        "        self.mc_correct += w * (np.argmax(self.stats.cls_counts) == y)\n",
        "        self.nb_correct += w * (np.argmax(self.nb_pred(x, self.stats)) == y)\n",
        "        self.cnt += w\n",
        "        self.stats.update(x, y, w)\n",
        "        self.num_cls = self.stats.num_cls\n",
        "\n",
        "    def predict_prob(self, x):\n",
        "        if not self.stats:\n",
        "            return np.zeros(1)\n",
        "        else:\n",
        "            maj_probs = ClassificationUtils.majority_class_prob(self.stats.cls_counts, self.stats.get_cls_count())\n",
        "            if self.mc_correct >= self.nb_correct:\n",
        "                return maj_probs\n",
        "\n",
        "            nb_probs = self.nb_pred(x, self.stats)\n",
        "            return nb_probs if np.any(nb_probs) else maj_probs\n",
        "\n",
        "    def attempt_split(self):\n",
        "        if self.cnt > 0 and self.cnt - self.last_split_try >= self.split_wait:\n",
        "            best_split = self.__find_best_att_split()\n",
        "            self.__try_best_split(best_split)\n",
        "\n",
        "    def __find_best_att_split(self):\n",
        "        best_split = (float('inf'), None, None, [], [])  # entropy, att idx, thresh val, left prob, right prob\n",
        "\n",
        "        for att_idx in self.split_atts:\n",
        "            mi, mx = np.around(self.stats.get_att_extr(att_idx), decimals=10)\n",
        "            step = (mx - mi) * self.split_step\n",
        "\n",
        "            s = mi + step\n",
        "            while s < mx:\n",
        "                ent, l_prob, r_prob = Statistics.calc_split_weighted_entropy(self.stats, att_idx, s, self.num_cls)\n",
        "                if ent < best_split[0]:\n",
        "                    best_split = [ent, att_idx, s, l_prob, r_prob]\n",
        "\n",
        "                s += step\n",
        "\n",
        "        return best_split\n",
        "\n",
        "    def __try_best_split(self, best_split):\n",
        "        if best_split[1] is None: return\n",
        "        n = self.stats.get_cls_count()\n",
        "        curr_entropy = entropy(self.stats.cls_counts / n)\n",
        "        hb = self.hb(math.log(self.num_cls), self.hb_delta, n)\n",
        "\n",
        "        if curr_entropy - best_split[0] > hb or hb < self.tie_thresh:\n",
        "            _, att_idx, thresh, l_prob, r_prob = best_split\n",
        "            self.split = (att_idx, thresh)\n",
        "\n",
        "            l_stats, r_stats = self.stats.split(att_idx, thresh, l_prob, r_prob)\n",
        "\n",
        "            self.left = TreeNode(self.split_step, self.split_wait, self.hb_delta, self.tie_thresh, self.rnd, self.subspaces,\n",
        "                                 self.split_atts, l_stats, self.att_split_est, self.log_prob, self.num_atts, self.num_cls)\n",
        "            self.right = TreeNode(self.split_step, self.split_wait, self.hb_delta, self.tie_thresh, self.rnd, self.subspaces,\n",
        "                                  self.split_atts, r_stats, self.att_split_est, self.log_prob, self.num_atts, self.num_cls)\n",
        "\n",
        "            self.is_leaf = False\n",
        "            self.stats = None\n",
        "\n",
        "        self.last_split_try = self.cnt\n",
        "\n",
        "    @staticmethod\n",
        "    def hb(r, delta, n):\n",
        "        return math.sqrt((r * r * math.log(1.0 / delta)) / (2.0 * n))"
      ],
      "metadata": {
        "id": "Tqdf4RrvLHeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "irf.py"
      ],
      "metadata": {
        "id": "Jp7Ym8auLJJl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import random\n",
        "from collections import Counter\n",
        "\n",
        "from skmultiflow.drift_detection import ADWIN\n",
        "import numpy as np\n",
        "import ray\n",
        "\n",
        "# from core.clearn import ContinualLearner\n",
        "# from learners.ht import HoeffdingTree\n",
        "# from utils.calc_utils import CalculationsUtils\n",
        "# from utils.coll_utils import CollectionUtils\n",
        "\n",
        "\n",
        "class IncrementalRandomForest(ContinualLearner):\n",
        "\n",
        "    def __init__(self, size: int, lambda_val=5.0, split_step=0.1, split_wait=100, hb_delta=0.01, tie_thresh=0.05,\n",
        "                 rnd=True, subspaces=False, att_split_est=False, log_prob=True, num_atts=0, num_cls=0, num_workers=1):\n",
        "        super().__init__()\n",
        "        self.size = size\n",
        "        self.lambda_val = lambda_val\n",
        "        self.tree_groups = []\n",
        "        self.num_par_groups = num_workers\n",
        "        self.par = self.num_par_groups > 1\n",
        "        self.init_tree_groups([0, split_step, split_wait, hb_delta, tie_thresh, rnd, subspaces, att_split_est, log_prob,\n",
        "                               num_atts, num_cls])\n",
        "\n",
        "    def init_tree_groups(self, tree_params: list):\n",
        "        trees_per_group, r = math.ceil(self.size / self.num_par_groups), self.size\n",
        "        while r > 0:\n",
        "            tree_params[0] = min(r, trees_per_group)\n",
        "            self.tree_groups.append(RemoteTreeGroupWrapper(*tree_params) if self.par else TreeGroup(*tree_params))\n",
        "            r -= trees_per_group\n",
        "\n",
        "    def predict(self, x_batch):\n",
        "        return np.array([np.argmax(ya) for ya in self.predict_prob(x_batch)])\n",
        "\n",
        "    def predict_prob(self, x_batch):\n",
        "        weights = self.fetch([tg.get_weights() for tg in self.tree_groups])\n",
        "        ws = sum([sum(w) for w in weights])\n",
        "\n",
        "        probs = self.fetch([tg.predict_prob(x_batch) for tg in self.tree_groups])\n",
        "        trees_batch_probs = CollectionUtils.flatten_list(probs)\n",
        "        probs_sum = [CalculationsUtils.sum_arrays([tree_probs[i] for tree_probs in trees_batch_probs]) for i in range(len(x_batch))]\n",
        "\n",
        "        return np.array(probs_sum, dtype=object) / ws\n",
        "\n",
        "    def update(self, x_batch, y_batch, **kwargs):\n",
        "        weights = kwargs.get('weights', np.ones(len(y_batch)))\n",
        "\n",
        "        for tree_group in self.tree_groups:\n",
        "            tree_group.update_trees(x_batch, y_batch, self.lambda_val, weights)\n",
        "\n",
        "    def get_tree_group(self, idx):\n",
        "        return self.tree_groups[idx].get_trees()\n",
        "\n",
        "    def fetch(self, obj):\n",
        "        return obj if not self.par else ray.get(obj)\n",
        "\n",
        "\n",
        "class TreeGroup:\n",
        "\n",
        "    def __init__(self, size: int, split_step=0.1, split_wait=100, hb_delta=0.01, tie_thresh=0.05, rnd=True, subspaces=False,\n",
        "                 att_split_est=False, log_prob=True, num_atts=0, num_cls=0):\n",
        "        self.trees = [\n",
        "            ForestHoeffdingTree(split_step, split_wait, hb_delta, tie_thresh, rnd, subspaces, att_split_est, log_prob, num_atts, num_cls)\n",
        "            for _ in range(size)\n",
        "        ]\n",
        "\n",
        "    def get_weights(self):\n",
        "        return [tree.get_weight() for tree in self.trees]\n",
        "\n",
        "    def predict_prob(self, x_batch):\n",
        "        return [tree.predict_prob(x_batch) for tree in self.trees]\n",
        "\n",
        "    def update_trees(self, x_batch, y_batch, lambda_val, weights):\n",
        "        for tree in self.trees:\n",
        "            k = np.random.poisson(lambda_val, len(x_batch))\n",
        "            tree.update(x_batch, y_batch, weights=np.multiply(weights, k))\n",
        "\n",
        "    def get_trees(self):\n",
        "        return self.trees\n",
        "\n",
        "\n",
        "class ForestHoeffdingTree(HoeffdingTree):\n",
        "\n",
        "    def __init__(self, split_step=0.1, split_wait=100, hb_delta=0.01, tie_thresh=0.05, rnd=True, subspaces=False, att_split_est=False,\n",
        "                 log_prob=True, num_atts=0, num_cls=0):\n",
        "        super().__init__(split_step, split_wait, hb_delta, tie_thresh, rnd, subspaces, att_split_est, log_prob, num_atts, num_cls)\n",
        "        self.quality = ADWIN()\n",
        "\n",
        "    def update(self, x_batch, y_batch, **kwargs):\n",
        "        preds = super().predict(x_batch)\n",
        "        for p, y in zip(preds, y_batch): self.quality.add_element(int(int(p) == int(y)))\n",
        "        super().update(x_batch, y_batch, **kwargs)\n",
        "\n",
        "    def predict_prob(self, x_batch):\n",
        "        return self.get_weight() * np.array([self.find_leaf(x).predict_prob(x) for x in x_batch], dtype=object)\n",
        "\n",
        "    def get_weight(self):\n",
        "        return self.quality.estimation if self.quality.total > 0 else 1.0\n",
        "\n",
        "\n",
        "@ray.remote\n",
        "class RemoteTreeGroup(TreeGroup):\n",
        "\n",
        "    def __init__(self, size: int, split_step=0.1, split_wait=100, hb_delta=0.01, tie_thresh=0.05, bag=False, subspaces=False,\n",
        "                 att_split_est=False, log_prob=True, num_atts=0, num_cls=0):\n",
        "        super().__init__(size, split_step, split_wait, hb_delta, tie_thresh, bag, subspaces, att_split_est, log_prob, num_atts, num_cls)\n",
        "\n",
        "\n",
        "class RemoteTreeGroupWrapper:\n",
        "\n",
        "    def __init__(self, *remote_tree_group_args):\n",
        "        self.remote_tree_group = RemoteTreeGroup.remote(*remote_tree_group_args)\n",
        "\n",
        "    def get_weights(self):\n",
        "        return self.remote_tree_group.get_weights.remote()\n",
        "\n",
        "    def predict_prob(self, x_batch):\n",
        "        return self.remote_tree_group.predict_prob.remote(x_batch)\n",
        "\n",
        "    def update_trees(self, x_batch, y_batch, lambda_val, weights):\n",
        "        self.remote_tree_group.update_trees.remote(x_batch, y_batch, lambda_val, weights)\n",
        "\n",
        "    def get_trees(self):\n",
        "        return self.remote_tree_group.get_trees.remote()"
      ],
      "metadata": {
        "id": "ese8nofjLMSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#utils/coll_utils.py /\n",
        "\n",
        "import itertools\n",
        "from functools import reduce\n",
        "from typing import Callable\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class CollectionUtils:\n",
        "\n",
        "    @staticmethod\n",
        "    def ensure_arr_size(arr: np.ndarray, y: int):\n",
        "        if len(arr.shape) == 1:\n",
        "            return np.hstack((arr, np.zeros(y - len(arr) + 1))) if len(arr) - 1 < y else arr\n",
        "        else:\n",
        "            return np.hstack((arr, np.zeros((arr.shape[0], y - arr.shape[1] + 1, arr.shape[2])))) if arr.shape[1] - 1 < y else arr\n",
        "\n",
        "    @staticmethod\n",
        "    def ensure_list2d_size(lst: list, y: int, element_creator: Callable[[], any]):\n",
        "        if len(lst[0]) > y:\n",
        "            return lst\n",
        "\n",
        "        for l in lst:\n",
        "            l_len = len(l) - 1\n",
        "            for _ in range(y - l_len):\n",
        "                l.append(element_creator())\n",
        "\n",
        "        return lst\n",
        "\n",
        "    @staticmethod\n",
        "    def split_list(lst, chunk_size: int):\n",
        "        return [lst[i:i + chunk_size] for i in range(0, len(lst), chunk_size)]\n",
        "\n",
        "    @staticmethod\n",
        "    def flatten_list(lst):\n",
        "        return list(itertools.chain.from_iterable(lst))"
      ],
      "metadata": {
        "id": "9YxCoTnFLPH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # data_labels.py\n",
        "\n",
        "# import csv\n",
        "\n",
        "# from torch.utils.data import Dataset\n",
        "\n",
        "# #import data.data_collection as data_col\n",
        "\n",
        "\n",
        "# class DataLabelsUtils:\n",
        "\n",
        "#     @staticmethod\n",
        "#     def get_dataset_labels(dataset: Dataset):\n",
        "#         return dataset.classes if hasattr(dataset, 'classes') else None\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "# cls_names = {\n",
        "#     'FASHION': lambda: ['T-shirt/top', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot'],\n",
        "#     'CIFAR10': lambda: DataLabelsUtils.get_dataset_labels(data_collection.get('CIFAR10-TRAIN')),\n",
        "#     'CIFAR20C': lambda: DataLabelsUtils.get_dataset_labels(data_collection.get('CIFAR20C-TRAIN')),\n",
        "#     'CIFAR100': lambda: DataLabelsUtils.get_dataset_labels(data_collection.get('CIFAR100-TRAIN')),\n",
        "    \n",
        "# }\n",
        "\n",
        "\n",
        "# def get_cls_names(name: str):\n",
        "#     return cls_names[name]()"
      ],
      "metadata": {
        "id": "ZhoOgDJdLRu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#stream.py\n",
        "import random\n",
        "from typing import Dict\n",
        "import numpy as np\n",
        "from numpy.random.mtrand import RandomState\n",
        "from torch.utils.data import Dataset, Subset\n",
        "from abc import ABC\n",
        "\n",
        "# from data.data_utils import IndexDataset, DataUtils\n",
        "# from utils.coll_utils import CollectionUtils\n",
        "\n",
        "\n",
        "class Stream(ABC):\n",
        "    def __init__(self, cls_names: list = None):\n",
        "        self.cls_names = cls_names if cls_names is not None else []\n",
        "\n",
        "\n",
        "class InstanceStream(Stream):\n",
        "\n",
        "    def __init__(self, dataset: Dataset, order=None, frac=1.0, shuffle=False, cls_names: list = None, init_frac: float = 0.0):\n",
        "        super().__init__(cls_names)\n",
        "        if order:\n",
        "            data_indices = order\n",
        "        else:\n",
        "            data_indices = list(RandomState(0).permutation(len(dataset))) if shuffle else np.arange(len(dataset))\n",
        "\n",
        "        if frac < 1.0:\n",
        "            indices = random.sample(range(len(data_indices)), int(frac * len(data_indices)))\n",
        "            data_indices = [data_indices[i] for i in sorted(indices)]\n",
        "\n",
        "        init_indices = []\n",
        "        if init_frac > 0.0:\n",
        "            f = int(init_frac * len(data_indices))\n",
        "            init_indices, data_indices = data_indices[:f], data_indices[f:]\n",
        "\n",
        "        self.init_data = Subset(dataset, init_indices)\n",
        "        self.data = Subset(dataset, data_indices)\n",
        "\n",
        "    def get_init_data(self):\n",
        "        return self.init_data\n",
        "\n",
        "    def get_data(self):\n",
        "        return self.data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "class ClassStream(Stream):\n",
        "\n",
        "    def __init__(self, train_dataset: Dataset, test_dataset: Dataset=None, class_size: int=1, class_frac: float=1.0,\n",
        "                 class_batch_seq: list=None, test_frac: float=0.2, max_cls_num=-1, cls_names: list=None, init_data: Dict=None):\n",
        "        super().__init__(cls_names)\n",
        "\n",
        "        if not test_dataset:\n",
        "            indices = list(RandomState(0).permutation(len(train_dataset)))\n",
        "            f = int(test_frac * len(indices))\n",
        "            test_dataset = Subset(train_dataset, indices[:f])\n",
        "            train_dataset = Subset(train_dataset, indices[f:])\n",
        "\n",
        "        train_class_batch = self.create_class_batches(train_dataset, class_size, class_batch_seq, max_cls_num)\n",
        "\n",
        "        init_indices, init_class_concept_mapping = [], {}\n",
        "        cf = class_frac\n",
        "        random.seed(0)\n",
        "\n",
        "        if init_data is not None:\n",
        "            for class_batch_idx, frac in init_data.items():\n",
        "                class_idx, class_batch_indices, class_concept_mapping = train_class_batch[class_batch_idx]\n",
        "\n",
        "                f = int(frac * len(class_batch_indices))\n",
        "                train_class_batch[class_batch_idx] = (class_idx, class_batch_indices[f:], class_concept_mapping)\n",
        "\n",
        "                init_indices.extend(class_batch_indices[:f])\n",
        "                init_class_concept_mapping.update(class_concept_mapping)\n",
        "\n",
        "        self.init_data = (init_class_concept_mapping, Subset(train_dataset, init_indices if cf == 1.0 else random.sample(init_indices, int(cf * len(init_indices)))))\n",
        "\n",
        "        self.train_data = [(class_idx, Subset(train_dataset, indices if cf == 1.0 else random.sample(indices, int(cf * len(indices)))), class_concept_mapping)\n",
        "                           for class_idx, indices, class_concept_mapping in train_class_batch]\n",
        "\n",
        "        test_class_batch = self.create_class_batches(test_dataset, class_size, class_batch_seq, -1)\n",
        "        self.test_data = [(class_idx, Subset(test_dataset, indices if cf == 1.0 else random.sample(indices, int(cf * len(indices)))), class_concept_mapping)\n",
        "                          for class_idx, indices, class_concept_mapping in test_class_batch]\n",
        "\n",
        "    def get_init_data(self):\n",
        "        return self.init_data\n",
        "\n",
        "    def get_train_data(self):\n",
        "        return self.train_data\n",
        "\n",
        "    def get_test_data(self):\n",
        "        return self.test_data\n",
        "\n",
        "    @staticmethod\n",
        "    def create_class_batches(dataset, class_size, class_batch_seq, max_cls_num):\n",
        "        indices_per_class = DataUtils.get_class_indices(IndexDataset(dataset))\n",
        "\n",
        "        if not class_batch_seq:\n",
        "            input_classes = sorted(list(indices_per_class.keys()))\n",
        "            class_batch_seq = CollectionUtils.split_list(input_classes, class_size)\n",
        "\n",
        "            for i, subclasses in enumerate(class_batch_seq):\n",
        "                class_batch_seq[i] = (i, subclasses, {c: i for c in subclasses})\n",
        "\n",
        "        indices_per_class_batch = [(class_idx, CollectionUtils.flatten_list([indices_per_class[cls] for cls in classes]), concept_mapping)\n",
        "                                   for i, (class_idx, classes, concept_mapping) in enumerate(class_batch_seq)]\n",
        "\n",
        "        if max_cls_num > -1:\n",
        "            for i, b in enumerate(indices_per_class_batch):\n",
        "                indices_per_class_batch[i] = (b[0], b[1][:max_cls_num], b[2])\n",
        "\n",
        "        return indices_per_class_batch"
      ],
      "metadata": {
        "id": "VDthe_PMLUsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plt_utils.py \n",
        "import matplotlib.pyplot as plt\n",
        "import io\n",
        "import tensorflow as tf\n",
        "import itertools\n",
        "import numpy as np\n",
        "import matplotlib.colors as mcolors\n",
        "\n",
        "\n",
        "class PlotUtils:\n",
        "\n",
        "    @staticmethod\n",
        "    def create_image_grid(images, labels, cls_names):\n",
        "        figure = plt.figure(figsize=(20, 20))\n",
        "        rows, cols = (10, 10) if len(images) == 100 else (5, 5)\n",
        "\n",
        "        for i in range(min(rows * cols, len(images))):\n",
        "            cls_idx = labels[i].item()\n",
        "            plt.subplot(rows, cols, i + 1, title=cls_names[cls_idx] if len(cls_names) > cls_idx else cls_idx)\n",
        "            plt.xticks([])\n",
        "            plt.yticks([])\n",
        "            plt.grid(False)\n",
        "            plt.imshow(images[i])\n",
        "\n",
        "        return figure\n",
        "\n",
        "    @staticmethod\n",
        "    def fig_to_image(figure):\n",
        "        buf = io.BytesIO()\n",
        "        plt.savefig(buf, format='png')\n",
        "        plt.close(figure)\n",
        "\n",
        "        buf.seek(0)\n",
        "        image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
        "        image = tf.expand_dims(image, 0)\n",
        "\n",
        "        return image\n",
        "\n",
        "    @staticmethod\n",
        "    def create_confusion_matrix(cm, class_names, title=None):\n",
        "        figure = plt.figure(figsize=(8, 8))\n",
        "\n",
        "        colors = plt.cm.Blues(np.linspace(0, 1, 128))\n",
        "        cmap = mcolors.LinearSegmentedColormap.from_list('colormap', colors)\n",
        "\n",
        "        plt.imshow(cm, interpolation='nearest', cmap=cmap if len(cm) > 1 else plt.cm.Blues_r)\n",
        "        if title: plt.title(title, fontsize=24, pad=16)\n",
        "\n",
        "        tick_marks = np.arange(len(class_names))\n",
        "        plt.xticks(tick_marks, class_names, rotation=45, fontsize=12)\n",
        "        plt.yticks(tick_marks, class_names, fontsize=12)\n",
        "\n",
        "        labels = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
        "\n",
        "        threshold = cm.max() / 2.\n",
        "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "            color = 'white' if cm[i, j] > threshold else 'black'\n",
        "            plt.text(j, i, labels[i, j], horizontalalignment='center', color=color)\n",
        "\n",
        "        plt.ylabel('True label', fontsize=16, labelpad=20)\n",
        "        plt.xlabel('Predicted label', fontsize=16, labelpad=20)\n",
        "\n",
        "        return figure"
      ],
      "metadata": {
        "id": "_W8hMhxqLZoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tf_writers.py\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import sklearn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "#from utils.plt_utils import PlotUtils as pu\n",
        "\n",
        "\n",
        "class TBScalars:\n",
        "\n",
        "    @staticmethod\n",
        "    def write_epoch_result(tasks_acc, epoch, stream_label, i):\n",
        "        tf.summary.scalar(f'{stream_label}#EPOCHS/C{i}', sum(tasks_acc) / len(tasks_acc), epoch,\n",
        "                          description='x=epochs, y=overall accuracy')\n",
        "        tf.summary.flush()\n",
        "\n",
        "    @staticmethod\n",
        "    def write_tasks_results(stream_label, tasks_acc, i):\n",
        "        for j, acc in enumerate(tasks_acc):\n",
        "            tf.summary.scalar(f'{stream_label}/C{j}', acc, i,\n",
        "                              description='x=class ids, y=accuracy for a given Ci')  # todo: add configurable class-aggregation?\n",
        "\n",
        "        tf.summary.scalar(f'ALL/{stream_label}', sum(tasks_acc) / len(tasks_acc), i,\n",
        "                          description='x=class ids, y=overall accuracy')\n",
        "        tf.summary.flush()\n",
        "\n",
        "\n",
        "class TBImages:\n",
        "\n",
        "    @staticmethod\n",
        "    def write_test_data(data: Dataset, i: int, stream_label: str, cls_names: list):\n",
        "        loader = DataLoader(data, batch_size=100, shuffle=True)\n",
        "\n",
        "        images, labels = next(iter(loader))\n",
        "        images = np.transpose(images.reshape(*images.shape), (0, 2, 3, 1))\n",
        "        figure = PlotUtils.create_image_grid(images, labels, cls_names)\n",
        "\n",
        "        tf.summary.image(f'{stream_label}#EXAMPLES', PlotUtils.fig_to_image(figure), step=i)\n",
        "        tf.summary.flush()\n",
        "\n",
        "    @staticmethod\n",
        "    def write_confusion_matrices(labels, preds, i, stream_label):\n",
        "        cm = sklearn.metrics.confusion_matrix(labels, preds)\n",
        "        cm[np.isnan(cm)] = 0.0\n",
        "\n",
        "        figure = PlotUtils.create_confusion_matrix(cm, class_names=[f'C{k}' for k in range(len(cm))])\n",
        "\n",
        "        tf.summary.image(f'{stream_label}#CONF-MATS', PlotUtils.fig_to_image(figure), step=i)\n",
        "        tf.summary.flush()\n",
        "\n",
        "        return cm\n"
      ],
      "metadata": {
        "id": "PCEWo78eLcVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# eval.py\n",
        "import collections\n",
        "import copy\n",
        "import os\n",
        "\n",
        "import torch\n",
        "from typing import Callable\n",
        "from abc import ABC, abstractmethod\n",
        "from skmultiflow.drift_detection import ADWIN\n",
        "from torch import Tensor\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import torch.utils.tensorboard as tb\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "#from core.clearn import ContinualLearner\n",
        "#from data.stream import Stream, InstanceStream, ClassStream\n",
        "#from eval.tf_writers import TBScalars, TBImages\n",
        "\n",
        "\n",
        "class Evaluator(ABC):\n",
        "\n",
        "    @abstractmethod\n",
        "    def evaluate(self, model_creator: (str, Callable[[], ContinualLearner]), data_creator: (str, Callable[[], Stream])):\n",
        "        pass\n",
        "\n",
        "\n",
        "class InstanceStreamEvaluator(Evaluator):\n",
        "\n",
        "    def __init__(self, batch_size: int, shuffle=False, init_skip_frac=0.05, numpy=False, logdir_root: str='runs'):\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.init_skip_frac = init_skip_frac\n",
        "        self.numpy = numpy\n",
        "        self.logdir_root = logdir_root\n",
        "\n",
        "    def evaluate(self, model_creator: (str, Callable[[], ContinualLearner]), data_creator: (str, Callable[[], Stream])):\n",
        "        model_label, model_creator = model_creator\n",
        "        stream_label, stream_creator = data_creator\n",
        "\n",
        "        print('[1/3] Preparing data')\n",
        "        instance_stream: InstanceStream = stream_creator()\n",
        "        instance_stream_loader = DataLoader(instance_stream.get_data(), batch_size=self.batch_size, shuffle=self.shuffle)\n",
        "\n",
        "        print('[2/3] Preparing model')\n",
        "        model = model_creator()\n",
        "\n",
        "        init_data = instance_stream.get_init_data()\n",
        "        n = len(init_data)\n",
        "        if n > 0:\n",
        "            print(f'Initializing model with {n} instances')\n",
        "            init_data_loader = DataLoader(init_data, batch_size=n, shuffle=self.shuffle)\n",
        "            inputs_batch, labels_batch = next(iter(init_data_loader))\n",
        "            if self.numpy: inputs_batch, labels_batch = inputs_batch.numpy(), labels_batch.numpy()\n",
        "            model.initialize(inputs_batch, labels_batch)\n",
        "\n",
        "        print('[3/3] Preparing metrics')\n",
        "        per_class_acc = {}\n",
        "        acc = ADWIN()\n",
        "        correct = 0.0\n",
        "        all = 0.0\n",
        "        init_skip_num = self.init_skip_frac * len(instance_stream)\n",
        "\n",
        "        logdir = f'{self.logdir_root}/{model_label}'\n",
        "        tb_writer = tb.SummaryWriter(logdir)\n",
        "\n",
        "        print('Evaluating...')\n",
        "        i = 0\n",
        "        for inputs_batch, labels_batch in tqdm(instance_stream_loader):\n",
        "            if self.numpy: inputs_batch, labels_batch = inputs_batch.numpy(), labels_batch.numpy()\n",
        "\n",
        "            i += len(inputs_batch)\n",
        "            preds = model.predict(inputs_batch)\n",
        "            model.update(inputs_batch, labels_batch)\n",
        "\n",
        "            results = [int(int(p) == int(y)) for p, y in zip(preds, labels_batch)]\n",
        "            correct += sum(results)\n",
        "            all += len(inputs_batch)\n",
        "\n",
        "            for r, l in zip(results, labels_batch):\n",
        "                acc.add_element(float(r))\n",
        "                l = int(l)\n",
        "\n",
        "                if l not in per_class_acc:\n",
        "                    per_class_acc[l] = ADWIN()\n",
        "                per_class_acc[l].add_element(float(r))\n",
        "\n",
        "            if i > init_skip_num:\n",
        "                tb_writer.add_scalar(f'ALL/{stream_label}', acc.estimation, i)\n",
        "\n",
        "                for c, c_acc in per_class_acc.items():\n",
        "                    tb_writer.add_scalar(f'{stream_label}/{stream_label}-C{c}', c_acc.estimation, i)\n",
        "\n",
        "\n",
        "class ClassStreamEvaluator(Evaluator):\n",
        "\n",
        "    def __init__(self, batch_size: int, shuffle: bool, num_epochs: int, num_workers: int, numpy=False, vis=True, logdir_root: str='runs'):\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.num_epochs = num_epochs\n",
        "        self.num_workers = num_workers\n",
        "        self.numpy = numpy\n",
        "        self.vis = vis\n",
        "        self.logdir_root = logdir_root\n",
        "\n",
        "    def evaluate(self, model_creator: (str, Callable[[], ContinualLearner]), data_creator: (str, Callable[[], Stream])):\n",
        "        model_label, model_creator = model_creator\n",
        "        stream_label, stream_creator = data_creator\n",
        "\n",
        "        print('[1/3] Preparing data')\n",
        "        class_stream: ClassStream = stream_creator()\n",
        "        train_class_stream = class_stream.get_train_data()\n",
        "        test_class_stream = iter(class_stream.get_test_data())\n",
        "\n",
        "        print('[2/3] Preparing model')\n",
        "        model = model_creator()\n",
        "\n",
        "        init_class_concept_mapping, init_data = class_stream.get_init_data()\n",
        "        n = len(init_data)\n",
        "        if n > 0:\n",
        "            print(f'Initializing model with {n} instances')\n",
        "            init_data_loader = DataLoader(init_data, batch_size=n, num_workers=self.num_workers, shuffle=self.shuffle)\n",
        "            inputs_batch, labels_batch = next(iter(init_data_loader))\n",
        "            labels_batch = Tensor([init_class_concept_mapping[int(cls.item())] for cls in labels_batch])\n",
        "            if self.numpy: inputs_batch, labels_batch = inputs_batch.numpy(), labels_batch.numpy()\n",
        "            model.initialize(inputs_batch, labels_batch)\n",
        "\n",
        "        print('[3/3] Preparing metrics')\n",
        "        logdir = f'{self.logdir_root}/{model_label}'\n",
        "        tb_file_writer = tf.summary.create_file_writer(logdir)\n",
        "        tb_file_writer.set_as_default()\n",
        "        classes_test_data = {}\n",
        "        class_test_concept_mapping = {}\n",
        "        results = collections.defaultdict(list)\n",
        "        cms = []\n",
        "\n",
        "        print('Evaluating...')\n",
        "        for i, class_batch_data in enumerate(tqdm(train_class_stream)):\n",
        "            (class_idx, class_batch_train_data, class_concept_mapping) = class_batch_data\n",
        "            (test_class_idx, class_batch_test_data, test_class_concept_mapping) = next(test_class_stream)\n",
        "\n",
        "            assert class_idx == test_class_idx and class_concept_mapping == test_class_concept_mapping\n",
        "            class_test_concept_mapping.update(class_concept_mapping)\n",
        "\n",
        "            classes_test_data[class_idx] = DataLoader(class_batch_test_data, batch_size=self.batch_size, num_workers=self.num_workers)  # todo: subclasses\n",
        "            if self.vis: TBImages.write_test_data(class_batch_test_data, i, stream_label, class_stream.cls_names)\n",
        "\n",
        "            for j in range(self.num_epochs):\n",
        "                train_data_loader = DataLoader(class_batch_train_data, batch_size=self.batch_size, num_workers=self.num_workers, shuffle=self.shuffle)\n",
        "                for inputs_batch, labels_batch in tqdm(train_data_loader):\n",
        "                    labels_batch = Tensor([class_concept_mapping[int(cls.item())] for cls in labels_batch])\n",
        "                    if self.numpy: inputs_batch, labels_batch = inputs_batch.numpy(), labels_batch.numpy()\n",
        "                    model.update(inputs_batch, labels_batch)\n",
        "\n",
        "                # tasks_acc, _ = evaluate_tasks(model, classes_test_data, class_test_concept_mapping, self.numpy)\n",
        "                # TBScalars.write_epoch_result(tasks_acc, j, stream_label, i)\n",
        "\n",
        "            tasks_acc, (task_targets, task_preds) = evaluate_tasks(model, classes_test_data, class_test_concept_mapping, self.numpy)\n",
        "\n",
        "            for k, task_acc in enumerate(tasks_acc): results[k + 1].append(task_acc)\n",
        "            results[0].append(sum(tasks_acc) / len(tasks_acc))\n",
        "\n",
        "            TBScalars.write_tasks_results(stream_label, tasks_acc, i)\n",
        "            cm = TBImages.write_confusion_matrices(task_targets, task_preds, i, stream_label)\n",
        "            if (i + 1) % 10 == 0: cms.append(cm)\n",
        "\n",
        "        #dumping the model here\n",
        "        #saving model\n",
        "\n",
        "        # Initialize model\n",
        "\n",
        "        model = ClassStreamEvaluator(batch_size=256, shuffle=True, num_epochs=1, num_workers=8)\n",
        "\n",
        "        # # Print model's state_dict\n",
        "        # print(\"Model's state_dict:\")\n",
        "        # for param_tensor in model.state_dict():\n",
        "        # print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
        "\n",
        "        pickle_save_path = '/content/drive/MyDrive/pth files/ll_dt_tree'\n",
        "        torch.save(model.state_dict(), pickle_save_path + 'lldt_pickle_1.pkl')\n",
        "        \n",
        "\n",
        "        #writing result on csv\n",
        "        write_result_to_file(model_label, stream_label, results, cms)\n",
        "\n",
        "\n",
        "class OfflineClassStreamEvaluator(Evaluator):\n",
        "\n",
        "    def __init__(self, batch_size: int, num_epochs: int, num_workers: int, numpy=False, vis=True, logdir_root: str='runs',\n",
        "                 model_path: str=None):\n",
        "        self.batch_size = batch_size\n",
        "        self.num_epochs = num_epochs\n",
        "        self.num_workers = num_workers\n",
        "        self.numpy = numpy\n",
        "        self.vis = vis\n",
        "        self.logdir_root = logdir_root\n",
        "        self.model_path = model_path\n",
        "\n",
        "    def evaluate(self, model_creator: (str, Callable[[], ContinualLearner]), data_creator: (str, Callable[[], Stream])):\n",
        "        model_label, model_creator = model_creator\n",
        "        stream_label, stream_creator = data_creator\n",
        "        model = None\n",
        "\n",
        "        print('[1/2] Preparing data')\n",
        "        class_stream: ClassStream = stream_creator()\n",
        "        train_class_stream = class_stream.get_train_data()\n",
        "        test_class_stream = iter(class_stream.get_test_data())\n",
        "\n",
        "        print('[2/2] Preparing metrics')\n",
        "        logdir = f'{self.logdir_root}/{model_label}'\n",
        "        tb_file_writer = tf.summary.create_file_writer(logdir)\n",
        "        tb_file_writer.set_as_default()\n",
        "        all_train_data = None\n",
        "        classes_test_data = {}\n",
        "        class_test_concept_mapping = {}\n",
        "        results = collections.defaultdict(list)\n",
        "        cms = []\n",
        "\n",
        "        print('Evaluating...')\n",
        "        for i, class_batch_data in enumerate(tqdm(train_class_stream)):\n",
        "            (class_idx, class_batch_train_data, class_concept_mapping) = class_batch_data\n",
        "            (test_class_idx, class_batch_test_data, test_class_concept_mapping) = next(test_class_stream)\n",
        "\n",
        "            assert class_idx == test_class_idx and class_concept_mapping == test_class_concept_mapping\n",
        "            class_test_concept_mapping.update(class_concept_mapping)\n",
        "\n",
        "            all_train_data = all_train_data + class_batch_train_data if all_train_data is not None else class_batch_train_data\n",
        "            all_train_data_loader = DataLoader(all_train_data, batch_size=self.batch_size, num_workers=self.num_workers,\n",
        "                                               shuffle=True)\n",
        "\n",
        "            classes_test_data[class_idx] = DataLoader(class_batch_test_data, batch_size=self.batch_size, num_workers=self.num_workers,\n",
        "                                             shuffle=True)\n",
        "            if self.vis: TBImages.write_test_data(class_batch_test_data, i, stream_label, class_stream.cls_names)\n",
        "\n",
        "            model = model_creator()\n",
        "\n",
        "            for j in tqdm(range(self.num_epochs)):\n",
        "                for inputs_batch, labels_batch in all_train_data_loader:\n",
        "                    labels_batch = Tensor([class_test_concept_mapping[int(cls.item())] for cls in labels_batch])\n",
        "                    if self.numpy: inputs_batch, labels_batch = inputs_batch.numpy(), labels_batch.numpy()\n",
        "                    model.update(inputs_batch, labels_batch)\n",
        "\n",
        "                if hasattr(model, 'scheduler') and model.scheduler is not None:\n",
        "                    model.scheduler.step()\n",
        "\n",
        "                tasks_acc, _ = evaluate_tasks(model, classes_test_data, class_test_concept_mapping, self.numpy)\n",
        "                TBScalars.write_epoch_result(tasks_acc, j, stream_label, i)\n",
        "\n",
        "            tasks_acc, (task_targets, task_preds) = evaluate_tasks(model, classes_test_data, class_test_concept_mapping, self.numpy)\n",
        "\n",
        "            for k, task_acc in enumerate(tasks_acc): results[k + 1].append(task_acc)\n",
        "            results[0].append(sum(tasks_acc) / len(tasks_acc))\n",
        "\n",
        "            TBScalars.write_tasks_results(stream_label, tasks_acc, i)\n",
        "            cm = TBImages.write_confusion_matrices(task_targets, task_preds, i, stream_label)\n",
        "            if (i + 1) % 10 == 0: cms.append(cm)\n",
        "\n",
        "        write_result_to_file(model_label, stream_label, results, cms)\n",
        "\n",
        "        if self.model_path:\n",
        "            print(f'Saving model: {self.model_path}')\n",
        "            torch.save(model.get_net().state_dict(), self.model_path)\n",
        "\n",
        "\n",
        "def evaluate_tasks(model: ContinualLearner, classes_test_data, class_test_concept_mapping, numpy):\n",
        "    classes_acc, class_targets, class_preds = [], [], []\n",
        "\n",
        "    for j, class_test_data in classes_test_data.items():\n",
        "        correct, all = 0.0, 0.0\n",
        "\n",
        "        for inputs_batch, labels_batch in class_test_data:\n",
        "            labels_batch = Tensor([class_test_concept_mapping[int(cls.item())] for cls in labels_batch.long()])\n",
        "            if numpy: inputs_batch, labels_batch = inputs_batch.numpy(), labels_batch.numpy()\n",
        "\n",
        "            preds_batch = model.predict(inputs_batch)\n",
        "            results = [p == y for p, y in zip(preds_batch, labels_batch)]\n",
        "            correct += sum(results)\n",
        "            all += len(inputs_batch)\n",
        "\n",
        "            class_targets += list(labels_batch)\n",
        "            class_preds += list(preds_batch)\n",
        "\n",
        "        acc = correct / all\n",
        "        classes_acc.append(acc)  # todo: add per subclass\n",
        "\n",
        "    return classes_acc, (class_targets, class_preds)\n",
        "\n",
        "\n",
        "def write_result_to_file(model_label, stream_label, results, cms):\n",
        "    os.makedirs('results', exist_ok=True)\n",
        "    path = f'results/{model_label}#{stream_label}.csv'\n",
        "    print('Writing results to file ', path)\n",
        "\n",
        "    num_tasks = len(results[0])\n",
        "\n",
        "    f = open(path, 'w')\n",
        "    for task_id, values in results.items():\n",
        "        ext = [0.0] * (num_tasks - len(values))\n",
        "        values = ext + values\n",
        "        values = [str(f.item() if torch.is_tensor(f) else str(f)) for f in values]\n",
        "        vals = ','.join(values)\n",
        "        f.write(f'{task_id},{vals}\\n')\n",
        "    f.close()\n",
        "\n",
        "    path = f'results/{model_label}#{stream_label}_cms.npy'\n",
        "    print(f'Writing {len(cms)} confusion matrices to file ', path)\n",
        "    np.save(path, np.array(cms, dtype=object))"
      ],
      "metadata": {
        "id": "VyenP7nsLh7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#experiment.py\n",
        "\n",
        "# from core.clearn import ContinualLearner\n",
        "# from data.stream import Stream\n",
        "# from eval.eval import Evaluator\n",
        "\n",
        "import itertools\n",
        "from abc import ABC, abstractmethod\n",
        "from typing import List, Dict, Callable\n",
        "\n",
        "\n",
        "class Experiment(ABC):\n",
        "\n",
        "    def __init__(self):\n",
        "        self.algorithms: Dict[str, Callable[[], ContinualLearner]] = {}\n",
        "        self.streams: Dict[str, Callable[[], Stream]] = {}\n",
        "        self.evaluators: Dict[str, Callable[[], Evaluator]] = {}\n",
        "\n",
        "    def run(self, algorithms: List[str] = None, streams: List[str] = None, evaluators: List[str] = None):\n",
        "        self.prepare()\n",
        "        algorithms = self.algorithms.keys() if not algorithms else algorithms\n",
        "        streams = self.streams.keys() if not streams else streams\n",
        "        evaluators = self.evaluators.keys() if not evaluators else evaluators\n",
        "\n",
        "        for a, s, e, in itertools.product(algorithms, streams, evaluators):\n",
        "            print(f'Running for: {a}, {s}, {e}')\n",
        "            self.evaluators[e]().evaluate((a, self.algorithms[a]), (s, self.streams[s]))\n",
        "\n",
        "    def add_algorithm_creator(self, label: str, algorithm: Callable[[], ContinualLearner]):\n",
        "        self.algorithms[label] = algorithm\n",
        "\n",
        "    def add_data_creator(self, label: str, stream: Callable[[], Stream]):\n",
        "        self.streams[label] = stream\n",
        "\n",
        "    def add_evaluator_creator(self, label: str, evaluator: Callable[[], Evaluator]):\n",
        "        self.evaluators[label] = evaluator\n",
        "\n",
        "    @abstractmethod\n",
        "    def prepare(self):\n",
        "        pass"
      ],
      "metadata": {
        "id": "hZmuHf9DLkUY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RiverWrapper(ContinualLearner):\n",
        "    \n",
        "    def __init__(self, classifier: Classifier):\n",
        "        super().__init__()\n",
        "        self.classifier = classifier\n",
        "\n",
        "    def predict(self, x_batch):\n",
        "        preds = np.zeros(len(x_batch))\n",
        "\n",
        "        for i, x in enumerate(x_batch):\n",
        "            xd = {k: x[k] for k in range(len(x))}\n",
        "            preds[i] = self.classifier.predict_one(xd)\n",
        "\n",
        "        return preds\n",
        "\n",
        "    def predict_prob(self, x_batch):\n",
        "        pass\n",
        "\n",
        "    def update(self, x_batch, y_batch, **kwargs):\n",
        "        weights = kwargs.get('weights', np.ones(len(y_batch)))\n",
        "        y_batch = y_batch.astype(int) if isinstance(y_batch, np.ndarray) else y_batch.int()\n",
        "\n",
        "        for x, y, w in zip(x_batch, y_batch, weights):\n",
        "            xd = {k: x[k] for k in range(len(x))}\n",
        "            self.classifier.learn_one(xd, y)"
      ],
      "metadata": {
        "id": "KMCy56AkLmo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = '/content/drive/MyDrive/pth files/ll_dt_tree'"
      ],
      "metadata": {
        "id": "DMy5iIDlLpJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "lldt_runner.py"
      ],
      "metadata": {
        "id": "2pIiMAZdLreg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "import os\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "from skmultiflow.trees import HoeffdingTreeClassifier\n",
        "from river.ensemble import AdaptiveRandomForestClassifier\n",
        "from river.tree import HoeffdingTreeClassifier\n",
        "from river.multiclass.ovr import OneVsRestClassifier\n",
        "\n",
        "# import data.data_collection as data_col\n",
        "# from data.stream import ClassStream\n",
        "# from eval.eval import ClassStreamEvaluator\n",
        "# from eval.experiment import Experiment\n",
        "# from learners.ht import HoeffdingTree\n",
        "# from learners.irf import IncrementalRandomForest\n",
        "# from utils.cls_utils import RiverWrapper\n",
        "import ray\n",
        "\n",
        "\n",
        "# num_cores = multiprocessing.cpu_count()\n",
        "# ray.init(num_cpus=num_cores, ignore_reinit_error=True)\n",
        "\n",
        "\n",
        "class ExperimentLifelongTree(Experiment):\n",
        "    def prepare(self):\n",
        "        logdir_root = result\n",
        "\n",
        "        self.add_algorithm_creator('HT', lambda: HoeffdingTree(att_split_est=False))\n",
        "        # self.add_algorithm_creator('HT-s10', lambda: HoeffdingTree(att_split_est=False, split_wait=10))\n",
        "        # self.add_algorithm_creator('HT-ae', lambda: HoeffdingTree(att_split_est=True, log_prob=True))\n",
        "        # self.add_algorithm_creator('HT-ae-s10', lambda: HoeffdingTree(att_split_est=True, split_wait=10, log_prob=True))\n",
        "\n",
        "        self.add_algorithm_creator('IRF40', lambda: IncrementalRandomForest(size=40, num_workers=10, att_split_est=False))\n",
        "        # self.add_algorithm_creator('IRF40-s10', lambda: IncrementalRandomForest(size=40, split_wait=10, num_workers=10, att_split_est=False))\n",
        "        # self.add_algorithm_creator('IRF40-ae', lambda: IncrementalRandomForest(size=40, num_workers=10, att_split_est=True))\n",
        "        # self.add_algorithm_creator('IRF40-ae-s10', lambda: IncrementalRandomForest(size=40, split_wait=10, num_workers=10, att_split_est=True))\n",
        "\n",
        "        # self.add_algorithm_creator('ARF40', lambda: RiverWrapper(AdaptiveRandomForestClassifier(split_confidence=0.01, n_models=40)))\n",
        "        # self.add_algorithm_creator('BAG40', lambda: IncrementalRandomForest(size=40, num_workers=10, att_split_est=False, rnd=False, subspaces=False))\n",
        "        # self.add_algorithm_creator('RSP40', lambda: IncrementalRandomForest(size=40, num_workers=10, att_split_est=False, rnd=False, subspaces=True))\n",
        "        # self.add_algorithm_creator('OVR', lambda: RiverWrapper(OneVsRestClassifier(HoeffdingTreeClassifier(split_confidence=0.01))))\n",
        "\n",
        "        # self.add_data_creator('MNIST-CI-FLAT',\n",
        "        #                       lambda: ClassStream(data_collection.get('MNIST-TRAIN-FLAT'), data_collection.get('MNIST-TEST-FLAT'), class_size=1))\n",
        "        # self.add_data_creator('FASHION-CI-FLAT',\n",
        "        #                       lambda: ClassStream(data_collection.get('FASHION-TRAIN-FLAT'), data_collection.get('FASHION-TEST-FLAT'), class_size=1))\n",
        "        self.add_data_creator('SVHN-TENSOR-CI',\n",
        "                              lambda: ClassStream(data_collection.get('SVHN-TRAIN-TENSOR'), data_collection.get('SVHN-TEST-TENSOR'), class_size=1, max_cls_num=4658))\n",
        "        # self.add_data_creator('CIFAR20C-TENSOR-CI',\n",
        "        #                       lambda: ClassStream(data_collection.get('CIFAR20C-TRAIN-TENSOR'), data_collection.get('CIFAR20C-TEST-TENSOR'), class_size=1))\n",
        "        # self.add_data_creator('IMAGENET20A-TENSOR-CI',\n",
        "        #                       lambda: ClassStream(data_collection.get('IMAGENET20A-TRAIN-TENSOR'), data_collection.get('IMAGENET20A-TEST-TENSOR'), class_size=1))\n",
        "        # self.add_data_creator('IMAGENET20B-TENSOR-CI',\n",
        "        #                       lambda: ClassStream(data_collection.get('IMAGENET20B-TRAIN-TENSOR'), data_collection.get('IMAGENET20B-TEST-TENSOR'), class_size=1))\n",
        "\n",
        "        self.add_evaluator_creator('IncEval-shallow', lambda: ClassStreamEvaluator(batch_size=256, shuffle=True, num_epochs=1, num_workers=8,\n",
        "                                                               logdir_root=logdir_root, numpy=True, vis=False))\n",
        "\n"
      ],
      "metadata": {
        "id": "sQqCUI80LuCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# seqs = ['MNIST-CI-FLAT', 'FASHION-CI-FLAT', 'SVHN-TENSOR-CI', 'CIFAR20C-TENSOR-CI']\n",
        "# img_seqs = ['IMAGENET20A-TENSOR-CI', 'IMAGENET20B-TENSOR-CI']\n",
        "seqs = ['SVHN-TENSOR-CI']\n",
        "# img_seqs = ['IMAGENET20A-TENSOR-CI', 'IMAGENET20B-TENSOR-CI']\n",
        "ExperimentLifelongTree().run(algorithms=['HT'], streams=seqs, evaluators=['IncEval-shallow'])\n",
        "# ExperimentLifelongTree().run(algorithms=['HT', 'IRF40'], streams=seqs, evaluators=['IncEval-shallow']) important\n",
        "# ExperimentLifelongTree().run(algorithms=['HT-s10', 'IRF40-s10'], streams=img_seqs, evaluators=['IncEval-shallow'])\n",
        "\n",
        "#ExperimentLifelongTree().run(algorithms=['HT-ae', 'IRF40-ae'], streams=seqs, evaluators=['IncEval-shallow'])\n",
        "# ExperimentLifelongTree().run(algorithms=['HT-ae-s10', 'IRF40-ae-s10'], streams=img_seqs, evaluators=['IncEval-shallow'])\n",
        "\n",
        "# ExperimentLifelongTree().run(algorithms=['ARF40', 'BAG40', 'RSP40', 'OVR'], streams=seqs + img_seqs, evaluators=['IncEval-shallow'])\n",
        "\n",
        "#/content/drive/MyDrive/pth files/svhn10-2-train.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PNN7axxILxvV",
        "outputId": "a54e2318-6de6-4cc0-c6c4-20a4737e50a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running for: HT, SVHN-TENSOR-CI, IncEval-shallow\n",
            "[1/3] Preparing data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2/3] Preparing model\n",
            "[3/3] Preparing metrics\n",
            "Evaluating...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0%|          | 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "  5%|▌         | 1/19 [00:03<01:03,  3.52s/it]\u001b[A\n",
            " 11%|█         | 2/19 [00:06<00:54,  3.19s/it]\u001b[A\n",
            " 16%|█▌        | 3/19 [00:09<00:50,  3.13s/it]\u001b[A\n",
            " 21%|██        | 4/19 [00:12<00:46,  3.10s/it]\u001b[A\n",
            " 26%|██▋       | 5/19 [00:16<00:46,  3.34s/it]\u001b[A\n",
            " 32%|███▏      | 6/19 [00:20<00:46,  3.58s/it]\u001b[A\n",
            " 37%|███▋      | 7/19 [00:23<00:40,  3.35s/it]\u001b[A\n",
            " 42%|████▏     | 8/19 [00:26<00:36,  3.31s/it]\u001b[A\n",
            " 47%|████▋     | 9/19 [00:29<00:32,  3.28s/it]\u001b[A\n",
            " 53%|█████▎    | 10/19 [00:32<00:28,  3.16s/it]\u001b[A\n",
            " 58%|█████▊    | 11/19 [00:35<00:24,  3.03s/it]\u001b[A\n",
            " 63%|██████▎   | 12/19 [00:38<00:22,  3.17s/it]\u001b[A\n",
            " 68%|██████▊   | 13/19 [00:41<00:18,  3.13s/it]\u001b[A\n",
            " 74%|███████▎  | 14/19 [00:45<00:15,  3.18s/it]\u001b[A\n",
            " 79%|███████▉  | 15/19 [00:47<00:12,  3.05s/it]\u001b[A\n",
            " 84%|████████▍ | 16/19 [00:51<00:09,  3.06s/it]\u001b[A\n",
            " 89%|████████▉ | 17/19 [00:54<00:06,  3.06s/it]\u001b[A\n",
            " 95%|█████████▍| 18/19 [00:56<00:03,  3.01s/it]\u001b[A\n",
            "100%|██████████| 19/19 [00:57<00:00,  3.05s/it]\n",
            " 10%|█         | 1/10 [00:58<08:49, 58.86s/it]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0%|          | 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "  5%|▌         | 1/19 [00:04<01:13,  4.08s/it]\u001b[A\n",
            " 11%|█         | 2/19 [00:08<01:10,  4.14s/it]\u001b[A\n",
            " 16%|█▌        | 3/19 [00:12<01:05,  4.11s/it]\u001b[A\n",
            " 21%|██        | 4/19 [00:15<00:57,  3.82s/it]\u001b[A\n",
            " 26%|██▋       | 5/19 [00:19<00:52,  3.74s/it]\u001b[A\n",
            " 32%|███▏      | 6/19 [00:23<00:49,  3.83s/it]\u001b[A\n",
            " 37%|███▋      | 7/19 [00:26<00:44,  3.69s/it]\u001b[A\n",
            " 42%|████▏     | 8/19 [00:30<00:41,  3.80s/it]\u001b[A\n",
            " 47%|████▋     | 9/19 [00:34<00:38,  3.85s/it]\u001b[A\n",
            " 53%|█████▎    | 10/19 [00:38<00:33,  3.77s/it]\u001b[A\n",
            " 58%|█████▊    | 11/19 [00:42<00:30,  3.87s/it]\u001b[A\n",
            " 63%|██████▎   | 12/19 [00:45<00:26,  3.75s/it]\u001b[A\n",
            " 68%|██████▊   | 13/19 [00:49<00:22,  3.73s/it]\u001b[A\n",
            " 74%|███████▎  | 14/19 [00:53<00:18,  3.66s/it]\u001b[A\n",
            " 79%|███████▉  | 15/19 [00:56<00:14,  3.67s/it]\u001b[A\n",
            " 84%|████████▍ | 16/19 [01:00<00:11,  3.72s/it]\u001b[A\n",
            " 89%|████████▉ | 17/19 [01:04<00:07,  3.76s/it]\u001b[A\n",
            " 95%|█████████▍| 18/19 [01:08<00:03,  3.79s/it]\u001b[A\n",
            "100%|██████████| 19/19 [01:09<00:00,  3.65s/it]\n",
            " 20%|██        | 2/10 [02:27<10:10, 76.29s/it]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0%|          | 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "  5%|▌         | 1/19 [00:05<01:30,  5.01s/it]\u001b[A\n",
            " 11%|█         | 2/19 [00:09<01:17,  4.53s/it]\u001b[A\n",
            " 16%|█▌        | 3/19 [00:13<01:11,  4.49s/it]\u001b[A\n",
            " 21%|██        | 4/19 [00:18<01:09,  4.60s/it]\u001b[A\n",
            " 26%|██▋       | 5/19 [00:22<01:03,  4.54s/it]\u001b[A\n",
            " 32%|███▏      | 6/19 [00:27<00:58,  4.53s/it]\u001b[A\n",
            " 37%|███▋      | 7/19 [00:31<00:54,  4.50s/it]\u001b[A\n",
            " 42%|████▏     | 8/19 [00:36<00:48,  4.43s/it]\u001b[A\n",
            " 47%|████▋     | 9/19 [00:40<00:43,  4.39s/it]\u001b[A\n",
            " 53%|█████▎    | 10/19 [00:44<00:38,  4.31s/it]\u001b[A\n",
            " 58%|█████▊    | 11/19 [00:48<00:33,  4.18s/it]\u001b[A\n",
            " 63%|██████▎   | 12/19 [00:52<00:29,  4.20s/it]\u001b[A\n",
            " 68%|██████▊   | 13/19 [00:56<00:24,  4.15s/it]\u001b[A\n",
            " 74%|███████▎  | 14/19 [01:00<00:20,  4.18s/it]\u001b[A\n",
            " 79%|███████▉  | 15/19 [01:05<00:16,  4.25s/it]\u001b[A\n",
            " 84%|████████▍ | 16/19 [01:09<00:12,  4.13s/it]\u001b[A\n",
            " 89%|████████▉ | 17/19 [01:13<00:08,  4.17s/it]\u001b[A\n",
            " 95%|█████████▍| 18/19 [01:17<00:04,  4.25s/it]\u001b[A\n",
            "100%|██████████| 19/19 [01:19<00:00,  4.18s/it]\n",
            " 30%|███       | 3/10 [04:35<11:40, 100.02s/it]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0%|          | 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "  5%|▌         | 1/19 [00:05<01:34,  5.27s/it]\u001b[A\n",
            " 11%|█         | 2/19 [00:10<01:24,  5.00s/it]\u001b[A\n",
            " 16%|█▌        | 3/19 [00:15<01:23,  5.24s/it]\u001b[A\n",
            " 21%|██        | 4/19 [00:20<01:14,  4.97s/it]\u001b[A\n",
            " 26%|██▋       | 5/19 [00:25<01:10,  5.05s/it]\u001b[A\n",
            " 32%|███▏      | 6/19 [00:30<01:06,  5.09s/it]\u001b[A\n",
            " 37%|███▋      | 7/19 [00:35<01:01,  5.13s/it]\u001b[A\n",
            " 42%|████▏     | 8/19 [00:41<00:57,  5.21s/it]\u001b[A\n",
            " 47%|████▋     | 9/19 [00:46<00:52,  5.26s/it]\u001b[A\n",
            " 53%|█████▎    | 10/19 [00:51<00:46,  5.18s/it]\u001b[A\n",
            " 58%|█████▊    | 11/19 [00:56<00:40,  5.05s/it]\u001b[A\n",
            " 63%|██████▎   | 12/19 [01:00<00:34,  4.90s/it]\u001b[A\n",
            " 68%|██████▊   | 13/19 [01:05<00:29,  4.92s/it]\u001b[A\n",
            " 74%|███████▎  | 14/19 [01:10<00:24,  4.81s/it]\u001b[A\n",
            " 79%|███████▉  | 15/19 [01:15<00:19,  4.86s/it]\u001b[A\n",
            " 84%|████████▍ | 16/19 [01:19<00:14,  4.81s/it]\u001b[A\n",
            " 89%|████████▉ | 17/19 [01:24<00:09,  4.78s/it]\u001b[A\n",
            " 95%|█████████▍| 18/19 [01:29<00:04,  4.81s/it]\u001b[A\n",
            "100%|██████████| 19/19 [01:30<00:00,  4.79s/it]\n",
            " 40%|████      | 4/10 [08:07<14:25, 144.18s/it]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0%|          | 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "  5%|▌         | 1/19 [00:05<01:45,  5.83s/it]\u001b[A\n",
            " 11%|█         | 2/19 [00:12<01:43,  6.06s/it]\u001b[A\n",
            " 16%|█▌        | 3/19 [00:17<01:36,  6.00s/it]\u001b[A\n",
            " 21%|██        | 4/19 [00:23<01:28,  5.89s/it]\u001b[A\n",
            " 26%|██▋       | 5/19 [00:29<01:22,  5.88s/it]\u001b[A\n",
            " 32%|███▏      | 6/19 [00:35<01:14,  5.73s/it]\u001b[A\n",
            " 37%|███▋      | 7/19 [00:40<01:09,  5.78s/it]\u001b[A\n",
            " 42%|████▏     | 8/19 [00:46<01:03,  5.77s/it]\u001b[A\n",
            " 47%|████▋     | 9/19 [00:52<00:56,  5.70s/it]\u001b[A\n",
            " 53%|█████▎    | 10/19 [00:57<00:51,  5.68s/it]\u001b[A\n",
            " 58%|█████▊    | 11/19 [01:03<00:44,  5.58s/it]\u001b[A\n",
            " 63%|██████▎   | 12/19 [01:09<00:40,  5.79s/it]\u001b[A\n",
            " 68%|██████▊   | 13/19 [01:15<00:34,  5.74s/it]\u001b[A\n",
            " 74%|███████▎  | 14/19 [01:20<00:28,  5.63s/it]\u001b[A\n",
            " 79%|███████▉  | 15/19 [01:25<00:22,  5.57s/it]\u001b[A\n",
            " 84%|████████▍ | 16/19 [01:31<00:16,  5.66s/it]\u001b[A\n",
            " 89%|████████▉ | 17/19 [01:37<00:11,  5.83s/it]\u001b[A\n",
            " 95%|█████████▍| 18/19 [01:44<00:05,  5.90s/it]\u001b[A\n",
            "100%|██████████| 19/19 [01:45<00:00,  5.54s/it]\n",
            " 50%|█████     | 5/10 [12:41<15:55, 191.14s/it]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0%|          | 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "  5%|▌         | 1/19 [00:06<02:04,  6.90s/it]\u001b[A\n",
            " 11%|█         | 2/19 [00:12<01:49,  6.42s/it]\u001b[A\n",
            " 16%|█▌        | 3/19 [00:19<01:43,  6.47s/it]\u001b[A\n",
            " 21%|██        | 4/19 [00:25<01:37,  6.47s/it]\u001b[A\n",
            " 26%|██▋       | 5/19 [00:32<01:31,  6.51s/it]\u001b[A\n",
            " 32%|███▏      | 6/19 [00:39<01:24,  6.49s/it]\u001b[A\n",
            " 37%|███▋      | 7/19 [00:45<01:16,  6.35s/it]\u001b[A\n",
            " 42%|████▏     | 8/19 [00:51<01:11,  6.49s/it]\u001b[A\n",
            " 47%|████▋     | 9/19 [00:58<01:04,  6.42s/it]\u001b[A\n",
            " 53%|█████▎    | 10/19 [01:04<00:56,  6.28s/it]\u001b[A\n",
            " 58%|█████▊    | 11/19 [01:10<00:50,  6.26s/it]\u001b[A\n",
            " 63%|██████▎   | 12/19 [01:16<00:42,  6.13s/it]\u001b[A\n",
            " 68%|██████▊   | 13/19 [01:22<00:36,  6.10s/it]\u001b[A\n",
            " 74%|███████▎  | 14/19 [01:28<00:30,  6.12s/it]\u001b[A\n",
            " 79%|███████▉  | 15/19 [01:34<00:24,  6.08s/it]\u001b[A\n",
            " 84%|████████▍ | 16/19 [01:40<00:18,  6.24s/it]\u001b[A\n",
            " 89%|████████▉ | 17/19 [01:47<00:12,  6.26s/it]\u001b[A\n",
            " 95%|█████████▍| 18/19 [01:53<00:06,  6.31s/it]\u001b[A\n",
            "100%|██████████| 19/19 [01:55<00:00,  6.06s/it]\n",
            " 60%|██████    | 6/10 [18:28<16:15, 243.90s/it]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0%|          | 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "  5%|▌         | 1/19 [00:06<02:02,  6.82s/it]\u001b[A\n",
            " 11%|█         | 2/19 [00:13<01:55,  6.79s/it]\u001b[A\n",
            " 16%|█▌        | 3/19 [00:20<01:49,  6.87s/it]\u001b[A\n",
            " 21%|██        | 4/19 [00:27<01:42,  6.81s/it]\u001b[A\n",
            " 26%|██▋       | 5/19 [00:33<01:33,  6.68s/it]\u001b[A\n",
            " 32%|███▏      | 6/19 [00:41<01:29,  6.92s/it]\u001b[A\n",
            " 37%|███▋      | 7/19 [00:47<01:21,  6.82s/it]\u001b[A\n",
            " 42%|████▏     | 8/19 [00:54<01:14,  6.77s/it]\u001b[A\n",
            " 47%|████▋     | 9/19 [01:01<01:07,  6.75s/it]\u001b[A\n",
            " 53%|█████▎    | 10/19 [01:07<01:00,  6.74s/it]\u001b[A\n",
            " 58%|█████▊    | 11/19 [01:14<00:53,  6.68s/it]\u001b[A\n",
            " 63%|██████▎   | 12/19 [01:21<00:47,  6.73s/it]\u001b[A\n",
            " 68%|██████▊   | 13/19 [01:28<00:40,  6.78s/it]\u001b[A\n",
            " 74%|███████▎  | 14/19 [01:35<00:34,  6.88s/it]\u001b[A\n",
            " 79%|███████▉  | 15/19 [01:42<00:28,  7.07s/it]\u001b[A\n",
            " 84%|████████▍ | 16/19 [01:49<00:21,  7.06s/it]\u001b[A\n",
            " 89%|████████▉ | 17/19 [01:56<00:13,  6.90s/it]\u001b[A\n",
            " 95%|█████████▍| 18/19 [02:02<00:06,  6.81s/it]\u001b[A\n",
            "100%|██████████| 19/19 [02:04<00:00,  6.56s/it]\n",
            " 70%|███████   | 7/10 [26:02<15:38, 312.82s/it]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0%|          | 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "  5%|▌         | 1/19 [00:07<02:23,  7.99s/it]\u001b[A\n",
            " 11%|█         | 2/19 [00:15<02:12,  7.77s/it]\u001b[A\n",
            " 16%|█▌        | 3/19 [00:22<01:59,  7.44s/it]\u001b[A\n",
            " 21%|██        | 4/19 [00:29<01:50,  7.40s/it]\u001b[A\n",
            " 26%|██▋       | 5/19 [00:38<01:47,  7.67s/it]\u001b[A\n",
            " 32%|███▏      | 6/19 [00:45<01:37,  7.48s/it]\u001b[A\n",
            " 37%|███▋      | 7/19 [00:52<01:30,  7.55s/it]\u001b[A\n",
            " 42%|████▏     | 8/19 [01:00<01:24,  7.67s/it]\u001b[A\n",
            " 47%|████▋     | 9/19 [01:08<01:16,  7.63s/it]\u001b[A\n",
            " 53%|█████▎    | 10/19 [01:15<01:08,  7.61s/it]\u001b[A\n",
            " 58%|█████▊    | 11/19 [01:24<01:02,  7.76s/it]\u001b[A\n",
            " 63%|██████▎   | 12/19 [01:32<00:55,  7.97s/it]\u001b[A\n",
            " 68%|██████▊   | 13/19 [01:40<00:47,  7.87s/it]\u001b[A\n",
            " 74%|███████▎  | 14/19 [01:47<00:38,  7.76s/it]\u001b[A\n",
            " 79%|███████▉  | 15/19 [01:55<00:30,  7.63s/it]\u001b[A\n",
            " 84%|████████▍ | 16/19 [02:02<00:22,  7.61s/it]\u001b[A\n",
            " 89%|████████▉ | 17/19 [02:09<00:14,  7.46s/it]\u001b[A\n",
            " 95%|█████████▍| 18/19 [02:17<00:07,  7.59s/it]\u001b[A\n",
            "100%|██████████| 19/19 [02:19<00:00,  7.33s/it]\n",
            " 80%|████████  | 8/10 [35:17<12:59, 389.71s/it]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0%|          | 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "  5%|▌         | 1/19 [00:08<02:32,  8.46s/it]\u001b[A\n",
            " 11%|█         | 2/19 [00:17<02:27,  8.70s/it]\u001b[A\n",
            " 16%|█▌        | 3/19 [00:25<02:12,  8.27s/it]\u001b[A\n",
            " 21%|██        | 4/19 [00:33<02:06,  8.45s/it]\u001b[A\n",
            " 26%|██▋       | 5/19 [00:42<01:57,  8.37s/it]\u001b[A\n",
            " 32%|███▏      | 6/19 [00:50<01:49,  8.42s/it]\u001b[A\n",
            " 37%|███▋      | 7/19 [00:58<01:40,  8.36s/it]\u001b[A\n",
            " 42%|████▏     | 8/19 [01:07<01:31,  8.34s/it]\u001b[A\n",
            " 47%|████▋     | 9/19 [01:15<01:23,  8.31s/it]\u001b[A\n",
            " 53%|█████▎    | 10/19 [01:23<01:13,  8.21s/it]\u001b[A\n",
            " 58%|█████▊    | 11/19 [01:31<01:06,  8.33s/it]\u001b[A\n",
            " 63%|██████▎   | 12/19 [01:39<00:57,  8.19s/it]\u001b[A\n",
            " 68%|██████▊   | 13/19 [01:47<00:49,  8.18s/it]\u001b[A\n",
            " 74%|███████▎  | 14/19 [01:56<00:40,  8.18s/it]\u001b[A\n",
            " 79%|███████▉  | 15/19 [02:04<00:32,  8.24s/it]\u001b[A\n",
            " 84%|████████▍ | 16/19 [02:12<00:24,  8.07s/it]\u001b[A\n",
            " 89%|████████▉ | 17/19 [02:20<00:16,  8.19s/it]\u001b[A\n",
            " 95%|█████████▍| 18/19 [02:29<00:08,  8.28s/it]\u001b[A\n",
            "100%|██████████| 19/19 [02:31<00:00,  7.96s/it]\n",
            " 90%|█████████ | 9/10 [46:15<07:53, 473.81s/it]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0%|          | 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "  5%|▌         | 1/19 [00:09<02:52,  9.57s/it]\u001b[A\n",
            " 11%|█         | 2/19 [00:18<02:37,  9.28s/it]\u001b[A\n",
            " 16%|█▌        | 3/19 [00:27<02:26,  9.14s/it]\u001b[A\n",
            " 21%|██        | 4/19 [00:37<02:18,  9.25s/it]\u001b[A\n",
            " 26%|██▋       | 5/19 [00:47<02:13,  9.51s/it]\u001b[A\n",
            " 32%|███▏      | 6/19 [00:55<01:59,  9.19s/it]\u001b[A\n",
            " 37%|███▋      | 7/19 [01:04<01:48,  9.01s/it]\u001b[A\n",
            " 42%|████▏     | 8/19 [01:13<01:38,  8.95s/it]\u001b[A\n",
            " 47%|████▋     | 9/19 [01:22<01:30,  9.05s/it]\u001b[A\n",
            " 53%|█████▎    | 10/19 [01:31<01:22,  9.12s/it]\u001b[A\n",
            " 58%|█████▊    | 11/19 [01:40<01:11,  8.97s/it]\u001b[A\n",
            " 63%|██████▎   | 12/19 [01:48<01:01,  8.81s/it]\u001b[A\n",
            " 68%|██████▊   | 13/19 [01:57<00:53,  8.86s/it]\u001b[A\n",
            " 74%|███████▎  | 14/19 [02:06<00:44,  8.85s/it]\u001b[A\n",
            " 79%|███████▉  | 15/19 [02:15<00:35,  8.84s/it]\u001b[A\n",
            " 84%|████████▍ | 16/19 [02:24<00:26,  8.92s/it]\u001b[A\n",
            " 89%|████████▉ | 17/19 [02:33<00:17,  8.85s/it]\u001b[A\n",
            " 95%|█████████▍| 18/19 [02:41<00:08,  8.73s/it]\u001b[A\n",
            "100%|██████████| 19/19 [02:43<00:00,  8.60s/it]\n",
            "100%|██████████| 10/10 [58:36<00:00, 351.67s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-7ab112cd446e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mseqs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'SVHN-TENSOR-CI'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# img_seqs = ['IMAGENET20A-TENSOR-CI', 'IMAGENET20B-TENSOR-CI']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mExperimentLifelongTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malgorithms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'HT'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstreams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'IncEval-shallow'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m# ExperimentLifelongTree().run(algorithms=['HT', 'IRF40'], streams=seqs, evaluators=['IncEval-shallow']) important\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# ExperimentLifelongTree().run(algorithms=['HT-s10', 'IRF40-s10'], streams=img_seqs, evaluators=['IncEval-shallow'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-77a2a463aa1f>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, algorithms, streams, evaluators)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malgorithms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstreams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Running for: {a}, {s}, {e}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstreams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd_algorithm_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mContinualLearner\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-6384d789ae34>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, model_creator, data_creator)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0mpickle_save_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/pth files/ll_dt_tree'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_save_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'lldt_pickle_1.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'ClassStreamEvaluator' object has no attribute 'state_dict'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "FBXAXPDpkh-w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "zrYne4SAzOrL"
      }
    }
  ]
}