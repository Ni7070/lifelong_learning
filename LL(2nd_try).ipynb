{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LL(2nd try).ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN4Ool3lZoHHb0d59YdoxDf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "09b57d31525e4a288cd1ba6ad599116f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3d24cdb053d146599434871de0ac53fa",
              "IPY_MODEL_9c4fe8a3ec624b3c97ae47556d0272dd",
              "IPY_MODEL_0ba664480d364f4f81d95ea53de7b0b0"
            ],
            "layout": "IPY_MODEL_33eb6b7fd85549448e9b133fdca196fe"
          }
        },
        "3d24cdb053d146599434871de0ac53fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72d0a6d98d604461af56cc086378b056",
            "placeholder": "​",
            "style": "IPY_MODEL_9e1044c6828c463e87220756d06cdab0",
            "value": ""
          }
        },
        "9c4fe8a3ec624b3c97ae47556d0272dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a474a8b8aeff4ef98ef842b7cfb1fc1d",
            "max": 182040794,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_504d505eeaf54ce2ba62e2e35e115ac3",
            "value": 182040794
          }
        },
        "0ba664480d364f4f81d95ea53de7b0b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bcd6bb8117ee46a7ad391c15b596cdf3",
            "placeholder": "​",
            "style": "IPY_MODEL_6aa1c3b1ee504009a698898a0668711d",
            "value": " 182041600/? [00:14&lt;00:00, 19626296.97it/s]"
          }
        },
        "33eb6b7fd85549448e9b133fdca196fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72d0a6d98d604461af56cc086378b056": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e1044c6828c463e87220756d06cdab0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a474a8b8aeff4ef98ef842b7cfb1fc1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "504d505eeaf54ce2ba62e2e35e115ac3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bcd6bb8117ee46a7ad391c15b596cdf3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6aa1c3b1ee504009a698898a0668711d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7d3a8f2e21a4d5fb66f19dfacb14219": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dc4cb4abe16d451391b8aa9baa3a60d4",
              "IPY_MODEL_99105534d7944512a021ea86f1f29b2b",
              "IPY_MODEL_68abfe89ab2441329676b7dac0171aa4"
            ],
            "layout": "IPY_MODEL_914ab31848d44a83aa559c67617cb39d"
          }
        },
        "dc4cb4abe16d451391b8aa9baa3a60d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34fa3ec8137148c4ba2c2783d42549b8",
            "placeholder": "​",
            "style": "IPY_MODEL_c10ce811a9ef4abfa963b8dbea08b0f4",
            "value": ""
          }
        },
        "99105534d7944512a021ea86f1f29b2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a123e8831481462aa94a885e411707eb",
            "max": 64275384,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9e3340ffbbae4d7fa7e4e068a62c2c0c",
            "value": 64275384
          }
        },
        "68abfe89ab2441329676b7dac0171aa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a557b1d1b6f49bab6a97aea0672b446",
            "placeholder": "​",
            "style": "IPY_MODEL_9f1e83ce1be049d99c61fc34027169d6",
            "value": " 64275456/? [00:09&lt;00:00, 16736763.55it/s]"
          }
        },
        "914ab31848d44a83aa559c67617cb39d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34fa3ec8137148c4ba2c2783d42549b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c10ce811a9ef4abfa963b8dbea08b0f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a123e8831481462aa94a885e411707eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e3340ffbbae4d7fa7e4e068a62c2c0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1a557b1d1b6f49bab6a97aea0672b446": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f1e83ce1be049d99c61fc34027169d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ni7070/lifelong_learning/blob/master/LL(2nd_try).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "main() calls  \n",
        "\n",
        "```\n",
        "extractor.extract(False)\n",
        "lldt_runner.run()\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "F0xvkWnBlKce"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jWe2z2W3lGaF"
      },
      "outputs": [],
      "source": [
        "#tensor_set.py \n",
        "\n",
        "import os\n",
        "\n",
        "import torch\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "class TensorDataset(Dataset):\n",
        "    def __init__(self, path):\n",
        "        data = torch.load(path)\n",
        "        self.rows, self.labels = data[:, :-1], data[:, -1]\n",
        "        self.n = len(self.labels)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.rows[index], self.labels[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n\n",
        "\n",
        "\n",
        "def extract_features(image_dataset: Dataset, extractor: torch.nn.Module, out_path: str, device='cpu'):\n",
        "    print('Extracting features...')\n",
        "    loader = torch.utils.data.DataLoader(image_dataset, batch_size=256, num_workers=4)\n",
        "    n = len(image_dataset)\n",
        "    init = False\n",
        "    all_data = None\n",
        "\n",
        "    i = 0\n",
        "    for inputs, labels in tqdm(loader):\n",
        "        with torch.no_grad():\n",
        "            print('in', inputs.shape)\n",
        "            features = extractor(inputs.to(device)).cpu()\n",
        "            print('out', features.shape)\n",
        "            if not init:\n",
        "                all_data = torch.zeros((n, features.shape[1] + 1))\n",
        "                init = True\n",
        "\n",
        "            all_data[i:i + len(features), :-1] = features\n",
        "            all_data[i:i + len(features), -1] = labels\n",
        "\n",
        "        i += len(features)\n",
        "        print(i)\n",
        "\n",
        "    print(f'Saving to {out_path}')\n",
        "    os.makedirs(os.path.join(*out_path.split('/')[:-1]), exist_ok=True)\n",
        "    torch.save(all_data, out_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#learners/model/resnext.py \n",
        "\n",
        "from __future__ import division\n",
        "\n",
        "import torch\n",
        "\n",
        "\"\"\" \n",
        "Creates a ResNeXt Model as defined in:\n",
        "Xie, S., Girshick, R., Dollar, P., Tu, Z., & He, K. (2016). \n",
        "Aggregated residual transformations for deep neural networks. \n",
        "arXiv preprint arXiv:1611.05431.\n",
        "import from https://github.com/prlz77/ResNeXt.pytorch/blob/master/models/model.py\n",
        "\"\"\"\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import init\n",
        "\n",
        "__all__ = ['resnext']\n",
        "\n",
        "\n",
        "class ResNeXtBottleneck(nn.Module):\n",
        "    \"\"\"\n",
        "    RexNeXt bottleneck type C (https://github.com/facebookresearch/ResNeXt/blob/master/models/resnext.lua)\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, stride, cardinality, widen_factor):\n",
        "        \"\"\" Constructor\n",
        "        Args:\n",
        "            in_channels: input channel dimensionality\n",
        "            out_channels: output channel dimensionality\n",
        "            stride: conv stride. Replaces pooling layer.\n",
        "            cardinality: num of convolution groups.\n",
        "            widen_factor: factor to reduce the input dimensionality before convolution.\n",
        "        \"\"\"\n",
        "        super(ResNeXtBottleneck, self).__init__()\n",
        "        D = cardinality * out_channels // widen_factor\n",
        "        self.conv_reduce = nn.Conv2d(in_channels, D, kernel_size=1, stride=1, padding=0, bias=False)\n",
        "        self.bn_reduce = nn.BatchNorm2d(D)\n",
        "        self.conv_conv = nn.Conv2d(D, D, kernel_size=3, stride=stride, padding=1, groups=cardinality, bias=False)\n",
        "        self.bn = nn.BatchNorm2d(D)\n",
        "        self.conv_expand = nn.Conv2d(D, out_channels, kernel_size=1, stride=1, padding=0, bias=False)\n",
        "        self.bn_expand = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if in_channels != out_channels:\n",
        "            self.shortcut.add_module('shortcut_conv', nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, padding=0, bias=False))\n",
        "            self.shortcut.add_module('shortcut_bn', nn.BatchNorm2d(out_channels))\n",
        "\n",
        "    def forward(self, x):\n",
        "        bottleneck = self.conv_reduce.forward(x)\n",
        "        bottleneck = F.relu(self.bn_reduce.forward(bottleneck), inplace=True)\n",
        "        bottleneck = self.conv_conv.forward(bottleneck)\n",
        "        bottleneck = F.relu(self.bn.forward(bottleneck), inplace=True)\n",
        "        bottleneck = self.conv_expand.forward(bottleneck)\n",
        "        bottleneck = self.bn_expand.forward(bottleneck)\n",
        "        residual = self.shortcut.forward(x)\n",
        "        return F.relu(residual + bottleneck, inplace=True)\n",
        "\n",
        "\n",
        "class CifarResNeXt(nn.Module):\n",
        "    \"\"\"\n",
        "    ResNext optimized for the Cifar dataset, as specified in\n",
        "    https://arxiv.org/pdf/1611.05431.pdf\n",
        "    \"\"\"\n",
        "    def __init__(self, cardinality, depth, num_classes, widen_factor=4, dropRate=0):\n",
        "        \"\"\" Constructor\n",
        "        Args:\n",
        "            cardinality: number of convolution groups.\n",
        "            depth: number of layers.\n",
        "            num_classes: number of classes\n",
        "            widen_factor: factor to adjust the channel dimensionality\n",
        "        \"\"\"\n",
        "        super(CifarResNeXt, self).__init__()\n",
        "        self.cardinality = cardinality\n",
        "        self.depth = depth\n",
        "        self.block_depth = (self.depth - 2) // 9\n",
        "        self.widen_factor = widen_factor\n",
        "        self.num_classes = num_classes\n",
        "        self.output_size = 64\n",
        "        self.stages = [64, 64 * self.widen_factor, 128 * self.widen_factor, 256 * self.widen_factor]\n",
        "\n",
        "        self.conv_1_3x3 = nn.Conv2d(3, 64, 3, 1, 1, bias=False)\n",
        "        self.bn_1 = nn.BatchNorm2d(64)\n",
        "        self.stage_1 = self.block('stage_1', self.stages[0], self.stages[1], 1)\n",
        "        self.stage_2 = self.block('stage_2', self.stages[1], self.stages[2], 2)\n",
        "        self.stage_3 = self.block('stage_3', self.stages[2], self.stages[3], 2)\n",
        "        self.classifier = nn.Linear(1024, num_classes)\n",
        "        init.kaiming_normal(self.classifier.weight)\n",
        "\n",
        "        for key in self.state_dict():\n",
        "            if key.split('.')[-1] == 'weight':\n",
        "                if 'conv' in key:\n",
        "                    init.kaiming_normal(self.state_dict()[key], mode='fan_out')\n",
        "                if 'bn' in key:\n",
        "                    self.state_dict()[key][...] = 1\n",
        "            elif key.split('.')[-1] == 'bias':\n",
        "                self.state_dict()[key][...] = 0\n",
        "\n",
        "    def block(self, name, in_channels, out_channels, pool_stride=2):\n",
        "        \"\"\" Stack n bottleneck modules where n is inferred from the depth of the network.\n",
        "        Args:\n",
        "            name: string name of the current block.\n",
        "            in_channels: number of input channels\n",
        "            out_channels: number of output channels\n",
        "            pool_stride: factor to reduce the spatial dimensionality in the first bottleneck of the block.\n",
        "        Returns: a Module consisting of n sequential bottlenecks.\n",
        "        \"\"\"\n",
        "        block = nn.Sequential()\n",
        "        for bottleneck in range(self.block_depth):\n",
        "            name_ = '%s_bottleneck_%d' % (name, bottleneck)\n",
        "            if bottleneck == 0:\n",
        "                block.add_module(name_, ResNeXtBottleneck(in_channels, out_channels, pool_stride, self.cardinality,\n",
        "                                                          self.widen_factor))\n",
        "            else:\n",
        "                block.add_module(name_,\n",
        "                                 ResNeXtBottleneck(out_channels, out_channels, 1, self.cardinality, self.widen_factor))\n",
        "        return block\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_1_3x3.forward(x)\n",
        "        x = F.relu(self.bn_1.forward(x), inplace=True)\n",
        "        x = self.stage_1.forward(x)\n",
        "        x = self.stage_2.forward(x)\n",
        "        x = self.stage_3.forward(x)\n",
        "        x = F.avg_pool2d(x, 8, 1)\n",
        "        x = x.view(-1, 1, 1024)\n",
        "\n",
        "        # todo: remove\n",
        "        x = F.avg_pool1d(x, 2)\n",
        "        x = x.view(-1, 512)\n",
        "\n",
        "        return x\n",
        "        #return self.classifier(x)\n",
        "\n",
        "\n",
        "def create_cifar_resnext(model_path: str):\n",
        "    checkpoint = torch.load(model_path)\n",
        "    state_dict = checkpoint['state_dict']\n",
        "\n",
        "    # new_state_dict = OrderedDict()\n",
        "    # for k, v in state_dict.items():\n",
        "    #     if 'module' not in k:\n",
        "    #         k = 'module.'+k\n",
        "    #     else:\n",
        "    #         k = k.replace('features.module.', 'module.features.')\n",
        "    #     new_state_dict[k] = v\n",
        "\n",
        "    net = CifarResNeXt(depth=29, cardinality=8, num_classes=100, widen_factor=4)\n",
        "    net = torch.nn.DataParallel(net)\n",
        "    net.load_state_dict(state_dict)\n",
        "\n",
        "    return net"
      ],
      "metadata": {
        "id": "fXOZpb5ymbvP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Data_Utils\n",
        "import collections\n",
        "import os\n",
        "import zipfile\n",
        "from typing import Optional, Callable, Dict\n",
        "import torch\n",
        "from typing import Sequence\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import Dataset, Subset, DataLoader\n",
        "from torch.utils.data.dataset import T_co\n",
        "\n",
        "\n",
        "class IndexDataset(Dataset):\n",
        "\n",
        "    def __init__(self, dataset: Dataset):\n",
        "        self.dataset = dataset\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        data, target = self.dataset.__getitem__(index)\n",
        "        return data, target, index\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.dataset.__len__()\n",
        "\n",
        "\n",
        "class ClassSubset(Subset):\n",
        "\n",
        "    def __init__(self, dataset: Dataset[T_co], indices: Sequence[int], classes: Sequence[int]) -> None:\n",
        "        super().__init__(dataset, indices)\n",
        "        self.cls_map = {c: i for i, c in enumerate(classes)}\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img, target = self.dataset[self.indices[idx]]\n",
        "        return img, self.cls_map[target]\n",
        "\n",
        "\n",
        "class DataUtils:\n",
        "\n",
        "    @staticmethod\n",
        "    def create_dataset_subset(dataset: Dataset, classes: list, indices_path: str):\n",
        "        if os.path.exists(indices_path):\n",
        "            print(f'Loading indices from {indices_path}')\n",
        "            return ClassSubset(dataset, torch.load(indices_path), classes)\n",
        "\n",
        "        indices_per_class = DataUtils.get_class_indices(IndexDataset(dataset))\n",
        "\n",
        "        indices = []\n",
        "        for c in classes:\n",
        "            indices.extend(indices_per_class[c])\n",
        "\n",
        "        print(f'Writing indices to {indices_path}')\n",
        "        torch.save(indices, indices_path)\n",
        "\n",
        "        return ClassSubset(dataset, indices, classes)\n",
        "\n",
        "    @staticmethod\n",
        "    def create_dataset(root: str, dir_name: str, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None,\n",
        "                       download: bool = False, download_func: Optional[Callable] = None, zip_file: str = None, post_func: Optional[Callable] = None):\n",
        "        input_folder = os.path.join(root, dir_name)\n",
        "\n",
        "        if not os.path.exists(input_folder):\n",
        "            if download and download_func is not None:\n",
        "                print('Downloading the dataset')\n",
        "                download_func()\n",
        "\n",
        "                if os.path.exists(f'{root}/{zip_file}'):\n",
        "                    print(f'Extracting from {zip_file}')\n",
        "\n",
        "                    with zipfile.ZipFile(f'{root}/{zip_file}', 'r') as zip_ref:\n",
        "                        zip_ref.extractall(root)\n",
        "            else:\n",
        "                raise RuntimeError('Dataset not found. You can use download=True to download it')\n",
        "\n",
        "        if post_func is not None:\n",
        "            post_func(input_folder)\n",
        "\n",
        "        return ImageFolder(input_folder, transform, target_transform)\n",
        "\n",
        "    @staticmethod\n",
        "    def get_class_indices(dataset: IndexDataset) -> Dict[int, list]:\n",
        "        class_indices = collections.defaultdict(list)\n",
        "\n",
        "        for inputs, labels, indices in DataLoader(dataset, batch_size=1024, num_workers=4):\n",
        "            for label, idx in zip(labels.tolist(), indices.tolist()):\n",
        "                class_indices[label].append(idx)\n",
        "\n",
        "        return class_indices"
      ],
      "metadata": {
        "id": "TmH6zYEhnT9J"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install wget"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ks7Xa067m4Th",
        "outputId": "cc95916d-1d03-41d4-b4ba-d9ff3f009189"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9675 sha256=dc982a2569d0ed4a26d95302a250e14bdee65901e043c53f5e83d1fcd656cdc3\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hulgrrgpnZO",
        "outputId": "0f287498-ebf0-48e0-d336-a094d7a81f3a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_cifar_resnext29_pth_tar = '/content/drive/MyDrive/pth files/cifar_resnext29.pth.tar'\n",
        "svhn_train_save_path = '/content/drive/MyDrive/pth files/svhn10-2-train.pt'\n",
        "svhn_test_save_path = '/content/drive/MyDrive/pth files/svhn10-2-test.pt'"
      ],
      "metadata": {
        "id": "dXEVzJdep0Ii"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #data.data_collection\n",
        "\n",
        "import torch\n",
        "import wget\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from PIL import Image\n",
        "\n",
        "# from data.cifar100_coarse import CIFAR100Coarse\n",
        "# from data.data_utils import DataUtils\n",
        "# from data.post_funcs import imagenet200_val_post\n",
        "# from data.tensor_set import TensorDataset\n",
        "\n",
        "pytorch_data_root = './pytorch_data'\n",
        "arff_data_root = './arff_data'\n",
        "\n",
        "\n",
        "\n",
        "data_creators = {\n",
        "    # 'MNIST-TRAIN': lambda: datasets.MNIST(pytorch_data_root, train=True, download=True, transform=transforms.Compose([transforms.ToTensor()])),\n",
        "    # 'MNIST-TEST': lambda: datasets.MNIST(pytorch_data_root, train=False, download=True, transform=transforms.Compose([transforms.ToTensor()])),\n",
        "    # 'MNIST-TRAIN-FLAT': lambda: datasets.MNIST(pytorch_data_root, train=True, download=True, transform=transforms.Compose([transforms.ToTensor(), transforms.Lambda(lambda x: torch.flatten(x))])),\n",
        "    # 'MNIST-TEST-FLAT': lambda: datasets.MNIST(pytorch_data_root, train=False, download=True, transform=transforms.Compose([transforms.ToTensor(), transforms.Lambda(lambda x: torch.flatten(x))])),\n",
        "    # 'MNIST-TRAIN-TENSOR': lambda: TensorDataset(f'{pytorch_data_root}/extracted/mnist10-train.pt'),\n",
        "    # 'MNIST-TEST-TENSOR': lambda: TensorDataset(f'{pytorch_data_root}/extracted/mnist10-test.pt'),\n",
        "    # 'FASHION-TRAIN': lambda: datasets.FashionMNIST(pytorch_data_root, train=True, download=True, transform=transforms.Compose([transforms.RandomHorizontalFlip(), transforms.ToTensor()])),\n",
        "    # 'FASHION-TEST': lambda: datasets.FashionMNIST(pytorch_data_root, train=False, download=True, transform=transforms.Compose([transforms.ToTensor()])),\n",
        "    # 'FASHION-TRAIN-FLAT': lambda: datasets.FashionMNIST(pytorch_data_root, train=True, download=True, transform=transforms.Compose([transforms.RandomHorizontalFlip(), transforms.ToTensor(), transforms.Lambda(lambda x: torch.flatten(x))])),\n",
        "    # 'FASHION-TEST-FLAT': lambda: datasets.FashionMNIST(pytorch_data_root, train=False, download=True, transform=transforms.Compose([transforms.ToTensor(), transforms.Lambda(lambda x: torch.flatten(x))])),\n",
        "    # 'FASHION-TRAIN-TENSOR': lambda: TensorDataset(f'{pytorch_data_root}/extracted/fashion10-train.pt'),\n",
        "    # 'FASHION-TEST-TENSOR': lambda: TensorDataset(f'{pytorch_data_root}/extracted/fashion10-test.pt'),\n",
        "    'SVHN-TRAIN': lambda: datasets.SVHN(pytorch_data_root, split='train', transform=transforms.Compose([transforms.ToTensor()]), download=True),\n",
        "    'SVHN-TEST': lambda: datasets.SVHN(pytorch_data_root, split='test', transform=transforms.Compose([transforms.ToTensor()]), download=True),\n",
        "    'SVHN-TRAIN-TENSOR': lambda: TensorDataset(svhn_train_save_path),\n",
        "    'SVHN-TEST-TENSOR': lambda: TensorDataset(svhn_test_save_path),\n",
        "    # 'SVHN-TRAIN-TENSOR': lambda: TensorDataset(f'{pytorch_data_root}/extracted/svhn10-train.pt'),\n",
        "    # 'SVHN-TEST-TENSOR': lambda: TensorDataset(f'{pytorch_data_root}/extracted/svhn10-test.pt'),\n",
        "    # 'CIFAR10-TRAIN': lambda: datasets.CIFAR10(pytorch_data_root, True, transform=transforms.Compose([transforms.RandomHorizontalFlip(), transforms.ToTensor()]), download=True),\n",
        "    # 'CIFAR10-TEST': lambda: datasets.CIFAR10(pytorch_data_root, False, transform=transforms.Compose([transforms.ToTensor()]), download=True),\n",
        "    # 'CIFAR10-TRAIN-TENSOR': lambda: TensorDataset(f'{pytorch_data_root}/extracted/cifar10-train.pt'),\n",
        "    # 'CIFAR10-TEST-TENSOR': lambda: TensorDataset(f'{pytorch_data_root}/extracted/cifar10-test.pt'),\n",
        "    # 'CIFAR100-TRAIN': lambda: datasets.CIFAR100(pytorch_data_root, True, transform=transforms.Compose([transforms.RandomHorizontalFlip(), transforms.ToTensor()]), download=True),\n",
        "    # 'CIFAR100-TEST': lambda: datasets.CIFAR100(pytorch_data_root, False, transform=transforms.Compose([transforms.ToTensor()]), download=True),\n",
        "    # 'CIFAR20C-TRAIN': lambda: CIFAR100Coarse(pytorch_data_root, train=True, transform=transforms.Compose([transforms.RandomHorizontalFlip(), transforms.ToTensor()]), download=True),\n",
        "    # 'CIFAR20C-TEST': lambda: CIFAR100Coarse(pytorch_data_root, train=False, transform=transforms.Compose([transforms.ToTensor()]), download=True),\n",
        "    # 'CIFAR20C-TRAIN-TENSOR': lambda: TensorDataset(f'{pytorch_data_root}/extracted/cifar20c-train.pt'),\n",
        "    # 'CIFAR20C-TEST-TENSOR': lambda: TensorDataset(f'{pytorch_data_root}/extracted/cifar20c-test.pt'),\n",
        "    # 'IMAGENET200-TRAIN': lambda: DataUtils.create_dataset(pytorch_data_root, 'tiny-imagenet-200/train',\n",
        "    #                                                       transform=transforms.Compose([transforms.Resize((224, 224), interpolation=Image.NEAREST), transforms.ToTensor()]),\n",
        "    #                                             download=True, download_func=lambda: wget.download('http://cs231n.stanford.edu/tiny-imagenet-200.zip', pytorch_data_root),\n",
        "    #                                             zip_file='tiny-imagenet-200.zip',),\n",
        "    # 'IMAGENET200-TEST': lambda: DataUtils.create_dataset(pytorch_data_root, 'tiny-imagenet-200/val',\n",
        "    #                                                      transform=transforms.Compose([transforms.Resize((224, 224), interpolation=Image.NEAREST), transforms.ToTensor()]),\n",
        "    #                                            download=True, download_func=lambda: wget.download('http://cs231n.stanford.edu/tiny-imagenet-200.zip', pytorch_data_root),\n",
        "    #                                            zip_file='tiny-imagenet-200.zip', post_func=imagenet200_val_post),\n",
        "    # 'IMAGENET10-TRAIN': lambda: DataUtils.create_dataset_subset(get('IMAGENET200-TRAIN'), [0, 22, 25, 68, 117, 145, 153, 176, 188, 198], f'{pytorch_data_root}/imagenet10-train-indices.pt'),\n",
        "    # 'IMAGENET10-TEST': lambda: DataUtils.create_dataset_subset(get('IMAGENET200-TEST'), [0, 22, 25, 68, 117, 145, 153, 176, 188, 198], f'{pytorch_data_root}/imagenet10-test-indices.pt'),\n",
        "    # 'IMAGENET10-TRAIN-TENSOR': lambda: TensorDataset(f'{pytorch_data_root}/extracted/imagenet10-train.pt'),\n",
        "    # 'IMAGENET10-TEST-TENSOR': lambda: TensorDataset(f'{pytorch_data_root}/extracted/imagenet10-test.pt'),\n",
        "    # 'IMAGENET20A-TRAIN': lambda: DataUtils.create_dataset_subset(get('IMAGENET200-TRAIN'), [i * 10 - 1 for i in range(1, 21)], f'{pytorch_data_root}/imagenet20a-train-indices.pt'),\n",
        "    # 'IMAGENET20A-TEST': lambda: DataUtils.create_dataset_subset(get('IMAGENET200-TEST'), [i * 10 - 1 for i in range(1, 21)], f'{pytorch_data_root}/imagenet20a-test-indices.pt'),\n",
        "    # 'IMAGENET20A-TRAIN-TENSOR': lambda: TensorDataset(f'{pytorch_data_root}/extracted/imagenet20a-train.pt'),\n",
        "    # 'IMAGENET20A-TEST-TENSOR': lambda: TensorDataset(f'{pytorch_data_root}/extracted/imagenet20a-test.pt'),\n",
        "    # 'IMAGENET20B-TRAIN': lambda: DataUtils.create_dataset_subset(get('IMAGENET200-TRAIN'), [i * 10 - 5 for i in range(1, 21)], f'{pytorch_data_root}/imagenet20b-train-indices.pt'),\n",
        "    # 'IMAGENET20B-TEST': lambda: DataUtils.create_dataset_subset(get('IMAGENET200-TEST'), [i * 10 - 5 for i in range(1, 21)], f'{pytorch_data_root}/imagenet20b-test-indices.pt'),\n",
        "    # 'IMAGENET20B-TRAIN-TENSOR': lambda: TensorDataset(f'{pytorch_data_root}/extracted/imagenet20b-train.pt'),\n",
        "    # 'IMAGENET20B-TEST-TENSOR': lambda: TensorDataset(f'{pytorch_data_root}/extracted/imagenet20b-test.pt'),\n",
        "    # 'CELEB-TRAIN': lambda: datasets.CelebA(pytorch_data_root, split='train', target_type='identity', transform=transforms.Compose([transforms.ToTensor()]), download=True),\n",
        "    # 'CELEB-TEST': lambda: datasets.CelebA(pytorch_data_root, split='test', target_type='identity', transform=transforms.Compose([transforms.ToTensor()]), download=True)\n",
        "\n",
        "    # TODO:\n",
        "    # CORE50: https://vlomonaco.github.io/core50/index.html#dataset\n",
        "    # IMAGENET1000 (64): https://patrykchrabaszcz.github.io/Imagenet32/\n",
        "\n",
        "    # A) MNIST, FASHION, SVHN, CIFAR10, IMG10\n",
        "    # B) CORE50, CIFAR100, IMG200\n",
        "    # C) CELEB, IMG1000\n",
        "}\n",
        "\n",
        "class data_collection():\n",
        "  def get(name: str):\n",
        "      return data_creators[name]()"
      ],
      "metadata": {
        "id": "ia_VXUrvmtOH"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchsummary import summary\n",
        "\n",
        "# from data.tensor_set import extract_features\n",
        "# from learners.models.resnext import create_cifar_resnext\n",
        "# import data.data_collection as data_col\n",
        "\n",
        "\n",
        "def extract(last):\n",
        "    print('Running')\n",
        "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # cifar_resnext29.pth.tar -> https://github.com/bearpaw/pytorch-classification/blob/master/models/cifar/resnext.py\n",
        "\n",
        "    extractor = create_cifar_resnext(path_cifar_resnext29_pth_tar)\n",
        "    extractor.classifier = torch.nn.Identity()\n",
        "    extractor.eval().to(device)\n",
        "    summary(extractor.to(device), (3, 32, 32))\n",
        "    dataset = data_collection.get('SVHN-TRAIN')\n",
        "    extract_features(dataset, extractor, svhn_train_save_path, device=device)\n",
        "    dataset = data_collection.get('SVHN-TEST')\n",
        "    extract_features(dataset, extractor, svhn_test_save_path, device=device)\n",
        "\n",
        "    # extractor = create_cifar_resnext(path_cifar_resnext29_pth_tar)\n",
        "    # extractor.classifier = torch.nn.Identity()\n",
        "    # extractor.eval().to(device)\n",
        "    # summary(extractor.to(device), (3, 32, 32))\n",
        "    # dataset = data_collection.get('CIFAR20C-TRAIN')\n",
        "    # extract_features(dataset, extractor, f'pytorch_data/extracted/cifar20c-train.pt', device=device)\n",
        "    # dataset = data_collection.get('CIFAR20C-TEST')\n",
        "    # extract_features(dataset, extractor, f'pytorch_data/extracted/cifar20c-test.pt', device=device)\n",
        "\n",
        "    # extractor = torchvision.models.resnet18(pretrained=True)\n",
        "    # fc1 = extractor.fc\n",
        "    # extractor.fc = torch.nn.Sequential(fc1, torch.nn.Linear(1000, 256), torch.nn.ReLU(), torch.nn.Linear(256, 20))\n",
        "    # extractor.load_state_dict(torch.load('pytorch_models/imgnet20a-2f.pth'))\n",
        "    # if not last: extractor.fc = torch.nn.Identity()\n",
        "    # extractor.eval().to(device)\n",
        "    # dataset = data_collection.get('IMAGENET20A-TRAIN')\n",
        "    # extract_features(dataset, extractor, f'pytorch_data/extracted/imagenet20a-train.pt', device=device)\n",
        "    # dataset = data_collection.get('IMAGENET20A-TEST')\n",
        "    # extract_features(dataset, extractor, f'pytorch_data/extracted/imagenet20a-test.pt', device=device)\n",
        "\n",
        "    # extractor = torchvision.models.resnet18(pretrained=True)\n",
        "    # fc1 = extractor.fc\n",
        "    # extractor.fc = torch.nn.Sequential(fc1, torch.nn.Linear(1000, 256), torch.nn.ReLU(), torch.nn.Linear(256, 20))\n",
        "    # extractor.load_state_dict(torch.load('pytorch_models/imgnet20b-2f.pth'))\n",
        "    # if not last: extractor.fc = torch.nn.Identity()\n",
        "    # extractor.eval().to(device)\n",
        "    # dataset = data_collection.get('IMAGENET20B-TRAIN')\n",
        "    # extract_features(dataset, extractor, f'pytorch_data/extracted/imagenet20b-train.pt', device=device)\n",
        "    # dataset = data_collection.get('IMAGENET20B-TEST')\n",
        "    # extract_features(dataset, extractor, f'pytorch_data/extracted/imagenet20b-test.pt', device=device)\n"
      ],
      "metadata": {
        "id": "rovl8WLZn5ZG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extract(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "09b57d31525e4a288cd1ba6ad599116f",
            "3d24cdb053d146599434871de0ac53fa",
            "9c4fe8a3ec624b3c97ae47556d0272dd",
            "0ba664480d364f4f81d95ea53de7b0b0",
            "33eb6b7fd85549448e9b133fdca196fe",
            "72d0a6d98d604461af56cc086378b056",
            "9e1044c6828c463e87220756d06cdab0",
            "a474a8b8aeff4ef98ef842b7cfb1fc1d",
            "504d505eeaf54ce2ba62e2e35e115ac3",
            "bcd6bb8117ee46a7ad391c15b596cdf3",
            "6aa1c3b1ee504009a698898a0668711d",
            "d7d3a8f2e21a4d5fb66f19dfacb14219",
            "dc4cb4abe16d451391b8aa9baa3a60d4",
            "99105534d7944512a021ea86f1f29b2b",
            "68abfe89ab2441329676b7dac0171aa4",
            "914ab31848d44a83aa559c67617cb39d",
            "34fa3ec8137148c4ba2c2783d42549b8",
            "c10ce811a9ef4abfa963b8dbea08b0f4",
            "a123e8831481462aa94a885e411707eb",
            "9e3340ffbbae4d7fa7e4e068a62c2c0c",
            "1a557b1d1b6f49bab6a97aea0672b446",
            "9f1e83ce1be049d99c61fc34027169d6"
          ]
        },
        "id": "leU44M42pMCR",
        "outputId": "d2020fff-2393-4b1a-e847-0b03904910de"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:87: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:92: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1          [-1, 256, 32, 32]          16,384\n",
            "       BatchNorm2d-2          [-1, 256, 32, 32]             512\n",
            " ResNeXtBottleneck-3          [-1, 256, 32, 32]               0\n",
            " ResNeXtBottleneck-4          [-1, 256, 32, 32]               0\n",
            " ResNeXtBottleneck-5          [-1, 256, 32, 32]               0\n",
            "            Conv2d-6          [-1, 512, 16, 16]         131,072\n",
            "       BatchNorm2d-7          [-1, 512, 16, 16]           1,024\n",
            " ResNeXtBottleneck-8          [-1, 512, 16, 16]               0\n",
            " ResNeXtBottleneck-9          [-1, 512, 16, 16]               0\n",
            "ResNeXtBottleneck-10          [-1, 512, 16, 16]               0\n",
            "           Conv2d-11           [-1, 1024, 8, 8]         524,288\n",
            "      BatchNorm2d-12           [-1, 1024, 8, 8]           2,048\n",
            "ResNeXtBottleneck-13           [-1, 1024, 8, 8]               0\n",
            "ResNeXtBottleneck-14           [-1, 1024, 8, 8]               0\n",
            "ResNeXtBottleneck-15           [-1, 1024, 8, 8]               0\n",
            "     CifarResNeXt-16                  [-1, 512]               0\n",
            "================================================================\n",
            "Total params: 675,328\n",
            "Trainable params: 675,328\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 17.50\n",
            "Params size (MB): 2.58\n",
            "Estimated Total Size (MB): 20.09\n",
            "----------------------------------------------------------------\n",
            "Downloading http://ufldl.stanford.edu/housenumbers/train_32x32.mat to ./pytorch_data/train_32x32.mat\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/182040794 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "09b57d31525e4a288cd1ba6ad599116f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/287 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 1/287 [00:04<19:05,  4.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "256\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 2/287 [00:07<16:54,  3.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "512\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 3/287 [00:10<16:12,  3.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "768\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|▏         | 4/287 [00:13<15:50,  3.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "1024\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 5/287 [00:17<15:36,  3.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "1280\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 6/287 [00:20<15:27,  3.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "1536\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 7/287 [00:22<14:04,  3.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "1792\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 8/287 [00:25<12:57,  2.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "2048\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 9/287 [00:27<12:12,  2.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "2304\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 10/287 [00:29<11:40,  2.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "2560\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 11/287 [00:31<11:18,  2.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "2816\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 12/287 [00:34<11:02,  2.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "3072\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▍         | 13/287 [00:36<10:50,  2.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "3328\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▍         | 14/287 [00:38<10:41,  2.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "3584\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 15/287 [00:41<10:34,  2.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "3840\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 16/287 [00:43<10:28,  2.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "4096\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 17/287 [00:45<10:24,  2.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "4352\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▋         | 18/287 [00:47<10:21,  2.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "4608\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 19/287 [00:50<10:17,  2.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "4864\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 20/287 [00:52<10:13,  2.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "5120\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 21/287 [00:54<10:10,  2.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "5376\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 22/287 [00:57<10:08,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "5632\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 23/287 [00:59<10:06,  2.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "5888\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 24/287 [01:01<10:03,  2.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "6144\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▊         | 25/287 [01:03<10:00,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "6400\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 26/287 [01:06<09:57,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "6656\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 27/287 [01:08<09:55,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "6912\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|▉         | 28/287 [01:10<09:54,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "7168\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 29/287 [01:13<09:52,  2.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "7424\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 30/287 [01:15<09:49,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "7680\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 31/287 [01:17<09:46,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "7936\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 32/287 [01:20<09:44,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "8192\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█▏        | 33/287 [01:22<09:42,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "8448\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 34/287 [01:24<09:40,  2.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "8704\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 35/287 [01:26<09:38,  2.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "8960\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 36/287 [01:29<09:36,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "9216\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 37/287 [01:31<09:34,  2.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "9472\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 38/287 [01:33<09:31,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "9728\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▎        | 39/287 [01:36<09:28,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "9984\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 40/287 [01:38<09:25,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "10240\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 41/287 [01:40<09:23,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "10496\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▍        | 42/287 [01:42<09:20,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "10752\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▍        | 43/287 [01:45<09:18,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "11008\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 44/287 [01:47<09:15,  2.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "11264\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 45/287 [01:49<09:13,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "11520\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 46/287 [01:52<09:11,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "11776\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▋        | 47/287 [01:54<09:09,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "12032\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 48/287 [01:56<09:06,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "12288\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 49/287 [01:58<09:04,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "12544\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 50/287 [02:01<09:02,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "12800\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 51/287 [02:03<09:00,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "13056\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 52/287 [02:05<08:58,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "13312\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 53/287 [02:08<08:55,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "13568\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▉        | 54/287 [02:10<08:53,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "13824\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▉        | 55/287 [02:12<08:51,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "14080\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|█▉        | 56/287 [02:15<08:48,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "14336\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|█▉        | 57/287 [02:17<08:45,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "14592\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 58/287 [02:19<08:43,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "14848\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██        | 59/287 [02:21<08:42,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "15104\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██        | 60/287 [02:24<08:39,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "15360\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██▏       | 61/287 [02:26<08:38,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "15616\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 62/287 [02:28<08:34,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "15872\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 63/287 [02:31<08:33,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "16128\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 64/287 [02:33<08:30,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "16384\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 65/287 [02:35<08:28,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "16640\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 66/287 [02:37<08:25,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "16896\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 67/287 [02:40<08:23,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "17152\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▎       | 68/287 [02:42<08:20,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "17408\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 69/287 [02:44<08:19,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "17664\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 70/287 [02:47<08:16,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "17920\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▍       | 71/287 [02:49<08:14,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "18176\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 72/287 [02:51<08:12,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "18432\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 73/287 [02:53<08:09,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "18688\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 74/287 [02:56<08:07,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "18944\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 75/287 [02:58<08:05,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "19200\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▋       | 76/287 [03:00<08:04,  2.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "19456\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 77/287 [03:03<08:01,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "19712\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 78/287 [03:05<07:58,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "19968\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 79/287 [03:07<07:55,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "20224\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 80/287 [03:09<07:53,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "20480\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 81/287 [03:12<07:50,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "20736\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▊       | 82/287 [03:14<07:49,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "20992\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▉       | 83/287 [03:16<07:46,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "21248\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▉       | 84/287 [03:19<07:45,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "21504\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|██▉       | 85/287 [03:21<07:42,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "21760\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|██▉       | 86/287 [03:23<07:40,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "22016\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 87/287 [03:25<07:37,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "22272\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███       | 88/287 [03:28<07:35,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "22528\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███       | 89/287 [03:30<07:33,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "22784\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███▏      | 90/287 [03:32<07:31,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "23040\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 91/287 [03:35<07:29,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "23296\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 92/287 [03:37<07:25,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "23552\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 93/287 [03:39<07:22,  2.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "23808\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 94/287 [03:41<07:21,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "24064\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 95/287 [03:44<07:18,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "24320\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 96/287 [03:46<07:16,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "24576\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 97/287 [03:48<07:13,  2.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "24832\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 98/287 [03:51<07:12,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "25088\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 99/287 [03:53<07:10,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "25344\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▍      | 100/287 [03:55<07:07,  2.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "25600\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 101/287 [03:57<07:04,  2.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "25856\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 102/287 [04:00<07:03,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "26112\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 103/287 [04:02<07:01,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "26368\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 104/287 [04:04<06:59,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "26624\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 105/287 [04:07<06:56,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "26880\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 106/287 [04:09<06:53,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "27136\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 107/287 [04:11<06:51,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "27392\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 108/287 [04:14<06:49,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "27648\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 109/287 [04:16<06:46,  2.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "27904\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 110/287 [04:18<06:44,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "28160\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 39%|███▊      | 111/287 [04:20<06:42,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "28416\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 39%|███▉      | 112/287 [04:23<06:40,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "28672\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 39%|███▉      | 113/287 [04:25<06:37,  2.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "28928\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|███▉      | 114/287 [04:27<06:35,  2.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "29184\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 115/287 [04:30<06:33,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "29440\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 116/287 [04:32<06:30,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "29696\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████      | 117/287 [04:34<06:29,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "29952\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████      | 118/287 [04:36<06:28,  2.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "30208\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████▏     | 119/287 [04:39<06:24,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "30464\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 120/287 [04:41<06:22,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "30720\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 121/287 [04:43<06:20,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "30976\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 122/287 [04:46<06:18,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "31232\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 123/287 [04:48<06:16,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "31488\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 124/287 [04:50<06:13,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "31744\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▎     | 125/287 [04:52<06:10,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "32000\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 126/287 [04:55<06:08,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "32256\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 127/287 [04:57<06:06,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "32512\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▍     | 128/287 [04:59<06:04,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "32768\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▍     | 129/287 [05:02<06:01,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "33024\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▌     | 130/287 [05:04<05:59,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "33280\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 131/287 [05:06<05:57,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "33536\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 132/287 [05:08<05:54,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "33792\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▋     | 133/287 [05:11<05:51,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "34048\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 134/287 [05:13<05:49,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "34304\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 135/287 [05:15<05:47,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "34560\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 136/287 [05:18<05:45,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "34816\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 137/287 [05:20<05:42,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "35072\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 138/287 [05:22<05:40,  2.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "35328\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 139/287 [05:24<05:38,  2.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "35584\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▉     | 140/287 [05:27<05:36,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "35840\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▉     | 141/287 [05:29<05:33,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "36096\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▉     | 142/287 [05:31<05:31,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "36352\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|████▉     | 143/287 [05:34<05:29,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "36608\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 144/287 [05:36<05:27,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "36864\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████     | 145/287 [05:38<05:25,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "37120\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████     | 146/287 [05:40<05:22,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "37376\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████     | 147/287 [05:43<05:20,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "37632\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 148/287 [05:45<05:18,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "37888\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 149/287 [05:47<05:15,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "38144\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 150/287 [05:50<05:13,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "38400\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 151/287 [05:52<05:11,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "38656\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 152/287 [05:54<05:08,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "38912\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 153/287 [05:56<05:06,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "39168\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▎    | 154/287 [05:59<05:04,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "39424\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 155/287 [06:01<05:01,  2.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "39680\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 156/287 [06:03<04:59,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "39936\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▍    | 157/287 [06:06<04:57,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "40192\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▌    | 158/287 [06:08<04:55,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "40448\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▌    | 159/287 [06:10<04:53,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "40704\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 160/287 [06:12<04:50,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "40960\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 161/287 [06:15<04:48,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "41216\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▋    | 162/287 [06:17<04:45,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "41472\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 163/287 [06:19<04:43,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "41728\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 164/287 [06:22<04:41,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "41984\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 165/287 [06:24<04:39,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "42240\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 166/287 [06:26<04:36,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "42496\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 167/287 [06:29<04:34,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "42752\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▊    | 168/287 [06:31<04:32,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "43008\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▉    | 169/287 [06:33<04:30,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "43264\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▉    | 170/287 [06:35<04:27,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "43520\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|█████▉    | 171/287 [06:38<04:25,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "43776\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|█████▉    | 172/287 [06:40<04:23,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "44032\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 173/287 [06:42<04:21,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "44288\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 61%|██████    | 174/287 [06:45<04:18,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "44544\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 61%|██████    | 175/287 [06:47<04:16,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "44800\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 61%|██████▏   | 176/287 [06:49<04:14,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "45056\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 177/287 [06:51<04:11,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "45312\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 178/287 [06:54<04:09,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "45568\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 179/287 [06:56<04:07,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "45824\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 180/287 [06:58<04:04,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "46080\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 181/287 [07:01<04:02,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "46336\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 182/287 [07:03<04:00,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "46592\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 183/287 [07:05<03:58,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "46848\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 184/287 [07:07<03:56,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "47104\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 185/287 [07:10<03:54,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "47360\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▍   | 186/287 [07:12<03:51,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "47616\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 187/287 [07:14<03:48,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "47872\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 188/287 [07:17<03:46,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "48128\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 189/287 [07:19<03:44,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "48384\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 190/287 [07:21<03:42,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "48640\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 191/287 [07:23<03:39,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "48896\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 192/287 [07:26<03:37,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "49152\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 193/287 [07:28<03:35,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "49408\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 194/287 [07:30<03:33,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "49664\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 195/287 [07:33<03:31,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "49920\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 196/287 [07:35<03:28,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "50176\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▊   | 197/287 [07:37<03:26,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "50432\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▉   | 198/287 [07:40<03:23,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "50688\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▉   | 199/287 [07:42<03:21,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "50944\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|██████▉   | 200/287 [07:44<03:19,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "51200\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 201/287 [07:46<03:17,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "51456\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 202/287 [07:49<03:14,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "51712\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████   | 203/287 [07:51<03:12,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "51968\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████   | 204/287 [07:53<03:09,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "52224\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████▏  | 205/287 [07:56<03:07,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "52480\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 206/287 [07:58<03:05,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "52736\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 207/287 [08:00<03:03,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "52992\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 208/287 [08:02<03:00,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "53248\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 209/287 [08:05<02:58,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "53504\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 210/287 [08:07<02:56,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "53760\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▎  | 211/287 [08:09<02:53,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "54016\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 212/287 [08:12<02:51,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "54272\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 213/287 [08:14<02:49,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "54528\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▍  | 214/287 [08:16<02:47,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "54784\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▍  | 215/287 [08:18<02:44,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "55040\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 216/287 [08:21<02:42,  2.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "55296\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 217/287 [08:23<02:40,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "55552\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 218/287 [08:25<02:37,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "55808\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▋  | 219/287 [08:28<02:35,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "56064\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 220/287 [08:30<02:33,  2.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "56320\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 221/287 [08:32<02:30,  2.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "56576\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 222/287 [08:34<02:28,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "56832\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 223/287 [08:37<02:26,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "57088\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 224/287 [08:39<02:23,  2.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "57344\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 225/287 [08:41<02:21,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "57600\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▊  | 226/287 [08:44<02:19,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "57856\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▉  | 227/287 [08:46<02:17,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "58112\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▉  | 228/287 [08:48<02:14,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "58368\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|███████▉  | 229/287 [08:50<02:12,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "58624\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 230/287 [08:53<02:10,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "58880\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 231/287 [08:55<02:08,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "59136\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|████████  | 232/287 [08:57<02:05,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "59392\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|████████  | 233/287 [09:00<02:03,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "59648\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 234/287 [09:02<02:01,  2.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "59904\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 235/287 [09:04<01:59,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "60160\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 236/287 [09:06<01:56,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "60416\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 237/287 [09:09<01:54,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "60672\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 238/287 [09:11<01:52,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "60928\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 239/287 [09:13<01:49,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "61184\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▎ | 240/287 [09:16<01:47,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "61440\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 241/287 [09:18<01:45,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "61696\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 242/287 [09:20<01:43,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "61952\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▍ | 243/287 [09:22<01:41,  2.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "62208\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 244/287 [09:25<01:38,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "62464\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 245/287 [09:27<01:36,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "62720\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 246/287 [09:29<01:33,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "62976\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 247/287 [09:32<01:31,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "63232\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▋ | 248/287 [09:34<01:29,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "63488\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 249/287 [09:36<01:27,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "63744\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 250/287 [09:39<01:24,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "64000\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 251/287 [09:41<01:22,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "64256\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 252/287 [09:43<01:20,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "64512\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 253/287 [09:45<01:17,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "64768\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▊ | 254/287 [09:48<01:15,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "65024\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▉ | 255/287 [09:50<01:13,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "65280\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▉ | 256/287 [09:52<01:11,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "65536\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|████████▉ | 257/287 [09:55<01:08,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "65792\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|████████▉ | 258/287 [09:57<01:06,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "66048\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 259/287 [09:59<01:04,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "66304\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████ | 260/287 [10:01<01:01,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "66560\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████ | 261/287 [10:04<00:59,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "66816\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████▏| 262/287 [10:06<00:57,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "67072\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 263/287 [10:08<00:55,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "67328\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 264/287 [10:11<00:52,  2.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "67584\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 265/287 [10:13<00:50,  2.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "67840\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 266/287 [10:15<00:48,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "68096\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 267/287 [10:17<00:45,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "68352\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 268/287 [10:20<00:43,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "68608\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▎| 269/287 [10:22<00:41,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "68864\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 270/287 [10:24<00:38,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "69120\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 271/287 [10:27<00:36,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "69376\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▍| 272/287 [10:29<00:34,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "69632\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 273/287 [10:31<00:32,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "69888\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 274/287 [10:33<00:29,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "70144\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 275/287 [10:36<00:27,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "70400\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 276/287 [10:38<00:25,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "70656\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 277/287 [10:40<00:22,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "70912\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 278/287 [10:43<00:20,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "71168\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 279/287 [10:45<00:18,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "71424\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 280/287 [10:47<00:16,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "71680\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 281/287 [10:50<00:13,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "71936\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 282/287 [10:52<00:11,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "72192\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▊| 283/287 [10:54<00:09,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "72448\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▉| 284/287 [10:56<00:06,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "72704\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▉| 285/287 [10:59<00:04,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "72960\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r100%|█████████▉| 286/287 [11:01<00:02,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "73216\n",
            "in torch.Size([41, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 287/287 [11:02<00:00,  2.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([41, 512])\n",
            "73257\n",
            "Saving to /content/drive/MyDrive/pth files/svhn10-2-train.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://ufldl.stanford.edu/housenumbers/test_32x32.mat to ./pytorch_data/test_32x32.mat\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/64275384 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d7d3a8f2e21a4d5fb66f19dfacb14219"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/102 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 1/102 [00:02<04:49,  2.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "256\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 2/102 [00:05<04:11,  2.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "512\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 3/102 [00:07<03:59,  2.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "768\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 4/102 [00:09<03:52,  2.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "1024\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▍         | 5/102 [00:12<03:47,  2.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "1280\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 6/102 [00:14<03:43,  2.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "1536\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 7/102 [00:16<03:39,  2.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "1792\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 8/102 [00:18<03:36,  2.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "2048\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 9/102 [00:21<03:34,  2.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "2304\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|▉         | 10/102 [00:23<03:31,  2.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "2560\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 11/102 [00:25<03:28,  2.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "2816\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 12/102 [00:28<03:26,  2.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "3072\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 13/102 [00:30<03:24,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "3328\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▎        | 14/102 [00:32<03:21,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "3584\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▍        | 15/102 [00:34<03:19,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "3840\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 16/102 [00:37<03:17,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "4096\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 17/102 [00:39<03:14,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "4352\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 18/102 [00:41<03:12,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "4608\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▊        | 19/102 [00:44<03:10,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "4864\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|█▉        | 20/102 [00:46<03:08,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "5120\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██        | 21/102 [00:48<03:05,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "5376\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 22/102 [00:50<03:03,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "5632\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 23/102 [00:53<03:01,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "5888\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▎       | 24/102 [00:55<02:58,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "6144\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▍       | 25/102 [00:57<02:56,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "6400\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 26/102 [01:00<02:54,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "6656\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▋       | 27/102 [01:02<02:52,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "6912\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 28/102 [01:04<02:49,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "7168\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 29/102 [01:07<02:47,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "7424\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▉       | 30/102 [01:09<02:45,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "7680\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 31/102 [01:11<02:42,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "7936\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███▏      | 32/102 [01:13<02:40,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "8192\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 33/102 [01:16<02:38,  2.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "8448\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 34/102 [01:18<02:36,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "8704\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 35/102 [01:20<02:33,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "8960\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 36/102 [01:23<02:31,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "9216\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▋      | 37/102 [01:25<02:28,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "9472\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 38/102 [01:27<02:26,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "9728\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 39/102 [01:29<02:24,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "9984\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 39%|███▉      | 40/102 [01:32<02:22,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "10240\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 41/102 [01:34<02:19,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "10496\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████      | 42/102 [01:36<02:17,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "10752\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 43/102 [01:39<02:15,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "11008\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 44/102 [01:41<02:12,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "11264\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 45/102 [01:43<02:10,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "11520\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▌     | 46/102 [01:46<02:08,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "11776\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 47/102 [01:48<02:05,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "12032\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 48/102 [01:50<02:03,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "12288\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 49/102 [01:52<02:01,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "12544\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▉     | 50/102 [01:55<01:59,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "12800\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 51/102 [01:57<01:56,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "13056\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████     | 52/102 [01:59<01:54,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "13312\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 53/102 [02:02<01:52,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "13568\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 54/102 [02:04<01:49,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "13824\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 55/102 [02:06<01:47,  2.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "14080\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▍    | 56/102 [02:08<01:45,  2.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "14336\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 57/102 [02:11<01:43,  2.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "14592\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 58/102 [02:13<01:40,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "14848\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 59/102 [02:15<01:38,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "15104\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▉    | 60/102 [02:18<01:36,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "15360\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|█████▉    | 61/102 [02:20<01:33,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "15616\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 61%|██████    | 62/102 [02:22<01:31,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "15872\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 63/102 [02:24<01:29,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "16128\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 64/102 [02:27<01:27,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "16384\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▎   | 65/102 [02:29<01:24,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "16640\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▍   | 66/102 [02:31<01:22,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "16896\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 67/102 [02:34<01:20,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "17152\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 68/102 [02:36<01:17,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "17408\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 69/102 [02:38<01:15,  2.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "17664\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▊   | 70/102 [02:41<01:13,  2.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "17920\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|██████▉   | 71/102 [02:43<01:11,  2.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "18176\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████   | 72/102 [02:45<01:08,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "18432\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 73/102 [02:47<01:06,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "18688\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 74/102 [02:50<01:04,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "18944\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▎  | 75/102 [02:52<01:01,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "19200\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▍  | 76/102 [02:54<00:59,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "19456\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 77/102 [02:57<00:57,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "19712\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▋  | 78/102 [02:59<00:54,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "19968\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 79/102 [03:01<00:52,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "20224\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 80/102 [03:03<00:50,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "20480\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▉  | 81/102 [03:06<00:48,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "20736\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 82/102 [03:08<00:45,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "20992\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|████████▏ | 83/102 [03:10<00:43,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "21248\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 84/102 [03:13<00:41,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "21504\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 85/102 [03:15<00:39,  2.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "21760\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 86/102 [03:17<00:36,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "22016\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 87/102 [03:19<00:34,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "22272\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▋ | 88/102 [03:22<00:32,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "22528\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 89/102 [03:24<00:29,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "22784\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 90/102 [03:26<00:27,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "23040\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▉ | 91/102 [03:29<00:25,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "23296\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 92/102 [03:31<00:22,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "23552\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████ | 93/102 [03:33<00:20,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "23808\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 94/102 [03:36<00:18,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "24064\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 95/102 [03:38<00:16,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "24320\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 96/102 [03:40<00:13,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "24576\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 97/102 [03:42<00:11,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "24832\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 98/102 [03:45<00:09,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "25088\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 99/102 [03:47<00:06,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "25344\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 100/102 [03:49<00:04,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "25600\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▉| 101/102 [03:52<00:02,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "25856\n",
            "in torch.Size([176, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 102/102 [03:54<00:00,  2.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([176, 512])\n",
            "26032\n",
            "Saving to /content/drive/MyDrive/pth files/svhn10-2-test.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LL_DT.Runner"
      ],
      "metadata": {
        "id": "Zf9qUAC_umYa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install river"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xM1y_YgL4bc2",
        "outputId": "71d16974-f1a3-491f-8f38-17c6d2b4aa66"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting river\n",
            "  Downloading river-0.10.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 12.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from river) (1.3.5)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from river) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.7/dist-packages (from river) (1.21.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->river) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->river) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.0.1->river) (1.15.0)\n",
            "Installing collected packages: river\n",
            "Successfully installed river-0.10.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ray"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COnc92ZE4bad",
        "outputId": "a4fda85b-0c47-41d5-c927-d71c8c7bf5ce"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ray\n",
            "  Downloading ray-1.11.0-cp37-cp37m-manylinux2014_x86_64.whl (52.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 52.7 MB 2.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray) (3.17.3)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray) (7.1.2)\n",
            "Collecting redis>=3.5.0\n",
            "  Downloading redis-4.2.0-py3-none-any.whl (225 kB)\n",
            "\u001b[K     |████████████████████████████████| 225 kB 52.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from ray) (21.4.0)\n",
            "Collecting grpcio<=1.43.0,>=1.28.1\n",
            "  Downloading grpcio-1.43.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1 MB 37.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray) (3.6.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray) (4.3.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray) (3.13)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from ray) (1.21.5)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray) (1.0.3)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio<=1.43.0,>=1.28.1->ray) (1.15.0)\n",
            "Collecting deprecated>=1.2.3\n",
            "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting async-timeout>=4.0.2\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: packaging>=20.4 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray) (21.3)\n",
            "Requirement already satisfied: importlib-metadata>=1.0 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray) (4.11.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray) (3.10.0.2)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.3->redis>=3.5.0->ray) (1.14.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.0->redis>=3.5.0->ray) (3.7.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.4->redis>=3.5.0->ray) (3.0.7)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray) (0.18.1)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray) (5.4.0)\n",
            "Installing collected packages: deprecated, async-timeout, redis, grpcio, ray\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.44.0\n",
            "    Uninstalling grpcio-1.44.0:\n",
            "      Successfully uninstalled grpcio-1.44.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\u001b[0m\n",
            "Successfully installed async-timeout-4.0.2 deprecated-1.2.13 grpcio-1.43.0 ray-1.11.0 redis-4.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from utils.calc_utils import CalculationsUtils. This is the CalculationsUtils class     \n",
        "\n",
        "import math\n",
        "\n",
        "import torch\n",
        "# from torch.tensor import Tensor\n",
        "from torch import Tensor\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class CalculationsUtils:\n",
        "\n",
        "    @staticmethod\n",
        "    def div(a: float, b: float):\n",
        "        return a / b if b else 0.0\n",
        "\n",
        "    @staticmethod\n",
        "    def div_tensor(t: Tensor, d: float):\n",
        "        return t / d if d else torch.zeros(len(t))\n",
        "\n",
        "    @staticmethod\n",
        "    def normalize(t: Tensor):\n",
        "        s = t.sum()\n",
        "        return t / s if s > 0.0 else t\n",
        "\n",
        "    @staticmethod\n",
        "    def sum_arrays(arrays):\n",
        "        out = []\n",
        "        active = set(range(len(arrays)))\n",
        "\n",
        "        i = 0\n",
        "        while active:\n",
        "            out.append(0.0)\n",
        "            to_remove = set()\n",
        "\n",
        "            for a_idx in active:\n",
        "                if i > len(arrays[a_idx]) - 1:\n",
        "                    to_remove.add(a_idx)\n",
        "                else:\n",
        "                    out[-1] += arrays[a_idx][i]\n",
        "\n",
        "            active -= to_remove\n",
        "            i += 1\n",
        "\n",
        "        return np.array(out[:-1])\n",
        "\n",
        "    @staticmethod\n",
        "    def log(x):\n",
        "        if x > 0.0: return math.log(x)\n",
        "        return float('-inf') if x == 0.0 else float('NaN')"
      ],
      "metadata": {
        "id": "NdYORYwE868M"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from utils.coll_utils import CollectionUtils  This is the 'CollectionUtils' class\n",
        "\n",
        "import itertools\n",
        "from functools import reduce\n",
        "from typing import Callable\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class CollectionUtils:\n",
        "\n",
        "    @staticmethod\n",
        "    def ensure_arr_size(arr: np.ndarray, y: int):\n",
        "        if len(arr.shape) == 1:\n",
        "            return np.hstack((arr, np.zeros(y - len(arr) + 1))) if len(arr) - 1 < y else arr\n",
        "        else:\n",
        "            return np.hstack((arr, np.zeros((arr.shape[0], y - arr.shape[1] + 1, arr.shape[2])))) if arr.shape[1] - 1 < y else arr\n",
        "\n",
        "    @staticmethod\n",
        "    def ensure_list2d_size(lst: list, y: int, element_creator: Callable[[], any]):\n",
        "        if len(lst[0]) > y:\n",
        "            return lst\n",
        "\n",
        "        for l in lst:\n",
        "            l_len = len(l) - 1\n",
        "            for _ in range(y - l_len):\n",
        "                l.append(element_creator())\n",
        "\n",
        "        return lst\n",
        "\n",
        "    @staticmethod\n",
        "    def split_list(lst, chunk_size: int):\n",
        "        return [lst[i:i + chunk_size] for i in range(0, len(lst), chunk_size)]\n",
        "\n",
        "    @staticmethod\n",
        "    def flatten_list(lst):\n",
        "        return list(itertools.chain.from_iterable(lst))"
      ],
      "metadata": {
        "id": "WZE26Qk68_u0"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hoeffding Tree"
      ],
      "metadata": {
        "id": "El-2pNvt9KgB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# From core.clean import ContinualLearner this is the ContinualLearner class\n",
        "\n",
        "from abc import ABC, abstractmethod\n",
        "\n",
        "\n",
        "class ContinualLearner(ABC):\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def initialize(self, x_batch, y_batch, **kwargs):\n",
        "        self.update(x_batch, y_batch, **kwargs)\n",
        "\n",
        "    @abstractmethod\n",
        "    def predict(self, x_batch):\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def predict_prob(self, x_batch):\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def update(self, x_batch, y_batch, **kwargs):\n",
        "        pass"
      ],
      "metadata": {
        "id": "x0C5_F_h9H02"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from utils.stat_utils import Statistics, GaussianEstimator  Here is the Statistics and GaussianEstimator classes\n",
        "\n",
        "\n",
        "from abc import ABC, abstractmethod\n",
        "from typing import Callable\n",
        "import math\n",
        "import numpy as np\n",
        "from scipy.stats import entropy\n",
        "import copy\n",
        "\n",
        "# from utils.calc_utils import CalculationsUtils as cu\n",
        "# from utils.coll_utils import CollectionUtils as clu\n",
        "\n",
        "SQ2 = math.sqrt(2.0)\n",
        "NC = math.sqrt(2.0 * math.pi)\n",
        "\n",
        "\n",
        "class ValueEstimator(ABC):\n",
        "\n",
        "    @abstractmethod\n",
        "    def update(self, v: float, w: float):\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def get_count(self):\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def get_mean(self):\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def get_var(self):\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def get_std(self):\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def copy(self):\n",
        "        pass\n",
        "\n",
        "\n",
        "class ForgettingEstimator(ValueEstimator):\n",
        "    def __init__(self, decay: float, count: float=0.0, linear_sum: float=0.0, squared_sum: float=0.0, timestamp: int=0):\n",
        "        self.decay = decay\n",
        "        self.count = count\n",
        "        self.linear_sum = linear_sum\n",
        "        self.squared_sum = squared_sum\n",
        "        self.timestamp = timestamp\n",
        "\n",
        "    def update(self, v: float, t: int):\n",
        "        d = self.decay ** (t - self.timestamp)\n",
        "        self.count = d * self.count + 1\n",
        "        self.linear_sum = d * self.linear_sum + v\n",
        "        self.squared_sum = d * self.squared_sum + v**2\n",
        "\n",
        "        self.timestamp = t\n",
        "\n",
        "    def get_count(self):\n",
        "        return self.count\n",
        "\n",
        "    def get_mean(self):\n",
        "        if self.count == 0.0:\n",
        "            return float('NaN')\n",
        "        print(self.linear_sum, self.count)\n",
        "        return self.linear_sum / self.count\n",
        "\n",
        "    def get_var(self):\n",
        "        if self.count == 0.0:\n",
        "            return float('NaN')\n",
        "        return max(self.squared_sum / self.count - (self.linear_sum / self.count) ** 2, 0.0)\n",
        "\n",
        "    def get_std(self):\n",
        "        if self.count == 0.0:\n",
        "            return float('NaN')\n",
        "        return math.sqrt(self.get_var())\n",
        "\n",
        "    def copy(self):\n",
        "        return ForgettingEstimator(self.decay, self.count, self.linear_sum, self.squared_sum, self.timestamp)\n",
        "\n",
        "\n",
        "class DistributionEstimator(ValueEstimator):\n",
        "\n",
        "    @abstractmethod\n",
        "    def get_cdf(self, x: float):\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def get_pdf(self, x: float):\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def split(self, **kwargs):\n",
        "        pass\n",
        "\n",
        "\n",
        "class GaussianEstimator(DistributionEstimator):\n",
        "    def __init__(self, count: float=0.0, mean: float=0.0, var: float=0.0, std: float=0.0):\n",
        "        self.count = count\n",
        "        self.mean = mean\n",
        "        self.var = var\n",
        "        self.std = std\n",
        "\n",
        "    def update(self, v: float, w: float):\n",
        "        pm = self.mean\n",
        "        self.count += w\n",
        "        self.mean = pm + (w / self.count) * (v - pm)\n",
        "        self.var = self.var + w * (v - pm) * (v - self.mean)\n",
        "        self.std = math.sqrt(self.var / self.count)\n",
        "\n",
        "    def get_count(self):\n",
        "        return self.count\n",
        "\n",
        "    def get_mean(self):\n",
        "        return self.mean\n",
        "\n",
        "    def get_var(self):\n",
        "        return self.var\n",
        "\n",
        "    def get_std(self):\n",
        "        return self.std\n",
        "\n",
        "    def get_cdf(self, x: float):\n",
        "        z = (x - self.mean) / self.std\n",
        "        return (1.0 + math.erf(z / SQ2)) / 2.0\n",
        "\n",
        "    def get_pdf(self, x: float):\n",
        "        if self.std == 0:\n",
        "            return 1.0 if x == self.mean else 0.0\n",
        "\n",
        "        z = (x - self.mean) / self.std\n",
        "        return math.exp(-0.5 * z * z) / (NC * self.std)\n",
        "\n",
        "    def split(self, **kwargs):\n",
        "        return GaussianEstimator(self.count, self.mean, self.var, self.std), \\\n",
        "               GaussianEstimator(self.count, self.mean, self.var, self.std)\n",
        "\n",
        "    def copy(self):\n",
        "        return GaussianEstimator(self.count, self.mean, self.var, self.std)\n",
        "\n",
        "\n",
        "class Statistics:\n",
        "    def __init__(self, atts: list, num_cls: int, estimator_creator: Callable[[], DistributionEstimator], att_split_est=False,\n",
        "                 cls_counts=None, att_stats=None, att_extr_stats=None):\n",
        "        self.atts = atts\n",
        "        self.att_map = {att_idx: i for i, att_idx in enumerate(self.atts)}\n",
        "        self.num_cls = num_cls\n",
        "        self.estimator_creator = estimator_creator\n",
        "        self.att_split_est = att_split_est\n",
        "\n",
        "        self.att_stats = att_stats if att_stats is not None else [[self.estimator_creator() for _ in range(num_cls)] for _ in range(len(self.atts))]\n",
        "        self.att_extr_stats = att_extr_stats if att_extr_stats is not None else np.array([[float('inf'), float('-inf')] for _ in range(len(self.atts))])\n",
        "        self.cls_counts = cls_counts if cls_counts is not None else np.zeros(num_cls)\n",
        "        self.all_count = self.cls_counts.sum()\n",
        "\n",
        "    def update(self, x, y: int, w: float):\n",
        "        self.cls_counts = CollectionUtils.ensure_arr_size(self.cls_counts, y)\n",
        "        self.att_stats = CollectionUtils.ensure_list2d_size(self.att_stats, y, self.estimator_creator)\n",
        "        self.num_cls = max(self.num_cls, y + 1)\n",
        "\n",
        "        self.all_count += w\n",
        "        self.cls_counts[y] += w\n",
        "\n",
        "        for i, att_idx in enumerate(self.atts):\n",
        "            self.att_stats[i][y].update(x[att_idx], w)\n",
        "            self.att_extr_stats[i][0] = min(self.att_extr_stats[i][0], x[att_idx])\n",
        "            self.att_extr_stats[i][1] = max(self.att_extr_stats[i][1], x[att_idx])\n",
        "\n",
        "    def get_estimator(self, att_idx: int, cls_idx: int):\n",
        "        return self.att_stats[self.att_map[att_idx]][cls_idx]\n",
        "\n",
        "    def get_cls_count(self, cls_idx: int=-1):\n",
        "        return self.all_count if cls_idx < 0 else self.cls_counts[cls_idx]\n",
        "\n",
        "    def get_att_extr(self, att_idx: int):\n",
        "        return self.att_extr_stats[self.att_map[att_idx]]\n",
        "\n",
        "    def get_stats(self):\n",
        "        return self.cls_counts, self.att_stats, self.att_extr_stats\n",
        "\n",
        "    def split(self, split_att_idx: int, s: float, l_prob, r_prob):\n",
        "        l_cls_counts, r_cls_counts = self.all_count * l_prob, self.all_count * r_prob\n",
        "        l_att_stats, r_att_stats = None, None\n",
        "        l_att_extr, r_att_extr = None, None\n",
        "\n",
        "        if self.att_split_est:\n",
        "            l_att_stats, r_att_stats = [], []\n",
        "            for i, att_idx in enumerate(self.atts):\n",
        "                lstats, rstats = [], []\n",
        "\n",
        "                for cls_idx in range(self.num_cls):\n",
        "                    lest, rest = self.get_estimator(i, cls_idx).split(lc=l_cls_counts[cls_idx], rc=r_cls_counts[cls_idx])\n",
        "                    lstats.append(lest)\n",
        "                    rstats.append(rest)\n",
        "\n",
        "                l_att_stats.append(lstats)\n",
        "                r_att_stats.append(rstats)\n",
        "\n",
        "            l_att_extr, r_att_extr = copy.deepcopy(self.att_extr_stats), copy.deepcopy(self.att_extr_stats)\n",
        "            l_att_extr[split_att_idx][1] = s\n",
        "            r_att_extr[split_att_idx][0] = s\n",
        "\n",
        "        return Statistics(self.atts, self.num_cls, self.estimator_creator, self.att_split_est, l_cls_counts, l_att_stats, l_att_extr), \\\n",
        "               Statistics(self.atts, self.num_cls, self.estimator_creator, self.att_split_est, r_cls_counts, r_att_stats, r_att_extr)\n",
        "\n",
        "    @staticmethod\n",
        "    def calc_split_weighted_entropy(stats, att_idx: int, s: float, num_cls: int):\n",
        "        l_prob, r_prob = np.zeros(num_cls), np.zeros(num_cls)\n",
        "        lp_sum, rp_sum = 0.0, 0.0\n",
        "\n",
        "        for cls_idx in range(num_cls):\n",
        "            est = stats.get_estimator(att_idx, cls_idx)\n",
        "\n",
        "            if est.get_count() == 0:\n",
        "                continue\n",
        "            elif est.get_var() == 0:\n",
        "                lp = 1.0 if s >= est.get_mean() else 0.0\n",
        "            else:\n",
        "                lp = est.get_cdf(s)\n",
        "\n",
        "            lp_sum += lp\n",
        "            rp = 1.0 - lp\n",
        "            rp_sum += rp\n",
        "\n",
        "            cp = stats.get_cls_count(cls_idx) / stats.get_cls_count()\n",
        "            l_prob[cls_idx] = lp * cp\n",
        "            r_prob[cls_idx] = rp * cp\n",
        "\n",
        "        wl, wr = l_prob.sum(), r_prob.sum()\n",
        "        l_ent = entropy(CalculationsUtils.div_tensor(l_prob, lp_sum)) if wl > 0.0 else 0.0\n",
        "        r_ent = entropy(CalculationsUtils.div_tensor(r_prob, rp_sum)) if wr > 0.0 else 0.0\n",
        "        ent = wl * l_ent + wr * r_ent\n",
        "\n",
        "        return ent, l_prob, r_prob"
      ],
      "metadata": {
        "id": "3RpJ-lKE9Per"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikit-multiflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zd5e8lZx9Wx0",
        "outputId": "f0bff9c4-c420-40ee-c280-7f4e9232a040"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-multiflow\n",
            "  Downloading scikit_multiflow-0.5.3-cp37-cp37m-manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 20.5 MB/s eta 0:00:01\r\u001b[K     |▋                               | 20 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |▉                               | 30 kB 16.2 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 61 kB 11.2 MB/s eta 0:00:01\r\u001b[K     |██                              | 71 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 81 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 92 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |███                             | 102 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 112 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 122 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 133 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |████                            | 143 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 153 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 163 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████                           | 174 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 184 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 194 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 204 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 215 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 225 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 235 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████                         | 245 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 256 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 266 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████                        | 276 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 286 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 296 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 307 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 317 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 327 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 337 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 348 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 358 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 368 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 378 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 389 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 399 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 409 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 419 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 430 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 440 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 450 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 460 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 471 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 481 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 491 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 501 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 512 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 522 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 532 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 542 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 552 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 563 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 573 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 583 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 593 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 604 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 614 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 624 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 634 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 645 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 655 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 665 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 675 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 686 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 696 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 706 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 716 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 727 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 737 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 747 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 757 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 768 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 778 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 788 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 798 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 808 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 819 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 829 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 839 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 849 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 860 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 870 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 880 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 890 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 901 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 911 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 921 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 931 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 942 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 952 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 962 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 972 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 983 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 993 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.0 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.0 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.0 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.0 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.0 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.1 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.1 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.1 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.1 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.1 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.1 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.1 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1 MB 11.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-multiflow) (3.2.2)\n",
            "Requirement already satisfied: sortedcontainers>=1.5.7 in /usr/local/lib/python3.7/dist-packages (from scikit-multiflow) (2.4.0)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.7/dist-packages (from scikit-multiflow) (1.0.2)\n",
            "Requirement already satisfied: pandas>=0.25.3 in /usr/local/lib/python3.7/dist-packages (from scikit-multiflow) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from scikit-multiflow) (1.21.5)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-multiflow) (1.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->scikit-multiflow) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->scikit-multiflow) (3.0.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->scikit-multiflow) (1.4.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->scikit-multiflow) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=2.0.0->scikit-multiflow) (3.10.0.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.3->scikit-multiflow) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=2.0.0->scikit-multiflow) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20->scikit-multiflow) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20->scikit-multiflow) (3.1.0)\n",
            "Installing collected packages: scikit-multiflow\n",
            "Successfully installed scikit-multiflow-0.5.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from utils.cls_utils import ClassificationUtils This is the 'ClassificationUtils' class\n",
        "\n",
        "import math\n",
        "\n",
        "from river.base import Classifier\n",
        "from skmultiflow.core import ClassifierMixin\n",
        "from torch import Tensor\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "# from core.clearn import ContinualLearner\n",
        "# from utils.calc_utils import CalculationsUtils\n",
        "# from utils.stat_utils import Statistics\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "class ClassificationUtils:\n",
        "\n",
        "    @staticmethod\n",
        "    def majority_class_prob(counts, all_count):\n",
        "        return np.zeros(len(counts)) if all_count == 0 else counts / all_count\n",
        "\n",
        "    @staticmethod\n",
        "    def naive_bayes_prob(x, stats: Statistics, use_prior=True):\n",
        "        probs = np.zeros(stats.num_cls, dtype=np.double)\n",
        "        if stats.get_cls_count() == 0: return probs\n",
        "        p = 0.0\n",
        "\n",
        "        for cls_idx in range(stats.num_cls):\n",
        "            prob = stats.get_cls_count(cls_idx) / stats.get_cls_count() if use_prior else 1.0\n",
        "\n",
        "            for att_idx in stats.atts:\n",
        "                pr = stats.get_estimator(att_idx, cls_idx).get_pdf(x[att_idx])\n",
        "                prob *= (pr if not np.isnan(pr) else 1.0)\n",
        "\n",
        "            p += prob\n",
        "            probs[cls_idx] = prob\n",
        "\n",
        "        return probs if p == 0.0 else probs / p\n",
        "\n",
        "    @staticmethod\n",
        "    def naive_bayes_log_prob(x, stats: Statistics, use_prior=True):\n",
        "        log_probs = np.zeros(stats.num_cls, dtype=np.double)\n",
        "        if stats.get_cls_count() == 0: return log_probs\n",
        "        lps, lp_max = [], float('-inf')\n",
        "\n",
        "        for cls_idx in range(stats.num_cls):\n",
        "            log_prob = CalculationsUtils.log(stats.get_cls_count(cls_idx) / stats.get_cls_count()) if use_prior else 0.0\n",
        "\n",
        "            for att_idx in stats.atts:\n",
        "                pr = stats.get_estimator(att_idx, cls_idx).get_pdf(x[att_idx])\n",
        "                log_prob += (CalculationsUtils.log(pr) if not np.isnan(pr) else 0.0)\n",
        "\n",
        "            lps.append(log_prob)\n",
        "            lp_max = max(lp_max, log_prob)\n",
        "            log_probs[cls_idx] = log_prob\n",
        "\n",
        "        # https://stats.stackexchange.com/questions/105602/example-of-how-the-log-sum-exp-trick-works-in-naive-bayes/253319#253319\n",
        "        lps_sum = 0.0\n",
        "        zero_prob_indices = []\n",
        "        for i, lp in enumerate(lps):\n",
        "            if lp != float('-inf'):\n",
        "                lps_sum += math.exp(lp - lp_max)\n",
        "            else:\n",
        "                zero_prob_indices.append(i)\n",
        "\n",
        "        if not (np.isfinite(lps_sum) and np.isfinite(lp_max)):\n",
        "            return np.zeros(stats.num_cls)\n",
        "\n",
        "        lps_sum = math.log(lps_sum)\n",
        "        lps_sum += lp_max\n",
        "\n",
        "        probs = np.exp(log_probs - lps_sum)\n",
        "        probs[zero_prob_indices] = 0.0\n",
        "\n",
        "        return probs"
      ],
      "metadata": {
        "id": "S5abbPjG9a9t"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ht.py Hoeffding Tree main code\n",
        "import math\n",
        "from scipy.stats import entropy\n",
        "import numpy as np\n",
        "\n",
        "# from core.clearn import ContinualLearner\n",
        "# from utils.cls_utils import ClassificationUtils as cu\n",
        "# from utils.stat_utils import Statistics, GaussianEstimator\n",
        "\n",
        "\n",
        "class HoeffdingTree(ContinualLearner):\n",
        "    def __init__(self, split_step=0.1, split_wait=100, hb_delta=0.01, tie_thresh=0.05, rnd=False, subspaces=False,\n",
        "                 att_split_est=False, log_prob=True, num_atts=0, num_cls=0):\n",
        "        super().__init__()\n",
        "        self.root = TreeNode(split_step, split_wait, hb_delta, tie_thresh, rnd, subspaces, None, None, att_split_est, log_prob,\n",
        "                             num_atts, num_cls)\n",
        "\n",
        "    def predict(self, x_batch):\n",
        "        return np.array([np.argmax(ya) for ya in self.predict_prob(x_batch)])\n",
        "\n",
        "    def predict_prob(self, x_batch):\n",
        "        return np.array([self.find_leaf(x).predict_prob(x) for x in x_batch], dtype=object)\n",
        "\n",
        "    def update(self, x_batch, y_batch, **kwargs):\n",
        "        weights = kwargs.get('weights', np.ones(len(y_batch)))\n",
        "        y_batch = y_batch.astype(int) if isinstance(y_batch, np.ndarray) else y_batch.int()\n",
        "\n",
        "        for x, y, w in zip(x_batch, y_batch, weights):\n",
        "            leaf = self.find_leaf(x)\n",
        "            leaf.update(x, y, w if w > 0.0 else 1.0)\n",
        "            leaf.attempt_split()\n",
        "\n",
        "    def find_leaf(self, x):\n",
        "        node = self.root\n",
        "        while not node.is_leaf:\n",
        "            att, thresh = node.split\n",
        "            node = node.left if x[att] <= thresh else node.right\n",
        "\n",
        "        return node\n",
        "\n",
        "\n",
        "class TreeNode:\n",
        "    def __init__(self, split_step=0.1, split_wait=100, hb_delta=0.01, tie_thresh=0.05, rnd=False, subspaces=False,\n",
        "                 split_atts=None, stats=None, att_split_est=False, log_prob=True, num_atts=0, num_cls=0):\n",
        "        self.is_leaf = True\n",
        "        self.left = None\n",
        "        self.right = None\n",
        "        self.split = (None, None)\n",
        "        self.split_step = split_step\n",
        "        self.split_wait = split_wait\n",
        "        self.last_split_try = 0.0\n",
        "        self.cnt = 0.0\n",
        "        self.hb_delta = hb_delta\n",
        "        self.tie_thresh = tie_thresh\n",
        "\n",
        "        self.mc_correct = 0.0\n",
        "        self.nb_correct = 0.0\n",
        "\n",
        "        self.rnd = rnd\n",
        "        self.subspaces = subspaces\n",
        "        self.split_atts = split_atts\n",
        "        self.att_split_est = att_split_est\n",
        "        self.log_prob = log_prob\n",
        "        self.nb_pred = ClassificationUtils.naive_bayes_log_prob if self.log_prob else ClassificationUtils.naive_bayes_prob\n",
        "\n",
        "        if num_atts > 0:\n",
        "            self.init(num_atts, num_cls, stats)\n",
        "        else:\n",
        "            self.num_atts = 0\n",
        "            self.num_cls = 0\n",
        "            self.split_atts = None\n",
        "            self.stat_atts = []\n",
        "            self.att_map = None\n",
        "            self.stats = None\n",
        "\n",
        "    def init(self, num_atts, num_cls, stats):\n",
        "        self.num_atts = num_atts\n",
        "        self.num_cls = num_cls\n",
        "\n",
        "        if self.rnd or (self.subspaces and self.split_atts is None):\n",
        "            self.split_atts = np.random.permutation(num_atts)[:int(math.sqrt(num_atts)) + 1]\n",
        "        elif not self.subspaces:\n",
        "            self.split_atts = np.arange(0, num_atts)\n",
        "\n",
        "        self.stat_atts = self.split_atts if not self.att_split_est else np.arange(0, num_atts)\n",
        "\n",
        "        if stats is not None:\n",
        "            s = stats.get_stats()\n",
        "            self.stats = Statistics(self.stat_atts, self.num_cls, GaussianEstimator, self.att_split_est, *s)\n",
        "        else:\n",
        "            self.stats = Statistics(self.stat_atts, self.num_cls, GaussianEstimator, self.att_split_est)\n",
        "\n",
        "    def update(self, x, y: int, w: float):\n",
        "        if not self.stats:\n",
        "            self.init(len(x), y + 1, None)\n",
        "\n",
        "        self.mc_correct += w * (np.argmax(self.stats.cls_counts) == y)\n",
        "        self.nb_correct += w * (np.argmax(self.nb_pred(x, self.stats)) == y)\n",
        "        self.cnt += w\n",
        "        self.stats.update(x, y, w)\n",
        "        self.num_cls = self.stats.num_cls\n",
        "\n",
        "    def predict_prob(self, x):\n",
        "        if not self.stats:\n",
        "            return np.zeros(1)\n",
        "        else:\n",
        "            maj_probs = ClassificationUtils.majority_class_prob(self.stats.cls_counts, self.stats.get_cls_count())\n",
        "            if self.mc_correct >= self.nb_correct:\n",
        "                return maj_probs\n",
        "\n",
        "            nb_probs = self.nb_pred(x, self.stats)\n",
        "            return nb_probs if np.any(nb_probs) else maj_probs\n",
        "\n",
        "    def attempt_split(self):\n",
        "        if self.cnt > 0 and self.cnt - self.last_split_try >= self.split_wait:\n",
        "            best_split = self.__find_best_att_split()\n",
        "            self.__try_best_split(best_split)\n",
        "\n",
        "    def __find_best_att_split(self):\n",
        "        best_split = (float('inf'), None, None, [], [])  # entropy, att idx, thresh val, left prob, right prob\n",
        "\n",
        "        for att_idx in self.split_atts:\n",
        "            mi, mx = np.around(self.stats.get_att_extr(att_idx), decimals=10)\n",
        "            step = (mx - mi) * self.split_step\n",
        "\n",
        "            s = mi + step\n",
        "            while s < mx:\n",
        "                ent, l_prob, r_prob = Statistics.calc_split_weighted_entropy(self.stats, att_idx, s, self.num_cls)\n",
        "                if ent < best_split[0]:\n",
        "                    best_split = [ent, att_idx, s, l_prob, r_prob]\n",
        "\n",
        "                s += step\n",
        "\n",
        "        return best_split\n",
        "\n",
        "    def __try_best_split(self, best_split):\n",
        "        if best_split[1] is None: return\n",
        "        n = self.stats.get_cls_count()\n",
        "        curr_entropy = entropy(self.stats.cls_counts / n)\n",
        "        hb = self.hb(math.log(self.num_cls), self.hb_delta, n)\n",
        "\n",
        "        if curr_entropy - best_split[0] > hb or hb < self.tie_thresh:\n",
        "            _, att_idx, thresh, l_prob, r_prob = best_split\n",
        "            self.split = (att_idx, thresh)\n",
        "\n",
        "            l_stats, r_stats = self.stats.split(att_idx, thresh, l_prob, r_prob)\n",
        "\n",
        "            self.left = TreeNode(self.split_step, self.split_wait, self.hb_delta, self.tie_thresh, self.rnd, self.subspaces,\n",
        "                                 self.split_atts, l_stats, self.att_split_est, self.log_prob, self.num_atts, self.num_cls)\n",
        "            self.right = TreeNode(self.split_step, self.split_wait, self.hb_delta, self.tie_thresh, self.rnd, self.subspaces,\n",
        "                                  self.split_atts, r_stats, self.att_split_est, self.log_prob, self.num_atts, self.num_cls)\n",
        "\n",
        "            self.is_leaf = False\n",
        "            self.stats = None\n",
        "\n",
        "        self.last_split_try = self.cnt\n",
        "\n",
        "    @staticmethod\n",
        "    def hb(r, delta, n):\n",
        "        return math.sqrt((r * r * math.log(1.0 / delta)) / (2.0 * n))"
      ],
      "metadata": {
        "id": "C74H3wfo9fta"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "irf.py"
      ],
      "metadata": {
        "id": "IjpaBiOg9oZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import random\n",
        "from collections import Counter\n",
        "\n",
        "from skmultiflow.drift_detection import ADWIN\n",
        "import numpy as np\n",
        "import ray\n",
        "\n",
        "# from core.clearn import ContinualLearner\n",
        "# from learners.ht import HoeffdingTree\n",
        "# from utils.calc_utils import CalculationsUtils\n",
        "# from utils.coll_utils import CollectionUtils\n",
        "\n",
        "\n",
        "class IncrementalRandomForest(ContinualLearner):\n",
        "\n",
        "    def __init__(self, size: int, lambda_val=5.0, split_step=0.1, split_wait=100, hb_delta=0.01, tie_thresh=0.05,\n",
        "                 rnd=True, subspaces=False, att_split_est=False, log_prob=True, num_atts=0, num_cls=0, num_workers=1):\n",
        "        super().__init__()\n",
        "        self.size = size\n",
        "        self.lambda_val = lambda_val\n",
        "        self.tree_groups = []\n",
        "        self.num_par_groups = num_workers\n",
        "        self.par = self.num_par_groups > 1\n",
        "        self.init_tree_groups([0, split_step, split_wait, hb_delta, tie_thresh, rnd, subspaces, att_split_est, log_prob,\n",
        "                               num_atts, num_cls])\n",
        "\n",
        "    def init_tree_groups(self, tree_params: list):\n",
        "        trees_per_group, r = math.ceil(self.size / self.num_par_groups), self.size\n",
        "        while r > 0:\n",
        "            tree_params[0] = min(r, trees_per_group)\n",
        "            self.tree_groups.append(RemoteTreeGroupWrapper(*tree_params) if self.par else TreeGroup(*tree_params))\n",
        "            r -= trees_per_group\n",
        "\n",
        "    def predict(self, x_batch):\n",
        "        return np.array([np.argmax(ya) for ya in self.predict_prob(x_batch)])\n",
        "\n",
        "    def predict_prob(self, x_batch):\n",
        "        weights = self.fetch([tg.get_weights() for tg in self.tree_groups])\n",
        "        ws = sum([sum(w) for w in weights])\n",
        "\n",
        "        probs = self.fetch([tg.predict_prob(x_batch) for tg in self.tree_groups])\n",
        "        trees_batch_probs = CollectionUtils.flatten_list(probs)\n",
        "        probs_sum = [CalculationsUtils.sum_arrays([tree_probs[i] for tree_probs in trees_batch_probs]) for i in range(len(x_batch))]\n",
        "\n",
        "        return np.array(probs_sum, dtype=object) / ws\n",
        "\n",
        "    def update(self, x_batch, y_batch, **kwargs):\n",
        "        weights = kwargs.get('weights', np.ones(len(y_batch)))\n",
        "\n",
        "        for tree_group in self.tree_groups:\n",
        "            tree_group.update_trees(x_batch, y_batch, self.lambda_val, weights)\n",
        "\n",
        "    def get_tree_group(self, idx):\n",
        "        return self.tree_groups[idx].get_trees()\n",
        "\n",
        "    def fetch(self, obj):\n",
        "        return obj if not self.par else ray.get(obj)\n",
        "\n",
        "\n",
        "class TreeGroup:\n",
        "\n",
        "    def __init__(self, size: int, split_step=0.1, split_wait=100, hb_delta=0.01, tie_thresh=0.05, rnd=True, subspaces=False,\n",
        "                 att_split_est=False, log_prob=True, num_atts=0, num_cls=0):\n",
        "        self.trees = [\n",
        "            ForestHoeffdingTree(split_step, split_wait, hb_delta, tie_thresh, rnd, subspaces, att_split_est, log_prob, num_atts, num_cls)\n",
        "            for _ in range(size)\n",
        "        ]\n",
        "\n",
        "    def get_weights(self):\n",
        "        return [tree.get_weight() for tree in self.trees]\n",
        "\n",
        "    def predict_prob(self, x_batch):\n",
        "        return [tree.predict_prob(x_batch) for tree in self.trees]\n",
        "\n",
        "    def update_trees(self, x_batch, y_batch, lambda_val, weights):\n",
        "        for tree in self.trees:\n",
        "            k = np.random.poisson(lambda_val, len(x_batch))\n",
        "            tree.update(x_batch, y_batch, weights=np.multiply(weights, k))\n",
        "\n",
        "    def get_trees(self):\n",
        "        return self.trees\n",
        "\n",
        "\n",
        "class ForestHoeffdingTree(HoeffdingTree):\n",
        "\n",
        "    def __init__(self, split_step=0.1, split_wait=100, hb_delta=0.01, tie_thresh=0.05, rnd=True, subspaces=False, att_split_est=False,\n",
        "                 log_prob=True, num_atts=0, num_cls=0):\n",
        "        super().__init__(split_step, split_wait, hb_delta, tie_thresh, rnd, subspaces, att_split_est, log_prob, num_atts, num_cls)\n",
        "        self.quality = ADWIN()\n",
        "\n",
        "    def update(self, x_batch, y_batch, **kwargs):\n",
        "        preds = super().predict(x_batch)\n",
        "        for p, y in zip(preds, y_batch): self.quality.add_element(int(int(p) == int(y)))\n",
        "        super().update(x_batch, y_batch, **kwargs)\n",
        "\n",
        "    def predict_prob(self, x_batch):\n",
        "        return self.get_weight() * np.array([self.find_leaf(x).predict_prob(x) for x in x_batch], dtype=object)\n",
        "\n",
        "    def get_weight(self):\n",
        "        return self.quality.estimation if self.quality.total > 0 else 1.0\n",
        "\n",
        "\n",
        "@ray.remote\n",
        "class RemoteTreeGroup(TreeGroup):\n",
        "\n",
        "    def __init__(self, size: int, split_step=0.1, split_wait=100, hb_delta=0.01, tie_thresh=0.05, bag=False, subspaces=False,\n",
        "                 att_split_est=False, log_prob=True, num_atts=0, num_cls=0):\n",
        "        super().__init__(size, split_step, split_wait, hb_delta, tie_thresh, bag, subspaces, att_split_est, log_prob, num_atts, num_cls)\n",
        "\n",
        "\n",
        "class RemoteTreeGroupWrapper:\n",
        "\n",
        "    def __init__(self, *remote_tree_group_args):\n",
        "        self.remote_tree_group = RemoteTreeGroup.remote(*remote_tree_group_args)\n",
        "\n",
        "    def get_weights(self):\n",
        "        return self.remote_tree_group.get_weights.remote()\n",
        "\n",
        "    def predict_prob(self, x_batch):\n",
        "        return self.remote_tree_group.predict_prob.remote(x_batch)\n",
        "\n",
        "    def update_trees(self, x_batch, y_batch, lambda_val, weights):\n",
        "        self.remote_tree_group.update_trees.remote(x_batch, y_batch, lambda_val, weights)\n",
        "\n",
        "    def get_trees(self):\n",
        "        return self.remote_tree_group.get_trees.remote()"
      ],
      "metadata": {
        "id": "3InvUrzs9maE"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#utils/coll_utils.py /\n",
        "\n",
        "import itertools\n",
        "from functools import reduce\n",
        "from typing import Callable\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class CollectionUtils:\n",
        "\n",
        "    @staticmethod\n",
        "    def ensure_arr_size(arr: np.ndarray, y: int):\n",
        "        if len(arr.shape) == 1:\n",
        "            return np.hstack((arr, np.zeros(y - len(arr) + 1))) if len(arr) - 1 < y else arr\n",
        "        else:\n",
        "            return np.hstack((arr, np.zeros((arr.shape[0], y - arr.shape[1] + 1, arr.shape[2])))) if arr.shape[1] - 1 < y else arr\n",
        "\n",
        "    @staticmethod\n",
        "    def ensure_list2d_size(lst: list, y: int, element_creator: Callable[[], any]):\n",
        "        if len(lst[0]) > y:\n",
        "            return lst\n",
        "\n",
        "        for l in lst:\n",
        "            l_len = len(l) - 1\n",
        "            for _ in range(y - l_len):\n",
        "                l.append(element_creator())\n",
        "\n",
        "        return lst\n",
        "\n",
        "    @staticmethod\n",
        "    def split_list(lst, chunk_size: int):\n",
        "        return [lst[i:i + chunk_size] for i in range(0, len(lst), chunk_size)]\n",
        "\n",
        "    @staticmethod\n",
        "    def flatten_list(lst):\n",
        "        return list(itertools.chain.from_iterable(lst))"
      ],
      "metadata": {
        "id": "MlG7nscr8jWF"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # data_labels.py\n",
        "\n",
        "# import csv\n",
        "\n",
        "# from torch.utils.data import Dataset\n",
        "\n",
        "# #import data.data_collection as data_col\n",
        "\n",
        "\n",
        "# class DataLabelsUtils:\n",
        "\n",
        "#     @staticmethod\n",
        "#     def get_dataset_labels(dataset: Dataset):\n",
        "#         return dataset.classes if hasattr(dataset, 'classes') else None\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "# cls_names = {\n",
        "#     'FASHION': lambda: ['T-shirt/top', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot'],\n",
        "#     'CIFAR10': lambda: DataLabelsUtils.get_dataset_labels(data_collection.get('CIFAR10-TRAIN')),\n",
        "#     'CIFAR20C': lambda: DataLabelsUtils.get_dataset_labels(data_collection.get('CIFAR20C-TRAIN')),\n",
        "#     'CIFAR100': lambda: DataLabelsUtils.get_dataset_labels(data_collection.get('CIFAR100-TRAIN')),\n",
        "    \n",
        "# }\n",
        "\n",
        "\n",
        "# def get_cls_names(name: str):\n",
        "#     return cls_names[name]()"
      ],
      "metadata": {
        "id": "DdA4olC--May"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#stream.py\n",
        "import random\n",
        "from typing import Dict\n",
        "import numpy as np\n",
        "from numpy.random.mtrand import RandomState\n",
        "from torch.utils.data import Dataset, Subset\n",
        "from abc import ABC\n",
        "\n",
        "# from data.data_utils import IndexDataset, DataUtils\n",
        "# from utils.coll_utils import CollectionUtils\n",
        "\n",
        "\n",
        "class Stream(ABC):\n",
        "    def __init__(self, cls_names: list = None):\n",
        "        self.cls_names = cls_names if cls_names is not None else []\n",
        "\n",
        "\n",
        "class InstanceStream(Stream):\n",
        "\n",
        "    def __init__(self, dataset: Dataset, order=None, frac=1.0, shuffle=False, cls_names: list = None, init_frac: float = 0.0):\n",
        "        super().__init__(cls_names)\n",
        "        if order:\n",
        "            data_indices = order\n",
        "        else:\n",
        "            data_indices = list(RandomState(0).permutation(len(dataset))) if shuffle else np.arange(len(dataset))\n",
        "\n",
        "        if frac < 1.0:\n",
        "            indices = random.sample(range(len(data_indices)), int(frac * len(data_indices)))\n",
        "            data_indices = [data_indices[i] for i in sorted(indices)]\n",
        "\n",
        "        init_indices = []\n",
        "        if init_frac > 0.0:\n",
        "            f = int(init_frac * len(data_indices))\n",
        "            init_indices, data_indices = data_indices[:f], data_indices[f:]\n",
        "\n",
        "        self.init_data = Subset(dataset, init_indices)\n",
        "        self.data = Subset(dataset, data_indices)\n",
        "\n",
        "    def get_init_data(self):\n",
        "        return self.init_data\n",
        "\n",
        "    def get_data(self):\n",
        "        return self.data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "class ClassStream(Stream):\n",
        "\n",
        "    def __init__(self, train_dataset: Dataset, test_dataset: Dataset=None, class_size: int=1, class_frac: float=1.0,\n",
        "                 class_batch_seq: list=None, test_frac: float=0.2, max_cls_num=-1, cls_names: list=None, init_data: Dict=None):\n",
        "        super().__init__(cls_names)\n",
        "\n",
        "        if not test_dataset:\n",
        "            indices = list(RandomState(0).permutation(len(train_dataset)))\n",
        "            f = int(test_frac * len(indices))\n",
        "            test_dataset = Subset(train_dataset, indices[:f])\n",
        "            train_dataset = Subset(train_dataset, indices[f:])\n",
        "\n",
        "        train_class_batch = self.create_class_batches(train_dataset, class_size, class_batch_seq, max_cls_num)\n",
        "\n",
        "        init_indices, init_class_concept_mapping = [], {}\n",
        "        cf = class_frac\n",
        "        random.seed(0)\n",
        "\n",
        "        if init_data is not None:\n",
        "            for class_batch_idx, frac in init_data.items():\n",
        "                class_idx, class_batch_indices, class_concept_mapping = train_class_batch[class_batch_idx]\n",
        "\n",
        "                f = int(frac * len(class_batch_indices))\n",
        "                train_class_batch[class_batch_idx] = (class_idx, class_batch_indices[f:], class_concept_mapping)\n",
        "\n",
        "                init_indices.extend(class_batch_indices[:f])\n",
        "                init_class_concept_mapping.update(class_concept_mapping)\n",
        "\n",
        "        self.init_data = (init_class_concept_mapping, Subset(train_dataset, init_indices if cf == 1.0 else random.sample(init_indices, int(cf * len(init_indices)))))\n",
        "\n",
        "        self.train_data = [(class_idx, Subset(train_dataset, indices if cf == 1.0 else random.sample(indices, int(cf * len(indices)))), class_concept_mapping)\n",
        "                           for class_idx, indices, class_concept_mapping in train_class_batch]\n",
        "\n",
        "        test_class_batch = self.create_class_batches(test_dataset, class_size, class_batch_seq, -1)\n",
        "        self.test_data = [(class_idx, Subset(test_dataset, indices if cf == 1.0 else random.sample(indices, int(cf * len(indices)))), class_concept_mapping)\n",
        "                          for class_idx, indices, class_concept_mapping in test_class_batch]\n",
        "\n",
        "    def get_init_data(self):\n",
        "        return self.init_data\n",
        "\n",
        "    def get_train_data(self):\n",
        "        return self.train_data\n",
        "\n",
        "    def get_test_data(self):\n",
        "        return self.test_data\n",
        "\n",
        "    @staticmethod\n",
        "    def create_class_batches(dataset, class_size, class_batch_seq, max_cls_num):\n",
        "        indices_per_class = DataUtils.get_class_indices(IndexDataset(dataset))\n",
        "\n",
        "        if not class_batch_seq:\n",
        "            input_classes = sorted(list(indices_per_class.keys()))\n",
        "            class_batch_seq = CollectionUtils.split_list(input_classes, class_size)\n",
        "\n",
        "            for i, subclasses in enumerate(class_batch_seq):\n",
        "                class_batch_seq[i] = (i, subclasses, {c: i for c in subclasses})\n",
        "\n",
        "        indices_per_class_batch = [(class_idx, CollectionUtils.flatten_list([indices_per_class[cls] for cls in classes]), concept_mapping)\n",
        "                                   for i, (class_idx, classes, concept_mapping) in enumerate(class_batch_seq)]\n",
        "\n",
        "        if max_cls_num > -1:\n",
        "            for i, b in enumerate(indices_per_class_batch):\n",
        "                indices_per_class_batch[i] = (b[0], b[1][:max_cls_num], b[2])\n",
        "\n",
        "        return indices_per_class_batch"
      ],
      "metadata": {
        "id": "_Dsx9WiD5Ay9"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plt_utils.py \n",
        "import matplotlib.pyplot as plt\n",
        "import io\n",
        "import tensorflow as tf\n",
        "import itertools\n",
        "import numpy as np\n",
        "import matplotlib.colors as mcolors\n",
        "\n",
        "\n",
        "class PlotUtils:\n",
        "\n",
        "    @staticmethod\n",
        "    def create_image_grid(images, labels, cls_names):\n",
        "        figure = plt.figure(figsize=(20, 20))\n",
        "        rows, cols = (10, 10) if len(images) == 100 else (5, 5)\n",
        "\n",
        "        for i in range(min(rows * cols, len(images))):\n",
        "            cls_idx = labels[i].item()\n",
        "            plt.subplot(rows, cols, i + 1, title=cls_names[cls_idx] if len(cls_names) > cls_idx else cls_idx)\n",
        "            plt.xticks([])\n",
        "            plt.yticks([])\n",
        "            plt.grid(False)\n",
        "            plt.imshow(images[i])\n",
        "\n",
        "        return figure\n",
        "\n",
        "    @staticmethod\n",
        "    def fig_to_image(figure):\n",
        "        buf = io.BytesIO()\n",
        "        plt.savefig(buf, format='png')\n",
        "        plt.close(figure)\n",
        "\n",
        "        buf.seek(0)\n",
        "        image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
        "        image = tf.expand_dims(image, 0)\n",
        "\n",
        "        return image\n",
        "\n",
        "    @staticmethod\n",
        "    def create_confusion_matrix(cm, class_names, title=None):\n",
        "        figure = plt.figure(figsize=(8, 8))\n",
        "\n",
        "        colors = plt.cm.Blues(np.linspace(0, 1, 128))\n",
        "        cmap = mcolors.LinearSegmentedColormap.from_list('colormap', colors)\n",
        "\n",
        "        plt.imshow(cm, interpolation='nearest', cmap=cmap if len(cm) > 1 else plt.cm.Blues_r)\n",
        "        if title: plt.title(title, fontsize=24, pad=16)\n",
        "\n",
        "        tick_marks = np.arange(len(class_names))\n",
        "        plt.xticks(tick_marks, class_names, rotation=45, fontsize=12)\n",
        "        plt.yticks(tick_marks, class_names, fontsize=12)\n",
        "\n",
        "        labels = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
        "\n",
        "        threshold = cm.max() / 2.\n",
        "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "            color = 'white' if cm[i, j] > threshold else 'black'\n",
        "            plt.text(j, i, labels[i, j], horizontalalignment='center', color=color)\n",
        "\n",
        "        plt.ylabel('True label', fontsize=16, labelpad=20)\n",
        "        plt.xlabel('Predicted label', fontsize=16, labelpad=20)\n",
        "\n",
        "        return figure"
      ],
      "metadata": {
        "id": "KzptPmRx-nm8"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tf_writers.py\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import sklearn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "#from utils.plt_utils import PlotUtils as pu\n",
        "\n",
        "\n",
        "class TBScalars:\n",
        "\n",
        "    @staticmethod\n",
        "    def write_epoch_result(tasks_acc, epoch, stream_label, i):\n",
        "        tf.summary.scalar(f'{stream_label}#EPOCHS/C{i}', sum(tasks_acc) / len(tasks_acc), epoch,\n",
        "                          description='x=epochs, y=overall accuracy')\n",
        "        tf.summary.flush()\n",
        "\n",
        "    @staticmethod\n",
        "    def write_tasks_results(stream_label, tasks_acc, i):\n",
        "        for j, acc in enumerate(tasks_acc):\n",
        "            tf.summary.scalar(f'{stream_label}/C{j}', acc, i,\n",
        "                              description='x=class ids, y=accuracy for a given Ci')  # todo: add configurable class-aggregation?\n",
        "\n",
        "        tf.summary.scalar(f'ALL/{stream_label}', sum(tasks_acc) / len(tasks_acc), i,\n",
        "                          description='x=class ids, y=overall accuracy')\n",
        "        tf.summary.flush()\n",
        "\n",
        "\n",
        "class TBImages:\n",
        "\n",
        "    @staticmethod\n",
        "    def write_test_data(data: Dataset, i: int, stream_label: str, cls_names: list):\n",
        "        loader = DataLoader(data, batch_size=100, shuffle=True)\n",
        "\n",
        "        images, labels = next(iter(loader))\n",
        "        images = np.transpose(images.reshape(*images.shape), (0, 2, 3, 1))\n",
        "        figure = PlotUtils.create_image_grid(images, labels, cls_names)\n",
        "\n",
        "        tf.summary.image(f'{stream_label}#EXAMPLES', PlotUtils.fig_to_image(figure), step=i)\n",
        "        tf.summary.flush()\n",
        "\n",
        "    @staticmethod\n",
        "    def write_confusion_matrices(labels, preds, i, stream_label):\n",
        "        cm = sklearn.metrics.confusion_matrix(labels, preds)\n",
        "        cm[np.isnan(cm)] = 0.0\n",
        "\n",
        "        figure = PlotUtils.create_confusion_matrix(cm, class_names=[f'C{k}' for k in range(len(cm))])\n",
        "\n",
        "        tf.summary.image(f'{stream_label}#CONF-MATS', PlotUtils.fig_to_image(figure), step=i)\n",
        "        tf.summary.flush()\n",
        "\n",
        "        return cm\n",
        "\n"
      ],
      "metadata": {
        "id": "RpySj3iQ-0n_"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# eval.py\n",
        "import collections\n",
        "import copy\n",
        "import os\n",
        "\n",
        "import torch\n",
        "from typing import Callable\n",
        "from abc import ABC, abstractmethod\n",
        "from skmultiflow.drift_detection import ADWIN\n",
        "from torch import Tensor\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import torch.utils.tensorboard as tb\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "#from core.clearn import ContinualLearner\n",
        "#from data.stream import Stream, InstanceStream, ClassStream\n",
        "#from eval.tf_writers import TBScalars, TBImages\n",
        "\n",
        "\n",
        "class Evaluator(ABC):\n",
        "\n",
        "    @abstractmethod\n",
        "    def evaluate(self, model_creator: (str, Callable[[], ContinualLearner]), data_creator: (str, Callable[[], Stream])):\n",
        "        pass\n",
        "\n",
        "\n",
        "class InstanceStreamEvaluator(Evaluator):\n",
        "\n",
        "    def __init__(self, batch_size: int, shuffle=False, init_skip_frac=0.05, numpy=False, logdir_root: str='runs'):\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.init_skip_frac = init_skip_frac\n",
        "        self.numpy = numpy\n",
        "        self.logdir_root = logdir_root\n",
        "\n",
        "    def evaluate(self, model_creator: (str, Callable[[], ContinualLearner]), data_creator: (str, Callable[[], Stream])):\n",
        "        model_label, model_creator = model_creator\n",
        "        stream_label, stream_creator = data_creator\n",
        "\n",
        "        print('[1/3] Preparing data')\n",
        "        instance_stream: InstanceStream = stream_creator()\n",
        "        instance_stream_loader = DataLoader(instance_stream.get_data(), batch_size=self.batch_size, shuffle=self.shuffle)\n",
        "\n",
        "        print('[2/3] Preparing model')\n",
        "        model = model_creator()\n",
        "\n",
        "        init_data = instance_stream.get_init_data()\n",
        "        n = len(init_data)\n",
        "        if n > 0:\n",
        "            print(f'Initializing model with {n} instances')\n",
        "            init_data_loader = DataLoader(init_data, batch_size=n, shuffle=self.shuffle)\n",
        "            inputs_batch, labels_batch = next(iter(init_data_loader))\n",
        "            if self.numpy: inputs_batch, labels_batch = inputs_batch.numpy(), labels_batch.numpy()\n",
        "            model.initialize(inputs_batch, labels_batch)\n",
        "\n",
        "        print('[3/3] Preparing metrics')\n",
        "        per_class_acc = {}\n",
        "        acc = ADWIN()\n",
        "        correct = 0.0\n",
        "        all = 0.0\n",
        "        init_skip_num = self.init_skip_frac * len(instance_stream)\n",
        "\n",
        "        logdir = f'{self.logdir_root}/{model_label}'\n",
        "        tb_writer = tb.SummaryWriter(logdir)\n",
        "\n",
        "        print('Evaluating...')\n",
        "        i = 0\n",
        "        for inputs_batch, labels_batch in tqdm(instance_stream_loader):\n",
        "            if self.numpy: inputs_batch, labels_batch = inputs_batch.numpy(), labels_batch.numpy()\n",
        "\n",
        "            i += len(inputs_batch)\n",
        "            preds = model.predict(inputs_batch)\n",
        "            model.update(inputs_batch, labels_batch)\n",
        "\n",
        "            results = [int(int(p) == int(y)) for p, y in zip(preds, labels_batch)]\n",
        "            correct += sum(results)\n",
        "            all += len(inputs_batch)\n",
        "\n",
        "            for r, l in zip(results, labels_batch):\n",
        "                acc.add_element(float(r))\n",
        "                l = int(l)\n",
        "\n",
        "                if l not in per_class_acc:\n",
        "                    per_class_acc[l] = ADWIN()\n",
        "                per_class_acc[l].add_element(float(r))\n",
        "\n",
        "            if i > init_skip_num:\n",
        "                tb_writer.add_scalar(f'ALL/{stream_label}', acc.estimation, i)\n",
        "\n",
        "                for c, c_acc in per_class_acc.items():\n",
        "                    tb_writer.add_scalar(f'{stream_label}/{stream_label}-C{c}', c_acc.estimation, i)\n",
        "\n",
        "\n",
        "class ClassStreamEvaluator(Evaluator):\n",
        "\n",
        "    def __init__(self, batch_size: int, shuffle: bool, num_epochs: int, num_workers: int, numpy=False, vis=True, logdir_root: str='runs'):\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.num_epochs = num_epochs\n",
        "        self.num_workers = num_workers\n",
        "        self.numpy = numpy\n",
        "        self.vis = vis\n",
        "        self.logdir_root = logdir_root\n",
        "\n",
        "    def evaluate(self, model_creator: (str, Callable[[], ContinualLearner]), data_creator: (str, Callable[[], Stream])):\n",
        "        model_label, model_creator = model_creator\n",
        "        stream_label, stream_creator = data_creator\n",
        "\n",
        "        print('[1/3] Preparing data')\n",
        "        class_stream: ClassStream = stream_creator()\n",
        "        train_class_stream = class_stream.get_train_data()\n",
        "        test_class_stream = iter(class_stream.get_test_data())\n",
        "\n",
        "        print('[2/3] Preparing model')\n",
        "        model = model_creator()\n",
        "\n",
        "        init_class_concept_mapping, init_data = class_stream.get_init_data()\n",
        "        n = len(init_data)\n",
        "        if n > 0:\n",
        "            print(f'Initializing model with {n} instances')\n",
        "            init_data_loader = DataLoader(init_data, batch_size=n, num_workers=self.num_workers, shuffle=self.shuffle)\n",
        "            inputs_batch, labels_batch = next(iter(init_data_loader))\n",
        "            labels_batch = Tensor([init_class_concept_mapping[int(cls.item())] for cls in labels_batch])\n",
        "            if self.numpy: inputs_batch, labels_batch = inputs_batch.numpy(), labels_batch.numpy()\n",
        "            model.initialize(inputs_batch, labels_batch)\n",
        "\n",
        "        print('[3/3] Preparing metrics')\n",
        "        logdir = f'{self.logdir_root}/{model_label}'\n",
        "        tb_file_writer = tf.summary.create_file_writer(logdir)\n",
        "        tb_file_writer.set_as_default()\n",
        "        classes_test_data = {}\n",
        "        class_test_concept_mapping = {}\n",
        "        results = collections.defaultdict(list)\n",
        "        cms = []\n",
        "\n",
        "        print('Evaluating...')\n",
        "        for i, class_batch_data in enumerate(tqdm(train_class_stream)):\n",
        "            (class_idx, class_batch_train_data, class_concept_mapping) = class_batch_data\n",
        "            (test_class_idx, class_batch_test_data, test_class_concept_mapping) = next(test_class_stream)\n",
        "\n",
        "            assert class_idx == test_class_idx and class_concept_mapping == test_class_concept_mapping\n",
        "            class_test_concept_mapping.update(class_concept_mapping)\n",
        "\n",
        "            classes_test_data[class_idx] = DataLoader(class_batch_test_data, batch_size=self.batch_size, num_workers=self.num_workers)  # todo: subclasses\n",
        "            if self.vis: TBImages.write_test_data(class_batch_test_data, i, stream_label, class_stream.cls_names)\n",
        "\n",
        "            for j in range(self.num_epochs):\n",
        "                train_data_loader = DataLoader(class_batch_train_data, batch_size=self.batch_size, num_workers=self.num_workers, shuffle=self.shuffle)\n",
        "                for inputs_batch, labels_batch in tqdm(train_data_loader):\n",
        "                    labels_batch = Tensor([class_concept_mapping[int(cls.item())] for cls in labels_batch])\n",
        "                    if self.numpy: inputs_batch, labels_batch = inputs_batch.numpy(), labels_batch.numpy()\n",
        "                    model.update(inputs_batch, labels_batch)\n",
        "\n",
        "                # tasks_acc, _ = evaluate_tasks(model, classes_test_data, class_test_concept_mapping, self.numpy)\n",
        "                # TBScalars.write_epoch_result(tasks_acc, j, stream_label, i)\n",
        "\n",
        "            tasks_acc, (task_targets, task_preds) = evaluate_tasks(model, classes_test_data, class_test_concept_mapping, self.numpy)\n",
        "\n",
        "            for k, task_acc in enumerate(tasks_acc): results[k + 1].append(task_acc)\n",
        "            results[0].append(sum(tasks_acc) / len(tasks_acc))\n",
        "\n",
        "            TBScalars.write_tasks_results(stream_label, tasks_acc, i)\n",
        "            cm = TBImages.write_confusion_matrices(task_targets, task_preds, i, stream_label)\n",
        "            if (i + 1) % 10 == 0: cms.append(cm)\n",
        "\n",
        "        write_result_to_file(model_label, stream_label, results, cms)\n",
        "\n",
        "\n",
        "class OfflineClassStreamEvaluator(Evaluator):\n",
        "\n",
        "    def __init__(self, batch_size: int, num_epochs: int, num_workers: int, numpy=False, vis=True, logdir_root: str='runs',\n",
        "                 model_path: str=None):\n",
        "        self.batch_size = batch_size\n",
        "        self.num_epochs = num_epochs\n",
        "        self.num_workers = num_workers\n",
        "        self.numpy = numpy\n",
        "        self.vis = vis\n",
        "        self.logdir_root = logdir_root\n",
        "        self.model_path = model_path\n",
        "\n",
        "    def evaluate(self, model_creator: (str, Callable[[], ContinualLearner]), data_creator: (str, Callable[[], Stream])):\n",
        "        model_label, model_creator = model_creator\n",
        "        stream_label, stream_creator = data_creator\n",
        "        model = None\n",
        "\n",
        "        print('[1/2] Preparing data')\n",
        "        class_stream: ClassStream = stream_creator()\n",
        "        train_class_stream = class_stream.get_train_data()\n",
        "        test_class_stream = iter(class_stream.get_test_data())\n",
        "\n",
        "        print('[2/2] Preparing metrics')\n",
        "        logdir = f'{self.logdir_root}/{model_label}'\n",
        "        tb_file_writer = tf.summary.create_file_writer(logdir)\n",
        "        tb_file_writer.set_as_default()\n",
        "        all_train_data = None\n",
        "        classes_test_data = {}\n",
        "        class_test_concept_mapping = {}\n",
        "        results = collections.defaultdict(list)\n",
        "        cms = []\n",
        "\n",
        "        print('Evaluating...')\n",
        "        for i, class_batch_data in enumerate(tqdm(train_class_stream)):\n",
        "            (class_idx, class_batch_train_data, class_concept_mapping) = class_batch_data\n",
        "            (test_class_idx, class_batch_test_data, test_class_concept_mapping) = next(test_class_stream)\n",
        "\n",
        "            assert class_idx == test_class_idx and class_concept_mapping == test_class_concept_mapping\n",
        "            class_test_concept_mapping.update(class_concept_mapping)\n",
        "\n",
        "            all_train_data = all_train_data + class_batch_train_data if all_train_data is not None else class_batch_train_data\n",
        "            all_train_data_loader = DataLoader(all_train_data, batch_size=self.batch_size, num_workers=self.num_workers,\n",
        "                                               shuffle=True)\n",
        "\n",
        "            classes_test_data[class_idx] = DataLoader(class_batch_test_data, batch_size=self.batch_size, num_workers=self.num_workers,\n",
        "                                             shuffle=True)\n",
        "            if self.vis: TBImages.write_test_data(class_batch_test_data, i, stream_label, class_stream.cls_names)\n",
        "\n",
        "            model = model_creator()\n",
        "\n",
        "            for j in tqdm(range(self.num_epochs)):\n",
        "                for inputs_batch, labels_batch in all_train_data_loader:\n",
        "                    labels_batch = Tensor([class_test_concept_mapping[int(cls.item())] for cls in labels_batch])\n",
        "                    if self.numpy: inputs_batch, labels_batch = inputs_batch.numpy(), labels_batch.numpy()\n",
        "                    model.update(inputs_batch, labels_batch)\n",
        "\n",
        "                if hasattr(model, 'scheduler') and model.scheduler is not None:\n",
        "                    model.scheduler.step()\n",
        "\n",
        "                tasks_acc, _ = evaluate_tasks(model, classes_test_data, class_test_concept_mapping, self.numpy)\n",
        "                TBScalars.write_epoch_result(tasks_acc, j, stream_label, i)\n",
        "\n",
        "            tasks_acc, (task_targets, task_preds) = evaluate_tasks(model, classes_test_data, class_test_concept_mapping, self.numpy)\n",
        "\n",
        "            for k, task_acc in enumerate(tasks_acc): results[k + 1].append(task_acc)\n",
        "            results[0].append(sum(tasks_acc) / len(tasks_acc))\n",
        "\n",
        "            TBScalars.write_tasks_results(stream_label, tasks_acc, i)\n",
        "            cm = TBImages.write_confusion_matrices(task_targets, task_preds, i, stream_label)\n",
        "            if (i + 1) % 10 == 0: cms.append(cm)\n",
        "\n",
        "        write_result_to_file(model_label, stream_label, results, cms)\n",
        "\n",
        "        if self.model_path:\n",
        "            print(f'Saving model: {self.model_path}')\n",
        "            torch.save(model.get_net().state_dict(), self.model_path)\n",
        "\n",
        "\n",
        "def evaluate_tasks(model: ContinualLearner, classes_test_data, class_test_concept_mapping, numpy):\n",
        "    classes_acc, class_targets, class_preds = [], [], []\n",
        "\n",
        "    for j, class_test_data in classes_test_data.items():\n",
        "        correct, all = 0.0, 0.0\n",
        "\n",
        "        for inputs_batch, labels_batch in class_test_data:\n",
        "            labels_batch = Tensor([class_test_concept_mapping[int(cls.item())] for cls in labels_batch.long()])\n",
        "            if numpy: inputs_batch, labels_batch = inputs_batch.numpy(), labels_batch.numpy()\n",
        "\n",
        "            preds_batch = model.predict(inputs_batch)\n",
        "            results = [p == y for p, y in zip(preds_batch, labels_batch)]\n",
        "            correct += sum(results)\n",
        "            all += len(inputs_batch)\n",
        "\n",
        "            class_targets += list(labels_batch)\n",
        "            class_preds += list(preds_batch)\n",
        "\n",
        "        acc = correct / all\n",
        "        classes_acc.append(acc)  # todo: add per subclass\n",
        "\n",
        "    return classes_acc, (class_targets, class_preds)\n",
        "\n",
        "\n",
        "def write_result_to_file(model_label, stream_label, results, cms):\n",
        "    os.makedirs('results', exist_ok=True)\n",
        "    path = f'results/{model_label}#{stream_label}.csv'\n",
        "    print('Writing results to file ', path)\n",
        "\n",
        "    num_tasks = len(results[0])\n",
        "\n",
        "    f = open(path, 'w')\n",
        "    for task_id, values in results.items():\n",
        "        ext = [0.0] * (num_tasks - len(values))\n",
        "        values = ext + values\n",
        "        values = [str(f.item() if torch.is_tensor(f) else str(f)) for f in values]\n",
        "        vals = ','.join(values)\n",
        "        f.write(f'{task_id},{vals}\\n')\n",
        "    f.close()\n",
        "\n",
        "    path = f'results/{model_label}#{stream_label}_cms.npy'\n",
        "    print(f'Writing {len(cms)} confusion matrices to file ', path)\n",
        "    np.save(path, np.array(cms, dtype=object))"
      ],
      "metadata": {
        "id": "9RZ25J_l-_Rz"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#experiment.py\n",
        "\n",
        "# from core.clearn import ContinualLearner\n",
        "# from data.stream import Stream\n",
        "# from eval.eval import Evaluator\n",
        "\n",
        "import itertools\n",
        "from abc import ABC, abstractmethod\n",
        "from typing import List, Dict, Callable\n",
        "\n",
        "\n",
        "class Experiment(ABC):\n",
        "\n",
        "    def __init__(self):\n",
        "        self.algorithms: Dict[str, Callable[[], ContinualLearner]] = {}\n",
        "        self.streams: Dict[str, Callable[[], Stream]] = {}\n",
        "        self.evaluators: Dict[str, Callable[[], Evaluator]] = {}\n",
        "\n",
        "    def run(self, algorithms: List[str] = None, streams: List[str] = None, evaluators: List[str] = None):\n",
        "        self.prepare()\n",
        "        algorithms = self.algorithms.keys() if not algorithms else algorithms\n",
        "        streams = self.streams.keys() if not streams else streams\n",
        "        evaluators = self.evaluators.keys() if not evaluators else evaluators\n",
        "\n",
        "        for a, s, e, in itertools.product(algorithms, streams, evaluators):\n",
        "            print(f'Running for: {a}, {s}, {e}')\n",
        "            self.evaluators[e]().evaluate((a, self.algorithms[a]), (s, self.streams[s]))\n",
        "\n",
        "    def add_algorithm_creator(self, label: str, algorithm: Callable[[], ContinualLearner]):\n",
        "        self.algorithms[label] = algorithm\n",
        "\n",
        "    def add_data_creator(self, label: str, stream: Callable[[], Stream]):\n",
        "        self.streams[label] = stream\n",
        "\n",
        "    def add_evaluator_creator(self, label: str, evaluator: Callable[[], Evaluator]):\n",
        "        self.evaluators[label] = evaluator\n",
        "\n",
        "    @abstractmethod\n",
        "    def prepare(self):\n",
        "        pass"
      ],
      "metadata": {
        "id": "VD_tR6Cr_NA1"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RiverWrapper(ContinualLearner):\n",
        "    \n",
        "    def __init__(self, classifier: Classifier):\n",
        "        super().__init__()\n",
        "        self.classifier = classifier\n",
        "\n",
        "    def predict(self, x_batch):\n",
        "        preds = np.zeros(len(x_batch))\n",
        "\n",
        "        for i, x in enumerate(x_batch):\n",
        "            xd = {k: x[k] for k in range(len(x))}\n",
        "            preds[i] = self.classifier.predict_one(xd)\n",
        "\n",
        "        return preds\n",
        "\n",
        "    def predict_prob(self, x_batch):\n",
        "        pass\n",
        "\n",
        "    def update(self, x_batch, y_batch, **kwargs):\n",
        "        weights = kwargs.get('weights', np.ones(len(y_batch)))\n",
        "        y_batch = y_batch.astype(int) if isinstance(y_batch, np.ndarray) else y_batch.int()\n",
        "\n",
        "        for x, y, w in zip(x_batch, y_batch, weights):\n",
        "            xd = {k: x[k] for k in range(len(x))}\n",
        "            self.classifier.learn_one(xd, y)"
      ],
      "metadata": {
        "id": "LMkh4DD__RbQ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qmRrtMfr_bui",
        "outputId": "6d3ac99d-e2a3-4bb6-c962-bd29245cc02c"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mkdir 'll_dt_tree'"
      ],
      "metadata": {
        "id": "fhtV8E2Y_Y4J"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "lldt_runner.py "
      ],
      "metadata": {
        "id": "p6uB1AcjAgoS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "import os\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "from skmultiflow.trees import HoeffdingTreeClassifier\n",
        "from river.ensemble import AdaptiveRandomForestClassifier\n",
        "from river.tree import HoeffdingTreeClassifier\n",
        "from river.multiclass.ovr import OneVsRestClassifier\n",
        "\n",
        "# import data.data_collection as data_col\n",
        "# from data.stream import ClassStream\n",
        "# from eval.eval import ClassStreamEvaluator\n",
        "# from eval.experiment import Experiment\n",
        "# from learners.ht import HoeffdingTree\n",
        "# from learners.irf import IncrementalRandomForest\n",
        "# from utils.cls_utils import RiverWrapper\n",
        "# import ray\n",
        "\n",
        "\n",
        "num_cores = multiprocessing.cpu_count()\n",
        "ray.init(num_cpus=num_cores, ignore_reinit_error=True)\n",
        "\n",
        "\n",
        "class ExperimentLifelongTree(Experiment):\n",
        "    def prepare(self):\n",
        "        logdir_root = '/content/drive/ll_dt_tree'\n",
        "\n",
        "        self.add_algorithm_creator('HT', lambda: HoeffdingTree(att_split_est=False))\n",
        "        self.add_algorithm_creator('HT-s10', lambda: HoeffdingTree(att_split_est=False, split_wait=10))\n",
        "        self.add_algorithm_creator('HT-ae', lambda: HoeffdingTree(att_split_est=True, log_prob=True))\n",
        "        self.add_algorithm_creator('HT-ae-s10', lambda: HoeffdingTree(att_split_est=True, split_wait=10, log_prob=True))\n",
        "\n",
        "        self.add_algorithm_creator('IRF40', lambda: IncrementalRandomForest(size=40, num_workers=10, att_split_est=False))\n",
        "        self.add_algorithm_creator('IRF40-s10', lambda: IncrementalRandomForest(size=40, split_wait=10, num_workers=10, att_split_est=False))\n",
        "        self.add_algorithm_creator('IRF40-ae', lambda: IncrementalRandomForest(size=40, num_workers=10, att_split_est=True))\n",
        "        self.add_algorithm_creator('IRF40-ae-s10', lambda: IncrementalRandomForest(size=40, split_wait=10, num_workers=10, att_split_est=True))\n",
        "\n",
        "        self.add_algorithm_creator('ARF40', lambda: RiverWrapper(AdaptiveRandomForestClassifier(split_confidence=0.01, n_models=40)))\n",
        "        self.add_algorithm_creator('BAG40', lambda: IncrementalRandomForest(size=40, num_workers=10, att_split_est=False, rnd=False, subspaces=False))\n",
        "        self.add_algorithm_creator('RSP40', lambda: IncrementalRandomForest(size=40, num_workers=10, att_split_est=False, rnd=False, subspaces=True))\n",
        "        self.add_algorithm_creator('OVR', lambda: RiverWrapper(OneVsRestClassifier(HoeffdingTreeClassifier(split_confidence=0.01))))\n",
        "\n",
        "        # self.add_data_creator('MNIST-CI-FLAT',\n",
        "        #                       lambda: ClassStream(data_collection.get('MNIST-TRAIN-FLAT'), data_collection.get('MNIST-TEST-FLAT'), class_size=1))\n",
        "        # self.add_data_creator('FASHION-CI-FLAT',\n",
        "        #                       lambda: ClassStream(data_collection.get('FASHION-TRAIN-FLAT'), data_collection.get('FASHION-TEST-FLAT'), class_size=1))\n",
        "        self.add_data_creator('SVHN-TENSOR-CI',\n",
        "                              lambda: ClassStream(data_collection.get('SVHN-TRAIN-TENSOR'), data_collection.get('SVHN-TEST-TENSOR'), class_size=1, max_cls_num=4658))\n",
        "        # self.add_data_creator('CIFAR20C-TENSOR-CI',\n",
        "        #                       lambda: ClassStream(data_collection.get('CIFAR20C-TRAIN-TENSOR'), data_collection.get('CIFAR20C-TEST-TENSOR'), class_size=1))\n",
        "        # self.add_data_creator('IMAGENET20A-TENSOR-CI',\n",
        "        #                       lambda: ClassStream(data_collection.get('IMAGENET20A-TRAIN-TENSOR'), data_collection.get('IMAGENET20A-TEST-TENSOR'), class_size=1))\n",
        "        # self.add_data_creator('IMAGENET20B-TENSOR-CI',\n",
        "        #                       lambda: ClassStream(data_collection.get('IMAGENET20B-TRAIN-TENSOR'), data_collection.get('IMAGENET20B-TEST-TENSOR'), class_size=1))\n",
        "\n",
        "        self.add_evaluator_creator('IncEval-shallow', lambda: ClassStreamEvaluator(batch_size=256, shuffle=True, num_epochs=1, num_workers=8,\n",
        "                                                               logdir_root=logdir_root, numpy=True, vis=False))\n",
        "\n",
        "\n",
        "def run():\n",
        "    # seqs = ['MNIST-CI-FLAT', 'FASHION-CI-FLAT', 'SVHN-TENSOR-CI', 'CIFAR20C-TENSOR-CI']\n",
        "    # img_seqs = ['IMAGENET20A-TENSOR-CI', 'IMAGENET20B-TENSOR-CI']\n",
        "    seqs = ['SVHN-TENSOR-CI']\n",
        "    # img_seqs = ['IMAGENET20A-TENSOR-CI', 'IMAGENET20B-TENSOR-CI']\n",
        "\n",
        "    ExperimentLifelongTree().run(algorithms=['HT', 'IRF40'], streams=seqs, evaluators=['IncEval-shallow'])\n",
        "    # ExperimentLifelongTree().run(algorithms=['HT-s10', 'IRF40-s10'], streams=img_seqs, evaluators=['IncEval-shallow'])\n",
        "\n",
        "    ExperimentLifelongTree().run(algorithms=['HT-ae', 'IRF40-ae'], streams=seqs, evaluators=['IncEval-shallow'])\n",
        "    # ExperimentLifelongTree().run(algorithms=['HT-ae-s10', 'IRF40-ae-s10'], streams=img_seqs, evaluators=['IncEval-shallow'])\n",
        "\n",
        "    # ExperimentLifelongTree().run(algorithms=['ARF40', 'BAG40', 'RSP40', 'OVR'], streams=seqs + img_seqs, evaluators=['IncEval-shallow'])"
      ],
      "metadata": {
        "id": "ZJHYF1mTuk_Y"
      },
      "execution_count": 28,
      "outputs": []
    }
  ]
}