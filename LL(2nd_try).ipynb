{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ni7070/lifelong_learning/blob/master/LL(2nd_try).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0xvkWnBlKce"
      },
      "source": [
        "main() calls  \n",
        "\n",
        "```\n",
        "extractor.extract(False)\n",
        "lldt_runner.run()\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jWe2z2W3lGaF"
      },
      "outputs": [],
      "source": [
        "#tensor_set.py \n",
        "\n",
        "import os\n",
        "\n",
        "import torch\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "class TensorDataset(Dataset):\n",
        "    def __init__(self, path):\n",
        "        data = torch.load(path)\n",
        "        self.rows, self.labels = data[:, :-1], data[:, -1]\n",
        "        self.n = len(self.labels)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.rows[index], self.labels[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n\n",
        "\n",
        "\n",
        "def extract_features(image_dataset: Dataset, extractor: torch.nn.Module, out_path: str, device='cpu'):\n",
        "    print('Extracting features...')\n",
        "    loader = torch.utils.data.DataLoader(image_dataset, batch_size=256, num_workers=4)\n",
        "    n = len(image_dataset)\n",
        "    init = False\n",
        "    all_data = None\n",
        "\n",
        "    i = 0\n",
        "    for inputs, labels in tqdm(loader):\n",
        "        with torch.no_grad():\n",
        "            print('in', inputs.shape)\n",
        "            features = extractor(inputs.to(device)).cpu()\n",
        "            print('out', features.shape)\n",
        "            if not init:\n",
        "                all_data = torch.zeros((n, features.shape[1] + 1))\n",
        "                init = True\n",
        "\n",
        "            all_data[i:i + len(features), :-1] = features\n",
        "            all_data[i:i + len(features), -1] = labels\n",
        "\n",
        "        i += len(features)\n",
        "        print(i)\n",
        "\n",
        "    print(f'Saving to {out_path}')\n",
        "    os.makedirs(os.path.join(*out_path.split('/')[:-1]), exist_ok=True)\n",
        "    torch.save(all_data, out_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fXOZpb5ymbvP"
      },
      "outputs": [],
      "source": [
        "#learners/model/resnext.py \n",
        "\n",
        "from __future__ import division\n",
        "\n",
        "import torch\n",
        "\n",
        "\"\"\" \n",
        "Creates a ResNeXt Model as defined in:\n",
        "Xie, S., Girshick, R., Dollar, P., Tu, Z., & He, K. (2016). \n",
        "Aggregated residual transformations for deep neural networks. \n",
        "arXiv preprint arXiv:1611.05431.\n",
        "import from https://github.com/prlz77/ResNeXt.pytorch/blob/master/models/model.py\n",
        "\"\"\"\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import init\n",
        "\n",
        "__all__ = ['resnext']\n",
        "\n",
        "\n",
        "class ResNeXtBottleneck(nn.Module):\n",
        "    \"\"\"\n",
        "    RexNeXt bottleneck type C (https://github.com/facebookresearch/ResNeXt/blob/master/models/resnext.lua)\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, stride, cardinality, widen_factor):\n",
        "        \"\"\" Constructor\n",
        "        Args:\n",
        "            in_channels: input channel dimensionality\n",
        "            out_channels: output channel dimensionality\n",
        "            stride: conv stride. Replaces pooling layer.\n",
        "            cardinality: num of convolution groups.\n",
        "            widen_factor: factor to reduce the input dimensionality before convolution.\n",
        "        \"\"\"\n",
        "        super(ResNeXtBottleneck, self).__init__()\n",
        "        D = cardinality * out_channels // widen_factor\n",
        "        self.conv_reduce = nn.Conv2d(in_channels, D, kernel_size=1, stride=1, padding=0, bias=False)\n",
        "        self.bn_reduce = nn.BatchNorm2d(D)\n",
        "        self.conv_conv = nn.Conv2d(D, D, kernel_size=3, stride=stride, padding=1, groups=cardinality, bias=False)\n",
        "        self.bn = nn.BatchNorm2d(D)\n",
        "        self.conv_expand = nn.Conv2d(D, out_channels, kernel_size=1, stride=1, padding=0, bias=False)\n",
        "        self.bn_expand = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if in_channels != out_channels:\n",
        "            self.shortcut.add_module('shortcut_conv', nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, padding=0, bias=False))\n",
        "            self.shortcut.add_module('shortcut_bn', nn.BatchNorm2d(out_channels))\n",
        "\n",
        "    def forward(self, x):\n",
        "        bottleneck = self.conv_reduce.forward(x)\n",
        "        bottleneck = F.relu(self.bn_reduce.forward(bottleneck), inplace=True)\n",
        "        bottleneck = self.conv_conv.forward(bottleneck)\n",
        "        bottleneck = F.relu(self.bn.forward(bottleneck), inplace=True)\n",
        "        bottleneck = self.conv_expand.forward(bottleneck)\n",
        "        bottleneck = self.bn_expand.forward(bottleneck)\n",
        "        residual = self.shortcut.forward(x)\n",
        "        return F.relu(residual + bottleneck, inplace=True)\n",
        "\n",
        "\n",
        "class CifarResNeXt(nn.Module):\n",
        "    \"\"\"\n",
        "    ResNext optimized for the Cifar dataset, as specified in\n",
        "    https://arxiv.org/pdf/1611.05431.pdf\n",
        "    \"\"\"\n",
        "    def __init__(self, cardinality, depth, num_classes, widen_factor=4, dropRate=0):\n",
        "        \"\"\" Constructor\n",
        "        Args:\n",
        "            cardinality: number of convolution groups.\n",
        "            depth: number of layers.\n",
        "            num_classes: number of classes\n",
        "            widen_factor: factor to adjust the channel dimensionality\n",
        "        \"\"\"\n",
        "        super(CifarResNeXt, self).__init__()\n",
        "        self.cardinality = cardinality\n",
        "        self.depth = depth\n",
        "        self.block_depth = (self.depth - 2) // 9\n",
        "        self.widen_factor = widen_factor\n",
        "        self.num_classes = num_classes\n",
        "        self.output_size = 64\n",
        "        self.stages = [64, 64 * self.widen_factor, 128 * self.widen_factor, 256 * self.widen_factor]\n",
        "\n",
        "        self.conv_1_3x3 = nn.Conv2d(3, 64, 3, 1, 1, bias=False)\n",
        "        self.bn_1 = nn.BatchNorm2d(64)\n",
        "        self.stage_1 = self.block('stage_1', self.stages[0], self.stages[1], 1)\n",
        "        self.stage_2 = self.block('stage_2', self.stages[1], self.stages[2], 2)\n",
        "        self.stage_3 = self.block('stage_3', self.stages[2], self.stages[3], 2)\n",
        "        self.classifier = nn.Linear(1024, num_classes)\n",
        "        init.kaiming_normal(self.classifier.weight)\n",
        "\n",
        "        for key in self.state_dict():\n",
        "            if key.split('.')[-1] == 'weight':\n",
        "                if 'conv' in key:\n",
        "                    init.kaiming_normal(self.state_dict()[key], mode='fan_out')\n",
        "                if 'bn' in key:\n",
        "                    self.state_dict()[key][...] = 1\n",
        "            elif key.split('.')[-1] == 'bias':\n",
        "                self.state_dict()[key][...] = 0\n",
        "\n",
        "    def block(self, name, in_channels, out_channels, pool_stride=2):\n",
        "        \"\"\" Stack n bottleneck modules where n is inferred from the depth of the network.\n",
        "        Args:\n",
        "            name: string name of the current block.\n",
        "            in_channels: number of input channels\n",
        "            out_channels: number of output channels\n",
        "            pool_stride: factor to reduce the spatial dimensionality in the first bottleneck of the block.\n",
        "        Returns: a Module consisting of n sequential bottlenecks.\n",
        "        \"\"\"\n",
        "        block = nn.Sequential()\n",
        "        for bottleneck in range(self.block_depth):\n",
        "            name_ = '%s_bottleneck_%d' % (name, bottleneck)\n",
        "            if bottleneck == 0:\n",
        "                block.add_module(name_, ResNeXtBottleneck(in_channels, out_channels, pool_stride, self.cardinality,\n",
        "                                                          self.widen_factor))\n",
        "            else:\n",
        "                block.add_module(name_,\n",
        "                                 ResNeXtBottleneck(out_channels, out_channels, 1, self.cardinality, self.widen_factor))\n",
        "        return block\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_1_3x3.forward(x)\n",
        "        x = F.relu(self.bn_1.forward(x), inplace=True)\n",
        "        x = self.stage_1.forward(x)\n",
        "        x = self.stage_2.forward(x)\n",
        "        x = self.stage_3.forward(x)\n",
        "        x = F.avg_pool2d(x, 8, 1)\n",
        "        x = x.view(-1, 1, 1024)\n",
        "\n",
        "        # todo: remove\n",
        "        x = F.avg_pool1d(x, 2)\n",
        "        x = x.view(-1, 512)\n",
        "\n",
        "        return x\n",
        "        #return self.classifier(x)\n",
        "\n",
        "\n",
        "def create_cifar_resnext(model_path: str):\n",
        "    checkpoint = torch.load(model_path)\n",
        "    state_dict = checkpoint['state_dict']\n",
        "\n",
        "    # new_state_dict = OrderedDict()\n",
        "    # for k, v in state_dict.items():\n",
        "    #     if 'module' not in k:\n",
        "    #         k = 'module.'+k\n",
        "    #     else:\n",
        "    #         k = k.replace('features.module.', 'module.features.')\n",
        "    #     new_state_dict[k] = v\n",
        "\n",
        "    net = CifarResNeXt(depth=29, cardinality=8, num_classes=100, widen_factor=4)\n",
        "    net = torch.nn.DataParallel(net)\n",
        "    net.load_state_dict(state_dict)\n",
        "\n",
        "    return net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "TmH6zYEhnT9J"
      },
      "outputs": [],
      "source": [
        "#Data_Utils\n",
        "import collections\n",
        "import os\n",
        "import zipfile\n",
        "from typing import Optional, Callable, Dict\n",
        "import torch\n",
        "from typing import Sequence\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import Dataset, Subset, DataLoader\n",
        "from torch.utils.data.dataset import T_co\n",
        "\n",
        "\n",
        "class IndexDataset(Dataset):\n",
        "\n",
        "    def __init__(self, dataset: Dataset):\n",
        "        self.dataset = dataset\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        data, target = self.dataset.__getitem__(index)\n",
        "        return data, target, index\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.dataset.__len__()\n",
        "\n",
        "\n",
        "class ClassSubset(Subset):\n",
        "\n",
        "    def __init__(self, dataset: Dataset[T_co], indices: Sequence[int], classes: Sequence[int]) -> None:\n",
        "        super().__init__(dataset, indices)\n",
        "        self.cls_map = {c: i for i, c in enumerate(classes)}\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img, target = self.dataset[self.indices[idx]]\n",
        "        return img, self.cls_map[target]\n",
        "\n",
        "\n",
        "class DataUtils:\n",
        "\n",
        "    @staticmethod\n",
        "    def create_dataset_subset(dataset: Dataset, classes: list, indices_path: str):\n",
        "        if os.path.exists(indices_path):\n",
        "            print(f'Loading indices from {indices_path}')\n",
        "            return ClassSubset(dataset, torch.load(indices_path), classes)\n",
        "\n",
        "        indices_per_class = DataUtils.get_class_indices(IndexDataset(dataset))\n",
        "\n",
        "        indices = []\n",
        "        for c in classes:\n",
        "            indices.extend(indices_per_class[c])\n",
        "\n",
        "        print(f'Writing indices to {indices_path}')\n",
        "        torch.save(indices, indices_path)\n",
        "\n",
        "        return ClassSubset(dataset, indices, classes)\n",
        "\n",
        "    @staticmethod\n",
        "    def create_dataset(root: str, dir_name: str, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None,\n",
        "                       download: bool = False, download_func: Optional[Callable] = None, zip_file: str = None, post_func: Optional[Callable] = None):\n",
        "        input_folder = os.path.join(root, dir_name)\n",
        "\n",
        "        if not os.path.exists(input_folder):\n",
        "            if download and download_func is not None:\n",
        "                print('Downloading the dataset')\n",
        "                download_func()\n",
        "\n",
        "                if os.path.exists(f'{root}/{zip_file}'):\n",
        "                    print(f'Extracting from {zip_file}')\n",
        "\n",
        "                    with zipfile.ZipFile(f'{root}/{zip_file}', 'r') as zip_ref:\n",
        "                        zip_ref.extractall(root)\n",
        "            else:\n",
        "                raise RuntimeError('Dataset not found. You can use download=True to download it')\n",
        "\n",
        "        if post_func is not None:\n",
        "            post_func(input_folder)\n",
        "\n",
        "        return ImageFolder(input_folder, transform, target_transform)\n",
        "\n",
        "    @staticmethod\n",
        "    def get_class_indices(dataset: IndexDataset) -> Dict[int, list]:\n",
        "        class_indices = collections.defaultdict(list)\n",
        "\n",
        "        for inputs, labels, indices in DataLoader(dataset, batch_size=1024, num_workers=4):\n",
        "            for label, idx in zip(labels.tolist(), indices.tolist()):\n",
        "                class_indices[label].append(idx)\n",
        "\n",
        "        return class_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ks7Xa067m4Th",
        "outputId": "60d665e6-fbe7-4631-a9fe-0c61829c42ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9675 sha256=4fcd42340dc139b02728db348f149cce3ba3e47586551d8f9710a33b98a63a89\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ]
        }
      ],
      "source": [
        "pip install wget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hulgrrgpnZO",
        "outputId": "56851a99-da1e-4339-a41b-bfd03ca38187"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "dXEVzJdep0Ii"
      },
      "outputs": [],
      "source": [
        "path_cifar_resnext29_pth_tar = '/content/drive/MyDrive/pth files/cifar_resnext29.pth.tar'\n",
        "svhn_train_save_path1 = '/content/drive/MyDrive/pth files/svhn10-2-train.pt'\n",
        "svhn_test_save_path1 = '/content/drive/MyDrive/pth files/svhn10-2-test.pt'\n",
        "svhn_train_save_path2 = '/content/drive/MyDrive/pth files/svhn10-train.pt'\n",
        "svhn_test_save_path2 = '/content/drive/MyDrive/pth files/svhn10-test.pt'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ia_VXUrvmtOH"
      },
      "outputs": [],
      "source": [
        " #data.data_collection\n",
        "\n",
        "import torch\n",
        "import wget\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from PIL import Image\n",
        "\n",
        "# from data.cifar100_coarse import CIFAR100Coarse\n",
        "# from data.data_utils import DataUtils\n",
        "# from data.post_funcs import imagenet200_val_post\n",
        "# from data.tensor_set import TensorDataset\n",
        "\n",
        "pytorch_data_root = './pytorch_data'\n",
        "arff_data_root = './arff_data'\n",
        "\n",
        "\n",
        "\n",
        "data_creators = {\n",
        "    # 'MNIST-TRAIN': lambda: datasets.MNIST(pytorch_data_root, train=True, download=True, transform=transforms.Compose([transforms.ToTensor()])),\n",
        "    # 'MNIST-TEST': lambda: datasets.MNIST(pytorch_data_root, train=False, download=True, transform=transforms.Compose([transforms.ToTensor()])),\n",
        "    # 'MNIST-TRAIN-FLAT': lambda: datasets.MNIST(pytorch_data_root, train=True, download=True, transform=transforms.Compose([transforms.ToTensor(), transforms.Lambda(lambda x: torch.flatten(x))])),\n",
        "    # 'MNIST-TEST-FLAT': lambda: datasets.MNIST(pytorch_data_root, train=False, download=True, transform=transforms.Compose([transforms.ToTensor(), transforms.Lambda(lambda x: torch.flatten(x))])),\n",
        "    # 'MNIST-TRAIN-TENSOR': lambda: TensorDataset(f'{pytorch_data_root}/extracted/mnist10-train.pt'),\n",
        "    # 'MNIST-TEST-TENSOR': lambda: TensorDataset(f'{pytorch_data_root}/extracted/mnist10-test.pt'),\n",
        "    # 'FASHION-TRAIN': lambda: datasets.FashionMNIST(pytorch_data_root, train=True, download=True, transform=transforms.Compose([transforms.RandomHorizontalFlip(), transforms.ToTensor()])),\n",
        "    # 'FASHION-TEST': lambda: datasets.FashionMNIST(pytorch_data_root, train=False, download=True, transform=transforms.Compose([transforms.ToTensor()])),\n",
        "    # 'FASHION-TRAIN-FLAT': lambda: datasets.FashionMNIST(pytorch_data_root, train=True, download=True, transform=transforms.Compose([transforms.RandomHorizontalFlip(), transforms.ToTensor(), transforms.Lambda(lambda x: torch.flatten(x))])),\n",
        "    # 'FASHION-TEST-FLAT': lambda: datasets.FashionMNIST(pytorch_data_root, train=False, download=True, transform=transforms.Compose([transforms.ToTensor(), transforms.Lambda(lambda x: torch.flatten(x))])),\n",
        "    # 'FASHION-TRAIN-TENSOR': lambda: TensorDataset(f'{pytorch_data_root}/extracted/fashion10-train.pt'),\n",
        "    # 'FASHION-TEST-TENSOR': lambda: TensorDataset(f'{pytorch_data_root}/extracted/fashion10-test.pt'),\n",
        "    'SVHN-TRAIN': lambda: datasets.SVHN(pytorch_data_root, split='train', transform=transforms.Compose([transforms.ToTensor()]), download=True),\n",
        "    'SVHN-TEST': lambda: datasets.SVHN(pytorch_data_root, split='test', transform=transforms.Compose([transforms.ToTensor()]), download=True),\n",
        "    'SVHN-TRAIN-TENSOR': lambda: TensorDataset(svhn_train_save_path1),\n",
        "    'SVHN-TEST-TENSOR': lambda: TensorDataset(svhn_test_save_path1),\n",
        "    # 'SVHN-TRAIN-TENSOR': lambda: TensorDataset(svhn_train_save_path2),\n",
        "    # 'SVHN-TEST-TENSOR': lambda: TensorDataset(svhn_train_save_path2),\n",
        "    \n",
        "    # 'CIFAR10-TRAIN': lambda: datasets.CIFAR10(pytorch_data_root, True, transform=transforms.Compose([transforms.RandomHorizontalFlip(), transforms.ToTensor()]), download=True),\n",
        "    # 'CIFAR10-TEST': lambda: datasets.CIFAR10(pytorch_data_root, False, transform=transforms.Compose([transforms.ToTensor()]), download=True),\n",
        "    # 'CIFAR10-TRAIN-TENSOR': lambda: TensorDataset(f'{pytorch_data_root}/extracted/cifar10-train.pt'),\n",
        "    # 'CIFAR10-TEST-TENSOR': lambda: TensorDataset(f'{pytorch_data_root}/extracted/cifar10-test.pt'),\n",
        "    # 'CIFAR100-TRAIN': lambda: datasets.CIFAR100(pytorch_data_root, True, transform=transforms.Compose([transforms.RandomHorizontalFlip(), transforms.ToTensor()]), download=True),\n",
        "    # 'CIFAR100-TEST': lambda: datasets.CIFAR100(pytorch_data_root, False, transform=transforms.Compose([transforms.ToTensor()]), download=True),\n",
        "    # 'CIFAR20C-TRAIN': lambda: CIFAR100Coarse(pytorch_data_root, train=True, transform=transforms.Compose([transforms.RandomHorizontalFlip(), transforms.ToTensor()]), download=True),\n",
        "    # 'CIFAR20C-TEST': lambda: CIFAR100Coarse(pytorch_data_root, train=False, transform=transforms.Compose([transforms.ToTensor()]), download=True),\n",
        "    # 'CIFAR20C-TRAIN-TENSOR': lambda: TensorDataset(f'{pytorch_data_root}/extracted/cifar20c-train.pt'),\n",
        "    # 'CIFAR20C-TEST-TENSOR': lambda: TensorDataset(f'{pytorch_data_root}/extracted/cifar20c-test.pt'),\n",
        "    # 'IMAGENET200-TRAIN': lambda: DataUtils.create_dataset(pytorch_data_root, 'tiny-imagenet-200/train',\n",
        "    #                                                       transform=transforms.Compose([transforms.Resize((224, 224), interpolation=Image.NEAREST), transforms.ToTensor()]),\n",
        "    #                                             download=True, download_func=lambda: wget.download('http://cs231n.stanford.edu/tiny-imagenet-200.zip', pytorch_data_root),\n",
        "    #                                             zip_file='tiny-imagenet-200.zip',),\n",
        "    # 'IMAGENET200-TEST': lambda: DataUtils.create_dataset(pytorch_data_root, 'tiny-imagenet-200/val',\n",
        "    #                                                      transform=transforms.Compose([transforms.Resize((224, 224), interpolation=Image.NEAREST), transforms.ToTensor()]),\n",
        "    #                                            download=True, download_func=lambda: wget.download('http://cs231n.stanford.edu/tiny-imagenet-200.zip', pytorch_data_root),\n",
        "    #                                            zip_file='tiny-imagenet-200.zip', post_func=imagenet200_val_post),\n",
        "    # 'IMAGENET10-TRAIN': lambda: DataUtils.create_dataset_subset(get('IMAGENET200-TRAIN'), [0, 22, 25, 68, 117, 145, 153, 176, 188, 198], f'{pytorch_data_root}/imagenet10-train-indices.pt'),\n",
        "    # 'IMAGENET10-TEST': lambda: DataUtils.create_dataset_subset(get('IMAGENET200-TEST'), [0, 22, 25, 68, 117, 145, 153, 176, 188, 198], f'{pytorch_data_root}/imagenet10-test-indices.pt'),\n",
        "    # 'IMAGENET10-TRAIN-TENSOR': lambda: TensorDataset(f'{pytorch_data_root}/extracted/imagenet10-train.pt'),\n",
        "    # 'IMAGENET10-TEST-TENSOR': lambda: TensorDataset(f'{pytorch_data_root}/extracted/imagenet10-test.pt'),\n",
        "    # 'IMAGENET20A-TRAIN': lambda: DataUtils.create_dataset_subset(get('IMAGENET200-TRAIN'), [i * 10 - 1 for i in range(1, 21)], f'{pytorch_data_root}/imagenet20a-train-indices.pt'),\n",
        "    # 'IMAGENET20A-TEST': lambda: DataUtils.create_dataset_subset(get('IMAGENET200-TEST'), [i * 10 - 1 for i in range(1, 21)], f'{pytorch_data_root}/imagenet20a-test-indices.pt'),\n",
        "    # 'IMAGENET20A-TRAIN-TENSOR': lambda: TensorDataset(f'{pytorch_data_root}/extracted/imagenet20a-train.pt'),\n",
        "    # 'IMAGENET20A-TEST-TENSOR': lambda: TensorDataset(f'{pytorch_data_root}/extracted/imagenet20a-test.pt'),\n",
        "    # 'IMAGENET20B-TRAIN': lambda: DataUtils.create_dataset_subset(get('IMAGENET200-TRAIN'), [i * 10 - 5 for i in range(1, 21)], f'{pytorch_data_root}/imagenet20b-train-indices.pt'),\n",
        "    # 'IMAGENET20B-TEST': lambda: DataUtils.create_dataset_subset(get('IMAGENET200-TEST'), [i * 10 - 5 for i in range(1, 21)], f'{pytorch_data_root}/imagenet20b-test-indices.pt'),\n",
        "    # 'IMAGENET20B-TRAIN-TENSOR': lambda: TensorDataset(f'{pytorch_data_root}/extracted/imagenet20b-train.pt'),\n",
        "    # 'IMAGENET20B-TEST-TENSOR': lambda: TensorDataset(f'{pytorch_data_root}/extracted/imagenet20b-test.pt'),\n",
        "    # 'CELEB-TRAIN': lambda: datasets.CelebA(pytorch_data_root, split='train', target_type='identity', transform=transforms.Compose([transforms.ToTensor()]), download=True),\n",
        "    # 'CELEB-TEST': lambda: datasets.CelebA(pytorch_data_root, split='test', target_type='identity', transform=transforms.Compose([transforms.ToTensor()]), download=True)\n",
        "\n",
        "    # TODO:\n",
        "    # CORE50: https://vlomonaco.github.io/core50/index.html#dataset\n",
        "    # IMAGENET1000 (64): https://patrykchrabaszcz.github.io/Imagenet32/\n",
        "\n",
        "    # A) MNIST, FASHION, SVHN, CIFAR10, IMG10\n",
        "    # B) CORE50, CIFAR100, IMG200\n",
        "    # C) CELEB, IMG1000\n",
        "}\n",
        "\n",
        "class data_collection():\n",
        "  def get(name: str):\n",
        "      return data_creators[name]()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "rovl8WLZn5ZG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchsummary import summary\n",
        "\n",
        "# from data.tensor_set import extract_features\n",
        "# from learners.models.resnext import create_cifar_resnext\n",
        "# import data.data_collection as data_col\n",
        "\n",
        "\n",
        "def extract(last):\n",
        "    print('Running')\n",
        "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # cifar_resnext29.pth.tar -> https://github.com/bearpaw/pytorch-classification/blob/master/models/cifar/resnext.py\n",
        "\n",
        "    extractor = create_cifar_resnext(path_cifar_resnext29_pth_tar)\n",
        "    extractor.classifier = torch.nn.Identity()\n",
        "    extractor.eval().to(device)\n",
        "    summary(extractor.to(device), (3, 32, 32))\n",
        "    dataset = data_collection.get('SVHN-TRAIN')\n",
        "    extract_features(dataset, extractor, svhn_train_save_path1, device=device)\n",
        "    dataset = data_collection.get('SVHN-TEST')\n",
        "    extract_features(dataset, extractor, svhn_test_save_path1, device=device)\n",
        "\n",
        "    # extractor = create_cifar_resnext(path_cifar_resnext29_pth_tar)\n",
        "    # extractor.classifier = torch.nn.Identity()\n",
        "    # extractor.eval().to(device)\n",
        "    # summary(extractor.to(device), (3, 32, 32))\n",
        "    # dataset = data_collection.get('CIFAR20C-TRAIN')\n",
        "    # extract_features(dataset, extractor, f'pytorch_data/extracted/cifar20c-train.pt', device=device)\n",
        "    # dataset = data_collection.get('CIFAR20C-TEST')\n",
        "    # extract_features(dataset, extractor, f'pytorch_data/extracted/cifar20c-test.pt', device=device)\n",
        "\n",
        "    # extractor = torchvision.models.resnet18(pretrained=True)\n",
        "    # fc1 = extractor.fc\n",
        "    # extractor.fc = torch.nn.Sequential(fc1, torch.nn.Linear(1000, 256), torch.nn.ReLU(), torch.nn.Linear(256, 20))\n",
        "    # extractor.load_state_dict(torch.load('pytorch_models/imgnet20a-2f.pth'))\n",
        "    # if not last: extractor.fc = torch.nn.Identity()\n",
        "    # extractor.eval().to(device)\n",
        "    # dataset = data_collection.get('IMAGENET20A-TRAIN')\n",
        "    # extract_features(dataset, extractor, f'pytorch_data/extracted/imagenet20a-train.pt', device=device)\n",
        "    # dataset = data_collection.get('IMAGENET20A-TEST')\n",
        "    # extract_features(dataset, extractor, f'pytorch_data/extracted/imagenet20a-test.pt', device=device)\n",
        "\n",
        "    # extractor = torchvision.models.resnet18(pretrained=True)\n",
        "    # fc1 = extractor.fc\n",
        "    # extractor.fc = torch.nn.Sequential(fc1, torch.nn.Linear(1000, 256), torch.nn.ReLU(), torch.nn.Linear(256, 20))\n",
        "    # extractor.load_state_dict(torch.load('pytorch_models/imgnet20b-2f.pth'))\n",
        "    # if not last: extractor.fc = torch.nn.Identity()\n",
        "    # extractor.eval().to(device)\n",
        "    # dataset = data_collection.get('IMAGENET20B-TRAIN')\n",
        "    # extract_features(dataset, extractor, f'pytorch_data/extracted/imagenet20b-train.pt', device=device)\n",
        "    # dataset = data_collection.get('IMAGENET20B-TEST')\n",
        "    # extract_features(dataset, extractor, f'pytorch_data/extracted/imagenet20b-test.pt', device=device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "eb07ac80c1584d5f8dce177777867265",
            "92cc0e98c41f41839a31da83b7d3c82b",
            "ccfe7fcb47524079bcfa2bb12f2b20ec",
            "c728a22baf424159875fc35939903bfc",
            "dab51c34a87f4430bed1ef675b519653",
            "e93465e670b94ea195f3bb53fe3a78bd",
            "b2b8199e917e44ceabe3068483a7bf77",
            "e5470947e4524295aab5c9195939992c",
            "2460148f13a849458ed8a3b05cb37c02",
            "d88b1077024649b7ad945f38c46c9a04",
            "f7132c5d5e244d4e83ba396410fed282",
            "87af4ba23efb4ec1ac5d453fad24ead6",
            "915945a9b19c4155bf4c4ae4e9357efc",
            "b156e123cc3d4d7a94cbaa3f84cf4ddd",
            "17cff304bbfe4d368bde6ce2f3d08bd3",
            "3b2ee8e30d374c8a8f121b8d8bc0f35b",
            "234a083c01b148bbaa27a0ba5f9f455e",
            "e8f22f5170e8473aa214f84444084280",
            "18f089b2536c463183e5708c23d38aa3",
            "de9b8ace5e9542fe8448aa246c769093",
            "2b8a2066269e4b2ea2f6477f16ca8d26",
            "a0a3318057e14d20999797927f827a73"
          ]
        },
        "id": "leU44M42pMCR",
        "outputId": "18c7af69-fa72-4f27-9cef-1d1da95a2ebb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:87: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:92: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1          [-1, 256, 32, 32]          16,384\n",
            "       BatchNorm2d-2          [-1, 256, 32, 32]             512\n",
            " ResNeXtBottleneck-3          [-1, 256, 32, 32]               0\n",
            " ResNeXtBottleneck-4          [-1, 256, 32, 32]               0\n",
            " ResNeXtBottleneck-5          [-1, 256, 32, 32]               0\n",
            "            Conv2d-6          [-1, 512, 16, 16]         131,072\n",
            "       BatchNorm2d-7          [-1, 512, 16, 16]           1,024\n",
            " ResNeXtBottleneck-8          [-1, 512, 16, 16]               0\n",
            " ResNeXtBottleneck-9          [-1, 512, 16, 16]               0\n",
            "ResNeXtBottleneck-10          [-1, 512, 16, 16]               0\n",
            "           Conv2d-11           [-1, 1024, 8, 8]         524,288\n",
            "      BatchNorm2d-12           [-1, 1024, 8, 8]           2,048\n",
            "ResNeXtBottleneck-13           [-1, 1024, 8, 8]               0\n",
            "ResNeXtBottleneck-14           [-1, 1024, 8, 8]               0\n",
            "ResNeXtBottleneck-15           [-1, 1024, 8, 8]               0\n",
            "     CifarResNeXt-16                  [-1, 512]               0\n",
            "================================================================\n",
            "Total params: 675,328\n",
            "Trainable params: 675,328\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 17.50\n",
            "Params size (MB): 2.58\n",
            "Estimated Total Size (MB): 20.09\n",
            "----------------------------------------------------------------\n",
            "Downloading http://ufldl.stanford.edu/housenumbers/train_32x32.mat to ./pytorch_data/train_32x32.mat\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/182040794 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eb07ac80c1584d5f8dce177777867265"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/287 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 1/287 [00:03<18:35,  3.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "256\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 2/287 [00:07<16:21,  3.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "512\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 3/287 [00:10<15:38,  3.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "768\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|▏         | 4/287 [00:13<15:15,  3.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "1024\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 5/287 [00:16<15:02,  3.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "1280\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 6/287 [00:19<14:53,  3.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "1536\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 7/287 [00:22<14:47,  3.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "1792\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 8/287 [00:25<14:42,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "2048\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 9/287 [00:29<14:37,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "2304\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 10/287 [00:32<14:34,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "2560\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 11/287 [00:35<14:31,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "2816\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 12/287 [00:38<14:28,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "3072\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▍         | 13/287 [00:41<14:25,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "3328\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▍         | 14/287 [00:44<14:22,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "3584\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 15/287 [00:47<14:20,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "3840\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 16/287 [00:51<14:18,  3.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "4096\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 17/287 [00:54<14:15,  3.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "4352\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▋         | 18/287 [00:57<14:13,  3.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "4608\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 19/287 [01:00<14:09,  3.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "4864\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 20/287 [01:03<14:05,  3.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "5120\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 21/287 [01:07<14:02,  3.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "5376\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 22/287 [01:10<13:58,  3.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "5632\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 23/287 [01:13<13:56,  3.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "5888\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 24/287 [01:16<13:52,  3.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "6144\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▊         | 25/287 [01:19<13:50,  3.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "6400\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 26/287 [01:22<13:47,  3.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "6656\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 27/287 [01:26<13:43,  3.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "6912\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|▉         | 28/287 [01:29<13:39,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "7168\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 29/287 [01:32<13:36,  3.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "7424\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 30/287 [01:35<13:33,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "7680\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 31/287 [01:38<13:30,  3.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "7936\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 32/287 [01:41<13:26,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "8192\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█▏        | 33/287 [01:44<13:22,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "8448\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 34/287 [01:48<13:20,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "8704\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 35/287 [01:51<13:17,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "8960\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 36/287 [01:54<13:13,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "9216\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 37/287 [01:57<13:10,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "9472\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 38/287 [02:00<13:07,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "9728\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▎        | 39/287 [02:03<13:05,  3.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "9984\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 40/287 [02:07<13:01,  3.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "10240\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 41/287 [02:10<12:57,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "10496\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▍        | 42/287 [02:13<12:54,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "10752\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▍        | 43/287 [02:16<12:51,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "11008\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 44/287 [02:19<12:48,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "11264\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 45/287 [02:22<12:45,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "11520\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 46/287 [02:26<12:41,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "11776\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▋        | 47/287 [02:29<12:39,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "12032\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 48/287 [02:32<12:35,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "12288\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 49/287 [02:35<12:32,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "12544\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 50/287 [02:38<12:29,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "12800\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 51/287 [02:41<12:26,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "13056\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 52/287 [02:45<12:22,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "13312\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 53/287 [02:48<12:19,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "13568\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▉        | 54/287 [02:51<12:16,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "13824\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▉        | 55/287 [02:54<12:12,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "14080\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|█▉        | 56/287 [02:57<12:10,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "14336\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|█▉        | 57/287 [03:00<12:07,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "14592\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 58/287 [03:04<12:04,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "14848\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██        | 59/287 [03:07<12:00,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "15104\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██        | 60/287 [03:10<11:57,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "15360\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██▏       | 61/287 [03:13<11:54,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "15616\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 62/287 [03:16<11:51,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "15872\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 63/287 [03:19<11:48,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "16128\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 64/287 [03:23<11:45,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "16384\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 65/287 [03:26<11:42,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "16640\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 66/287 [03:29<11:38,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "16896\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 67/287 [03:32<11:35,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "17152\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▎       | 68/287 [03:35<11:31,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "17408\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 69/287 [03:38<11:28,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "17664\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 70/287 [03:41<11:25,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "17920\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▍       | 71/287 [03:45<11:21,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "18176\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 72/287 [03:48<11:19,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "18432\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 73/287 [03:51<11:15,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "18688\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 74/287 [03:54<11:12,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "18944\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 75/287 [03:57<11:09,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "19200\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▋       | 76/287 [04:00<11:06,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "19456\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 77/287 [04:04<11:03,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "19712\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 78/287 [04:07<10:59,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "19968\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 79/287 [04:10<10:57,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "20224\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 80/287 [04:13<10:54,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "20480\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 81/287 [04:16<10:51,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "20736\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▊       | 82/287 [04:19<10:47,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "20992\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▉       | 83/287 [04:23<10:44,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "21248\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▉       | 84/287 [04:26<10:41,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "21504\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|██▉       | 85/287 [04:29<10:38,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "21760\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|██▉       | 86/287 [04:32<10:35,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "22016\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 87/287 [04:35<10:31,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "22272\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███       | 88/287 [04:38<10:28,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "22528\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███       | 89/287 [04:41<10:25,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "22784\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███▏      | 90/287 [04:45<10:22,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "23040\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 91/287 [04:48<10:19,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "23296\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 92/287 [04:51<10:15,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "23552\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 93/287 [04:54<10:13,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "23808\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 94/287 [04:57<10:09,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "24064\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 95/287 [05:00<10:06,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "24320\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 96/287 [05:04<10:03,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "24576\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 97/287 [05:07<10:00,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "24832\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 98/287 [05:10<09:57,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "25088\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 99/287 [05:13<09:54,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "25344\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▍      | 100/287 [05:16<09:50,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "25600\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 101/287 [05:19<09:47,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "25856\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 102/287 [05:23<09:45,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "26112\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 103/287 [05:26<09:41,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "26368\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 104/287 [05:29<09:38,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "26624\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 105/287 [05:32<09:34,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "26880\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 106/287 [05:35<09:31,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "27136\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 107/287 [05:38<09:28,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "27392\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 108/287 [05:42<09:25,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "27648\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 109/287 [05:45<09:21,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "27904\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 110/287 [05:48<09:19,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "28160\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 39%|███▊      | 111/287 [05:51<09:15,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "28416\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 39%|███▉      | 112/287 [05:54<09:13,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "28672\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 39%|███▉      | 113/287 [05:57<09:10,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "28928\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|███▉      | 114/287 [06:00<09:06,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "29184\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 115/287 [06:04<09:03,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "29440\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 116/287 [06:07<09:00,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "29696\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████      | 117/287 [06:10<08:57,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "29952\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████      | 118/287 [06:13<08:54,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "30208\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████▏     | 119/287 [06:16<08:50,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "30464\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 120/287 [06:19<08:48,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "30720\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 121/287 [06:23<08:44,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "30976\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 122/287 [06:26<08:41,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "31232\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 123/287 [06:29<08:38,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "31488\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 124/287 [06:32<08:34,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "31744\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▎     | 125/287 [06:35<08:31,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "32000\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 126/287 [06:38<08:28,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "32256\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 127/287 [06:42<08:25,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "32512\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▍     | 128/287 [06:45<08:22,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "32768\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▍     | 129/287 [06:48<08:19,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "33024\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▌     | 130/287 [06:51<08:15,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "33280\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 131/287 [06:54<08:13,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "33536\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 132/287 [06:57<08:09,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "33792\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▋     | 133/287 [07:01<08:06,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "34048\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 134/287 [07:04<08:03,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "34304\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 135/287 [07:07<08:00,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "34560\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 136/287 [07:10<07:57,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "34816\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 137/287 [07:13<07:53,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "35072\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 138/287 [07:16<07:50,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "35328\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 139/287 [07:19<07:47,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "35584\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▉     | 140/287 [07:23<07:44,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "35840\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▉     | 141/287 [07:26<07:40,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "36096\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▉     | 142/287 [07:29<07:37,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "36352\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|████▉     | 143/287 [07:32<07:34,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "36608\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 144/287 [07:35<07:31,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "36864\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████     | 145/287 [07:38<07:28,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "37120\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████     | 146/287 [07:42<07:25,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "37376\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████     | 147/287 [07:45<07:22,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "37632\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 148/287 [07:48<07:18,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "37888\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 149/287 [07:51<07:15,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "38144\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 150/287 [07:54<07:12,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "38400\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 151/287 [07:57<07:10,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "38656\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 152/287 [08:01<07:06,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "38912\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 153/287 [08:04<07:03,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "39168\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▎    | 154/287 [08:07<07:00,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "39424\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 155/287 [08:10<06:57,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "39680\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 156/287 [08:13<06:53,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "39936\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▍    | 157/287 [08:16<06:51,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "40192\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▌    | 158/287 [08:20<06:48,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "40448\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▌    | 159/287 [08:23<06:44,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "40704\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 160/287 [08:26<06:41,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "40960\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 161/287 [08:29<06:38,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "41216\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▋    | 162/287 [08:32<06:34,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "41472\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 163/287 [08:35<06:32,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "41728\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 164/287 [08:38<06:28,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "41984\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 165/287 [08:42<06:25,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "42240\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 166/287 [08:45<06:22,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "42496\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 167/287 [08:48<06:19,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "42752\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▊    | 168/287 [08:51<06:16,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "43008\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▉    | 169/287 [08:54<06:12,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "43264\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▉    | 170/287 [08:57<06:09,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "43520\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|█████▉    | 171/287 [09:01<06:06,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "43776\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|█████▉    | 172/287 [09:04<06:03,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "44032\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 173/287 [09:07<06:00,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "44288\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 61%|██████    | 174/287 [09:10<05:56,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "44544\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 61%|██████    | 175/287 [09:13<05:53,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "44800\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 61%|██████▏   | 176/287 [09:16<05:50,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "45056\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 177/287 [09:20<05:47,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "45312\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 178/287 [09:23<05:44,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "45568\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 179/287 [09:26<05:41,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "45824\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 180/287 [09:29<05:38,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "46080\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 181/287 [09:32<05:35,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "46336\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 182/287 [09:35<05:32,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "46592\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 183/287 [09:39<05:28,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "46848\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 184/287 [09:42<05:25,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "47104\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 185/287 [09:45<05:22,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "47360\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▍   | 186/287 [09:48<05:19,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "47616\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 187/287 [09:51<05:16,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "47872\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 188/287 [09:54<05:13,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "48128\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 189/287 [09:58<05:09,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "48384\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 190/287 [10:01<05:06,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "48640\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 191/287 [10:04<05:03,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "48896\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 192/287 [10:07<05:00,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "49152\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 193/287 [10:10<04:57,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "49408\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 194/287 [10:13<04:54,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "49664\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 195/287 [10:16<04:51,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "49920\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 196/287 [10:20<04:47,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "50176\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▊   | 197/287 [10:23<04:44,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "50432\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▉   | 198/287 [10:26<04:41,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "50688\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▉   | 199/287 [10:29<04:38,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "50944\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|██████▉   | 200/287 [10:32<04:35,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "51200\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 201/287 [10:35<04:32,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "51456\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 202/287 [10:39<04:28,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "51712\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████   | 203/287 [10:42<04:25,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "51968\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████   | 204/287 [10:45<04:22,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "52224\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████▏  | 205/287 [10:48<04:19,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "52480\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 206/287 [10:51<04:16,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "52736\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 207/287 [10:54<04:13,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "52992\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 208/287 [10:58<04:10,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "53248\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 209/287 [11:01<04:06,  3.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "53504\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 210/287 [11:04<04:03,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "53760\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▎  | 211/287 [11:07<04:00,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "54016\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 212/287 [11:10<03:57,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "54272\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 213/287 [11:13<03:53,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "54528\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▍  | 214/287 [11:17<03:51,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "54784\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▍  | 215/287 [11:20<03:47,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "55040\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 216/287 [11:23<03:44,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "55296\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 217/287 [11:26<03:41,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "55552\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 218/287 [11:29<03:38,  3.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "55808\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▋  | 219/287 [11:32<03:35,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "56064\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 220/287 [11:36<03:31,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "56320\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 221/287 [11:39<03:28,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "56576\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 222/287 [11:42<03:25,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "56832\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 223/287 [11:45<03:22,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "57088\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 224/287 [11:48<03:19,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "57344\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 225/287 [11:51<03:15,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "57600\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▊  | 226/287 [11:55<03:12,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "57856\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▉  | 227/287 [11:58<03:09,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "58112\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▉  | 228/287 [12:01<03:06,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "58368\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|███████▉  | 229/287 [12:04<03:03,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "58624\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 230/287 [12:07<03:00,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "58880\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 231/287 [12:10<02:57,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "59136\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|████████  | 232/287 [12:14<02:54,  3.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "59392\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|████████  | 233/287 [12:17<02:50,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "59648\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 234/287 [12:20<02:47,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "59904\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 235/287 [12:23<02:44,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "60160\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 236/287 [12:26<02:41,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "60416\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 237/287 [12:29<02:38,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "60672\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 238/287 [12:32<02:34,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "60928\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 239/287 [12:36<02:31,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "61184\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▎ | 240/287 [12:39<02:28,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "61440\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 241/287 [12:42<02:25,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "61696\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 242/287 [12:45<02:22,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "61952\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▍ | 243/287 [12:48<02:19,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "62208\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 244/287 [12:51<02:15,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "62464\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 245/287 [12:55<02:12,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "62720\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 246/287 [12:58<02:09,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "62976\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 247/287 [13:01<02:06,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "63232\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▋ | 248/287 [13:04<02:03,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "63488\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 249/287 [13:07<02:00,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "63744\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 250/287 [13:10<01:56,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "64000\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 251/287 [13:14<01:53,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "64256\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 252/287 [13:17<01:50,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "64512\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 253/287 [13:20<01:47,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "64768\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▊ | 254/287 [13:23<01:44,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "65024\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▉ | 255/287 [13:26<01:41,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "65280\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▉ | 256/287 [13:29<01:38,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "65536\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|████████▉ | 257/287 [13:33<01:34,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "65792\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|████████▉ | 258/287 [13:36<01:31,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "66048\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 259/287 [13:39<01:28,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "66304\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████ | 260/287 [13:42<01:25,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "66560\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████ | 261/287 [13:45<01:22,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "66816\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████▏| 262/287 [13:48<01:18,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "67072\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 263/287 [13:51<01:15,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "67328\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 264/287 [13:55<01:12,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "67584\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 265/287 [13:58<01:09,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "67840\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 266/287 [14:01<01:06,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "68096\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 267/287 [14:04<01:03,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "68352\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 268/287 [14:07<01:00,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "68608\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▎| 269/287 [14:10<00:56,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "68864\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 270/287 [14:14<00:53,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "69120\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 271/287 [14:17<00:50,  3.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "69376\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▍| 272/287 [14:20<00:47,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "69632\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 273/287 [14:23<00:44,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "69888\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 274/287 [14:26<00:41,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "70144\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 275/287 [14:29<00:37,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "70400\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 276/287 [14:33<00:34,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "70656\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 277/287 [14:36<00:31,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "70912\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 278/287 [14:39<00:28,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "71168\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 279/287 [14:42<00:25,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "71424\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 280/287 [14:45<00:22,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "71680\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 281/287 [14:48<00:18,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "71936\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 282/287 [14:52<00:15,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "72192\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▊| 283/287 [14:55<00:12,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "72448\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▉| 284/287 [14:58<00:09,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "72704\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▉| 285/287 [15:01<00:06,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "72960\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r100%|█████████▉| 286/287 [15:04<00:03,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "73216\n",
            "in torch.Size([41, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 287/287 [15:05<00:00,  3.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([41, 512])\n",
            "73257\n",
            "Saving to /content/drive/MyDrive/pth files/svhn10-2-train.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://ufldl.stanford.edu/housenumbers/test_32x32.mat to ./pytorch_data/test_32x32.mat\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/64275384 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "87af4ba23efb4ec1ac5d453fad24ead6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/102 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 1/102 [00:03<05:57,  3.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "256\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 2/102 [00:06<05:31,  3.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "512\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 3/102 [00:09<05:21,  3.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "768\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 4/102 [00:13<05:15,  3.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "1024\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▍         | 5/102 [00:16<05:10,  3.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "1280\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 6/102 [00:19<05:06,  3.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "1536\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 7/102 [00:22<05:02,  3.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "1792\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 8/102 [00:25<04:58,  3.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "2048\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 9/102 [00:28<04:55,  3.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "2304\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|▉         | 10/102 [00:32<04:51,  3.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "2560\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 11/102 [00:35<04:48,  3.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "2816\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 12/102 [00:38<04:45,  3.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "3072\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 13/102 [00:41<04:41,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "3328\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▎        | 14/102 [00:44<04:38,  3.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "3584\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▍        | 15/102 [00:47<04:35,  3.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "3840\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 16/102 [00:51<04:32,  3.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "4096\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 17/102 [00:54<04:29,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "4352\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 18/102 [00:57<04:25,  3.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "4608\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▊        | 19/102 [01:00<04:22,  3.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "4864\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|█▉        | 20/102 [01:03<04:19,  3.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "5120\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██        | 21/102 [01:06<04:16,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "5376\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 22/102 [01:09<04:12,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "5632\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 23/102 [01:13<04:09,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "5888\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▎       | 24/102 [01:16<04:06,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "6144\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▍       | 25/102 [01:19<04:03,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "6400\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 26/102 [01:22<04:00,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "6656\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▋       | 27/102 [01:25<03:57,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "6912\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 28/102 [01:28<03:53,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "7168\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 29/102 [01:32<03:50,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "7424\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▉       | 30/102 [01:35<03:47,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "7680\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 31/102 [01:38<03:44,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "7936\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███▏      | 32/102 [01:41<03:41,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "8192\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 33/102 [01:44<03:38,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "8448\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 34/102 [01:47<03:35,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "8704\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 35/102 [01:51<03:32,  3.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "8960\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 36/102 [01:54<03:28,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "9216\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▋      | 37/102 [01:57<03:25,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "9472\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 38/102 [02:00<03:22,  3.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "9728\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 39/102 [02:03<03:19,  3.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "9984\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 39%|███▉      | 40/102 [02:06<03:16,  3.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "10240\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 41/102 [02:10<03:12,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "10496\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████      | 42/102 [02:13<03:09,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "10752\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 43/102 [02:16<03:06,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "11008\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 44/102 [02:19<03:03,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "11264\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 45/102 [02:22<03:00,  3.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "11520\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▌     | 46/102 [02:25<02:57,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "11776\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 47/102 [02:29<02:54,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "12032\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 48/102 [02:32<02:50,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "12288\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 49/102 [02:35<02:47,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "12544\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▉     | 50/102 [02:38<02:44,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "12800\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 51/102 [02:41<02:41,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "13056\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████     | 52/102 [02:44<02:38,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "13312\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 53/102 [02:48<02:34,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "13568\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 54/102 [02:51<02:31,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "13824\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 55/102 [02:54<02:28,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "14080\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▍    | 56/102 [02:57<02:25,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "14336\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 57/102 [03:00<02:22,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "14592\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 58/102 [03:03<02:19,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "14848\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 59/102 [03:07<02:15,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "15104\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▉    | 60/102 [03:10<02:12,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "15360\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|█████▉    | 61/102 [03:13<02:09,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "15616\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 61%|██████    | 62/102 [03:16<02:06,  3.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "15872\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 63/102 [03:19<02:03,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "16128\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 64/102 [03:22<02:00,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "16384\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▎   | 65/102 [03:25<01:56,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "16640\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▍   | 66/102 [03:29<01:53,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "16896\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 67/102 [03:32<01:50,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "17152\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 68/102 [03:35<01:47,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "17408\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 69/102 [03:38<01:44,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "17664\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▊   | 70/102 [03:41<01:41,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "17920\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|██████▉   | 71/102 [03:44<01:37,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "18176\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████   | 72/102 [03:48<01:34,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "18432\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 73/102 [03:51<01:31,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "18688\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 74/102 [03:54<01:28,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "18944\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▎  | 75/102 [03:57<01:25,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "19200\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▍  | 76/102 [04:00<01:22,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "19456\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 77/102 [04:03<01:18,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "19712\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▋  | 78/102 [04:07<01:15,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "19968\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 79/102 [04:10<01:12,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "20224\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 80/102 [04:13<01:09,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "20480\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▉  | 81/102 [04:16<01:06,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "20736\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 82/102 [04:19<01:03,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "20992\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|████████▏ | 83/102 [04:22<01:00,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "21248\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 84/102 [04:26<00:56,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "21504\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 85/102 [04:29<00:53,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "21760\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 86/102 [04:32<00:50,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "22016\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 87/102 [04:35<00:47,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "22272\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▋ | 88/102 [04:38<00:44,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "22528\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 89/102 [04:41<00:41,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "22784\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 90/102 [04:45<00:37,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "23040\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▉ | 91/102 [04:48<00:34,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "23296\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 92/102 [04:51<00:31,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "23552\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████ | 93/102 [04:54<00:28,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "23808\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 94/102 [04:57<00:25,  3.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "24064\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 95/102 [05:00<00:22,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "24320\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 96/102 [05:03<00:18,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "24576\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 97/102 [05:07<00:15,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "24832\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 98/102 [05:10<00:12,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "25088\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 99/102 [05:13<00:09,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "25344\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 100/102 [05:16<00:06,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "25600\n",
            "in torch.Size([256, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▉| 101/102 [05:19<00:03,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([256, 512])\n",
            "25856\n",
            "in torch.Size([176, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 102/102 [05:22<00:00,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out torch.Size([176, 512])\n",
            "26032\n",
            "Saving to /content/drive/MyDrive/pth files/svhn10-2-test.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "extract(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zf9qUAC_umYa"
      },
      "source": [
        "LL_DT.Runner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xM1y_YgL4bc2",
        "outputId": "c07b0edf-6a61-4682-b8fa-3910297706c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting river\n",
            "  Downloading river-0.10.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from river) (1.3.5)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from river) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.7/dist-packages (from river) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->river) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->river) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.0.1->river) (1.15.0)\n",
            "Installing collected packages: river\n",
            "Successfully installed river-0.10.1\n"
          ]
        }
      ],
      "source": [
        "pip install river"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COnc92ZE4bad",
        "outputId": "35d39726-afcd-4b56-8cf9-eea177ab31c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ray\n",
            "  Downloading ray-1.12.0-cp37-cp37m-manylinux2014_x86_64.whl (53.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 53.2 MB 256 kB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray) (3.6.0)\n",
            "Collecting grpcio<=1.43.0,>=1.28.1\n",
            "  Downloading grpcio-1.43.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1 MB 6.3 MB/s \n",
            "\u001b[?25hCollecting aiosignal\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray) (1.0.3)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray) (4.3.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ray) (2.23.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from ray) (21.4.0)\n",
            "Collecting virtualenv\n",
            "  Downloading virtualenv-20.14.1-py2.py3-none-any.whl (8.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8 MB 34.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray) (3.13)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray) (7.1.2)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from ray) (1.21.6)\n",
            "Requirement already satisfied: protobuf>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray) (3.17.3)\n",
            "Collecting frozenlist\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 18.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio<=1.43.0,>=1.28.1->ray) (1.15.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray) (5.7.1)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray) (0.18.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray) (4.2.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray) (4.11.3)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema->ray) (3.8.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (2021.10.8)\n",
            "Collecting distlib<1,>=0.3.1\n",
            "  Downloading distlib-0.3.4-py2.py3-none-any.whl (461 kB)\n",
            "\u001b[K     |████████████████████████████████| 461 kB 10.9 MB/s \n",
            "\u001b[?25hCollecting platformdirs<3,>=2\n",
            "  Downloading platformdirs-2.5.2-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: platformdirs, frozenlist, distlib, virtualenv, grpcio, aiosignal, ray\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.44.0\n",
            "    Uninstalling grpcio-1.44.0:\n",
            "      Successfully uninstalled grpcio-1.44.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\u001b[0m\n",
            "Successfully installed aiosignal-1.2.0 distlib-0.3.4 frozenlist-1.3.0 grpcio-1.43.0 platformdirs-2.5.2 ray-1.12.0 virtualenv-20.14.1\n"
          ]
        }
      ],
      "source": [
        "pip install ray"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "NdYORYwE868M"
      },
      "outputs": [],
      "source": [
        "#from utils.calc_utils import CalculationsUtils. This is the CalculationsUtils class     \n",
        "\n",
        "import math\n",
        "\n",
        "import torch\n",
        "# from torch.tensor import Tensor\n",
        "from torch import Tensor\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class CalculationsUtils:\n",
        "\n",
        "    @staticmethod\n",
        "    def div(a: float, b: float):\n",
        "        return a / b if b else 0.0\n",
        "\n",
        "    @staticmethod\n",
        "    def div_tensor(t: Tensor, d: float):\n",
        "        return t / d if d else torch.zeros(len(t))\n",
        "\n",
        "    @staticmethod\n",
        "    def normalize(t: Tensor):\n",
        "        s = t.sum()\n",
        "        return t / s if s > 0.0 else t\n",
        "\n",
        "    @staticmethod\n",
        "    def sum_arrays(arrays):\n",
        "        out = []\n",
        "        active = set(range(len(arrays)))\n",
        "\n",
        "        i = 0\n",
        "        while active:\n",
        "            out.append(0.0)\n",
        "            to_remove = set()\n",
        "\n",
        "            for a_idx in active:\n",
        "                if i > len(arrays[a_idx]) - 1:\n",
        "                    to_remove.add(a_idx)\n",
        "                else:\n",
        "                    out[-1] += arrays[a_idx][i]\n",
        "\n",
        "            active -= to_remove\n",
        "            i += 1\n",
        "\n",
        "        return np.array(out[:-1])\n",
        "\n",
        "    @staticmethod\n",
        "    def log(x):\n",
        "        if x > 0.0: return math.log(x)\n",
        "        return float('-inf') if x == 0.0 else float('NaN')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "WZE26Qk68_u0"
      },
      "outputs": [],
      "source": [
        "#from utils.coll_utils import CollectionUtils  This is the 'CollectionUtils' class\n",
        "\n",
        "import itertools\n",
        "from functools import reduce\n",
        "from typing import Callable\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class CollectionUtils:\n",
        "\n",
        "    @staticmethod\n",
        "    def ensure_arr_size(arr: np.ndarray, y: int):\n",
        "        if len(arr.shape) == 1:\n",
        "            return np.hstack((arr, np.zeros(y - len(arr) + 1))) if len(arr) - 1 < y else arr\n",
        "        else:\n",
        "            return np.hstack((arr, np.zeros((arr.shape[0], y - arr.shape[1] + 1, arr.shape[2])))) if arr.shape[1] - 1 < y else arr\n",
        "\n",
        "    @staticmethod\n",
        "    def ensure_list2d_size(lst: list, y: int, element_creator: Callable[[], any]):\n",
        "        if len(lst[0]) > y:\n",
        "            return lst\n",
        "\n",
        "        for l in lst:\n",
        "            l_len = len(l) - 1\n",
        "            for _ in range(y - l_len):\n",
        "                l.append(element_creator())\n",
        "\n",
        "        return lst\n",
        "\n",
        "    @staticmethod\n",
        "    def split_list(lst, chunk_size: int):\n",
        "        return [lst[i:i + chunk_size] for i in range(0, len(lst), chunk_size)]\n",
        "\n",
        "    @staticmethod\n",
        "    def flatten_list(lst):\n",
        "        return list(itertools.chain.from_iterable(lst))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "El-2pNvt9KgB"
      },
      "source": [
        "Hoeffding Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "x0C5_F_h9H02"
      },
      "outputs": [],
      "source": [
        "# From core.clean import ContinualLearner this is the ContinualLearner class\n",
        "\n",
        "from abc import ABC, abstractmethod\n",
        "\n",
        "\n",
        "class ContinualLearner(ABC):\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def initialize(self, x_batch, y_batch, **kwargs):\n",
        "        self.update(x_batch, y_batch, **kwargs)\n",
        "\n",
        "    @abstractmethod\n",
        "    def predict(self, x_batch):\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def predict_prob(self, x_batch):\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def update(self, x_batch, y_batch, **kwargs):\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "3RpJ-lKE9Per"
      },
      "outputs": [],
      "source": [
        "# from utils.stat_utils import Statistics, GaussianEstimator  Here is the Statistics and GaussianEstimator classes\n",
        "\n",
        "\n",
        "from abc import ABC, abstractmethod\n",
        "from typing import Callable\n",
        "import math\n",
        "import numpy as np\n",
        "from scipy.stats import entropy\n",
        "import copy\n",
        "\n",
        "# from utils.calc_utils import CalculationsUtils as cu\n",
        "# from utils.coll_utils import CollectionUtils as clu\n",
        "\n",
        "SQ2 = math.sqrt(2.0)\n",
        "NC = math.sqrt(2.0 * math.pi)\n",
        "\n",
        "\n",
        "class ValueEstimator(ABC):\n",
        "\n",
        "    @abstractmethod\n",
        "    def update(self, v: float, w: float):\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def get_count(self):\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def get_mean(self):\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def get_var(self):\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def get_std(self):\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def copy(self):\n",
        "        pass\n",
        "\n",
        "\n",
        "class ForgettingEstimator(ValueEstimator):\n",
        "    def __init__(self, decay: float, count: float=0.0, linear_sum: float=0.0, squared_sum: float=0.0, timestamp: int=0):\n",
        "        self.decay = decay\n",
        "        self.count = count\n",
        "        self.linear_sum = linear_sum\n",
        "        self.squared_sum = squared_sum\n",
        "        self.timestamp = timestamp\n",
        "\n",
        "    def update(self, v: float, t: int):\n",
        "        d = self.decay ** (t - self.timestamp)\n",
        "        self.count = d * self.count + 1\n",
        "        self.linear_sum = d * self.linear_sum + v\n",
        "        self.squared_sum = d * self.squared_sum + v**2\n",
        "\n",
        "        self.timestamp = t\n",
        "\n",
        "    def get_count(self):\n",
        "        return self.count\n",
        "\n",
        "    def get_mean(self):\n",
        "        if self.count == 0.0:\n",
        "            return float('NaN')\n",
        "        print(self.linear_sum, self.count)\n",
        "        return self.linear_sum / self.count\n",
        "\n",
        "    def get_var(self):\n",
        "        if self.count == 0.0:\n",
        "            return float('NaN')\n",
        "        return max(self.squared_sum / self.count - (self.linear_sum / self.count) ** 2, 0.0)\n",
        "\n",
        "    def get_std(self):\n",
        "        if self.count == 0.0:\n",
        "            return float('NaN')\n",
        "        return math.sqrt(self.get_var())\n",
        "\n",
        "    def copy(self):\n",
        "        return ForgettingEstimator(self.decay, self.count, self.linear_sum, self.squared_sum, self.timestamp)\n",
        "\n",
        "\n",
        "class DistributionEstimator(ValueEstimator):\n",
        "\n",
        "    @abstractmethod\n",
        "    def get_cdf(self, x: float):\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def get_pdf(self, x: float):\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def split(self, **kwargs):\n",
        "        pass\n",
        "\n",
        "\n",
        "class GaussianEstimator(DistributionEstimator):\n",
        "    def __init__(self, count: float=0.0, mean: float=0.0, var: float=0.0, std: float=0.0):\n",
        "        self.count = count\n",
        "        self.mean = mean\n",
        "        self.var = var\n",
        "        self.std = std\n",
        "\n",
        "    def update(self, v: float, w: float):\n",
        "        pm = self.mean\n",
        "        self.count += w\n",
        "        self.mean = pm + (w / self.count) * (v - pm)\n",
        "        self.var = self.var + w * (v - pm) * (v - self.mean)\n",
        "        self.std = math.sqrt(self.var / self.count)\n",
        "\n",
        "    def get_count(self):\n",
        "        return self.count\n",
        "\n",
        "    def get_mean(self):\n",
        "        return self.mean\n",
        "\n",
        "    def get_var(self):\n",
        "        return self.var\n",
        "\n",
        "    def get_std(self):\n",
        "        return self.std\n",
        "\n",
        "    def get_cdf(self, x: float):\n",
        "        z = (x - self.mean) / self.std\n",
        "        return (1.0 + math.erf(z / SQ2)) / 2.0\n",
        "\n",
        "    def get_pdf(self, x: float):\n",
        "        if self.std == 0:\n",
        "            return 1.0 if x == self.mean else 0.0\n",
        "\n",
        "        z = (x - self.mean) / self.std\n",
        "        return math.exp(-0.5 * z * z) / (NC * self.std)\n",
        "\n",
        "    def split(self, **kwargs):\n",
        "        return GaussianEstimator(self.count, self.mean, self.var, self.std), \\\n",
        "               GaussianEstimator(self.count, self.mean, self.var, self.std)\n",
        "\n",
        "    def copy(self):\n",
        "        return GaussianEstimator(self.count, self.mean, self.var, self.std)\n",
        "\n",
        "\n",
        "class Statistics:\n",
        "    def __init__(self, atts: list, num_cls: int, estimator_creator: Callable[[], DistributionEstimator], att_split_est=False,\n",
        "                 cls_counts=None, att_stats=None, att_extr_stats=None):\n",
        "        self.atts = atts\n",
        "        self.att_map = {att_idx: i for i, att_idx in enumerate(self.atts)}\n",
        "        self.num_cls = num_cls\n",
        "        self.estimator_creator = estimator_creator\n",
        "        self.att_split_est = att_split_est\n",
        "\n",
        "        self.att_stats = att_stats if att_stats is not None else [[self.estimator_creator() for _ in range(num_cls)] for _ in range(len(self.atts))]\n",
        "        self.att_extr_stats = att_extr_stats if att_extr_stats is not None else np.array([[float('inf'), float('-inf')] for _ in range(len(self.atts))])\n",
        "        self.cls_counts = cls_counts if cls_counts is not None else np.zeros(num_cls)\n",
        "        self.all_count = self.cls_counts.sum()\n",
        "\n",
        "    def update(self, x, y: int, w: float):\n",
        "        self.cls_counts = CollectionUtils.ensure_arr_size(self.cls_counts, y)\n",
        "        self.att_stats = CollectionUtils.ensure_list2d_size(self.att_stats, y, self.estimator_creator)\n",
        "        self.num_cls = max(self.num_cls, y + 1)\n",
        "\n",
        "        self.all_count += w\n",
        "        self.cls_counts[y] += w\n",
        "\n",
        "        for i, att_idx in enumerate(self.atts):\n",
        "            self.att_stats[i][y].update(x[att_idx], w)\n",
        "            self.att_extr_stats[i][0] = min(self.att_extr_stats[i][0], x[att_idx])\n",
        "            self.att_extr_stats[i][1] = max(self.att_extr_stats[i][1], x[att_idx])\n",
        "\n",
        "    def get_estimator(self, att_idx: int, cls_idx: int):\n",
        "        return self.att_stats[self.att_map[att_idx]][cls_idx]\n",
        "\n",
        "    def get_cls_count(self, cls_idx: int=-1):\n",
        "        return self.all_count if cls_idx < 0 else self.cls_counts[cls_idx]\n",
        "\n",
        "    def get_att_extr(self, att_idx: int):\n",
        "        return self.att_extr_stats[self.att_map[att_idx]]\n",
        "\n",
        "    def get_stats(self):\n",
        "        return self.cls_counts, self.att_stats, self.att_extr_stats\n",
        "\n",
        "    def split(self, split_att_idx: int, s: float, l_prob, r_prob):\n",
        "        l_cls_counts, r_cls_counts = self.all_count * l_prob, self.all_count * r_prob\n",
        "        l_att_stats, r_att_stats = None, None\n",
        "        l_att_extr, r_att_extr = None, None\n",
        "\n",
        "        if self.att_split_est:\n",
        "            l_att_stats, r_att_stats = [], []\n",
        "            for i, att_idx in enumerate(self.atts):\n",
        "                lstats, rstats = [], []\n",
        "\n",
        "                for cls_idx in range(self.num_cls):\n",
        "                    lest, rest = self.get_estimator(i, cls_idx).split(lc=l_cls_counts[cls_idx], rc=r_cls_counts[cls_idx])\n",
        "                    lstats.append(lest)\n",
        "                    rstats.append(rest)\n",
        "\n",
        "                l_att_stats.append(lstats)\n",
        "                r_att_stats.append(rstats)\n",
        "\n",
        "            l_att_extr, r_att_extr = copy.deepcopy(self.att_extr_stats), copy.deepcopy(self.att_extr_stats)\n",
        "            l_att_extr[split_att_idx][1] = s\n",
        "            r_att_extr[split_att_idx][0] = s\n",
        "\n",
        "        return Statistics(self.atts, self.num_cls, self.estimator_creator, self.att_split_est, l_cls_counts, l_att_stats, l_att_extr), \\\n",
        "               Statistics(self.atts, self.num_cls, self.estimator_creator, self.att_split_est, r_cls_counts, r_att_stats, r_att_extr)\n",
        "\n",
        "    @staticmethod\n",
        "    def calc_split_weighted_entropy(stats, att_idx: int, s: float, num_cls: int):\n",
        "        l_prob, r_prob = np.zeros(num_cls), np.zeros(num_cls)\n",
        "        lp_sum, rp_sum = 0.0, 0.0\n",
        "\n",
        "        for cls_idx in range(num_cls):\n",
        "            est = stats.get_estimator(att_idx, cls_idx)\n",
        "\n",
        "            if est.get_count() == 0:\n",
        "                continue\n",
        "            elif est.get_var() == 0:\n",
        "                lp = 1.0 if s >= est.get_mean() else 0.0\n",
        "            else:\n",
        "                lp = est.get_cdf(s)\n",
        "\n",
        "            lp_sum += lp\n",
        "            rp = 1.0 - lp\n",
        "            rp_sum += rp\n",
        "\n",
        "            cp = stats.get_cls_count(cls_idx) / stats.get_cls_count()\n",
        "            l_prob[cls_idx] = lp * cp\n",
        "            r_prob[cls_idx] = rp * cp\n",
        "\n",
        "        wl, wr = l_prob.sum(), r_prob.sum()\n",
        "        l_ent = entropy(CalculationsUtils.div_tensor(l_prob, lp_sum)) if wl > 0.0 else 0.0\n",
        "        r_ent = entropy(CalculationsUtils.div_tensor(r_prob, rp_sum)) if wr > 0.0 else 0.0\n",
        "        ent = wl * l_ent + wr * r_ent\n",
        "\n",
        "        return ent, l_prob, r_prob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zd5e8lZx9Wx0",
        "outputId": "66616c91-a574-4a1a-8f27-c74faa5e52a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-multiflow\n",
            "  Downloading scikit_multiflow-0.5.3-cp37-cp37m-manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 22.2 MB/s eta 0:00:01\r\u001b[K     |▋                               | 20 kB 26.9 MB/s eta 0:00:01\r\u001b[K     |▉                               | 30 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 61 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██                              | 71 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 81 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 92 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |███                             | 102 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 112 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 122 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 133 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████                            | 143 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 153 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 163 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████                           | 174 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 184 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 194 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 204 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 215 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 225 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 235 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████                         | 245 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 256 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 266 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████                        | 276 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 286 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 296 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 307 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 317 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 327 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 337 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 348 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 358 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 368 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 378 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 389 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 399 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 409 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 419 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 430 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 440 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 450 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 460 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 471 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 481 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 491 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 501 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 512 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 522 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 532 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 542 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 552 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 563 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 573 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 583 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 593 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 604 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 614 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 624 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 634 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 645 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 655 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 665 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 675 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 686 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 696 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 706 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 716 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 727 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 737 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 747 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 757 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 768 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 778 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 788 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 798 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 808 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 819 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 829 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 839 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 849 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 860 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 870 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 880 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 890 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 901 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 911 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 921 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 931 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 942 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 952 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 962 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 972 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 983 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 993 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.0 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.0 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.0 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.0 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.0 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.1 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.1 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.1 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.1 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.1 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.1 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.1 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1 MB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from scikit-multiflow) (1.21.6)\n",
            "Requirement already satisfied: pandas>=0.25.3 in /usr/local/lib/python3.7/dist-packages (from scikit-multiflow) (1.3.5)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.7/dist-packages (from scikit-multiflow) (1.0.2)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-multiflow) (3.2.2)\n",
            "Requirement already satisfied: sortedcontainers>=1.5.7 in /usr/local/lib/python3.7/dist-packages (from scikit-multiflow) (2.4.0)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-multiflow) (1.4.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->scikit-multiflow) (3.0.8)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->scikit-multiflow) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->scikit-multiflow) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->scikit-multiflow) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=2.0.0->scikit-multiflow) (4.2.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.3->scikit-multiflow) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=2.0.0->scikit-multiflow) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20->scikit-multiflow) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20->scikit-multiflow) (1.1.0)\n",
            "Installing collected packages: scikit-multiflow\n",
            "Successfully installed scikit-multiflow-0.5.3\n"
          ]
        }
      ],
      "source": [
        "pip install scikit-multiflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "S5abbPjG9a9t"
      },
      "outputs": [],
      "source": [
        "#from utils.cls_utils import ClassificationUtils This is the 'ClassificationUtils' class\n",
        "\n",
        "import math\n",
        "\n",
        "from river.base import Classifier\n",
        "from skmultiflow.core import ClassifierMixin\n",
        "from torch import Tensor\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "# from core.clearn import ContinualLearner\n",
        "# from utils.calc_utils import CalculationsUtils\n",
        "# from utils.stat_utils import Statistics\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "class ClassificationUtils:\n",
        "\n",
        "    @staticmethod\n",
        "    def majority_class_prob(counts, all_count):\n",
        "        return np.zeros(len(counts)) if all_count == 0 else counts / all_count\n",
        "\n",
        "    @staticmethod\n",
        "    def naive_bayes_prob(x, stats: Statistics, use_prior=True):\n",
        "        probs = np.zeros(stats.num_cls, dtype=np.double)\n",
        "        if stats.get_cls_count() == 0: return probs\n",
        "        p = 0.0\n",
        "\n",
        "        for cls_idx in range(stats.num_cls):\n",
        "            prob = stats.get_cls_count(cls_idx) / stats.get_cls_count() if use_prior else 1.0\n",
        "\n",
        "            for att_idx in stats.atts:\n",
        "                pr = stats.get_estimator(att_idx, cls_idx).get_pdf(x[att_idx])\n",
        "                prob *= (pr if not np.isnan(pr) else 1.0)\n",
        "\n",
        "            p += prob\n",
        "            probs[cls_idx] = prob\n",
        "\n",
        "        return probs if p == 0.0 else probs / p\n",
        "\n",
        "    @staticmethod\n",
        "    def naive_bayes_log_prob(x, stats: Statistics, use_prior=True):\n",
        "        log_probs = np.zeros(stats.num_cls, dtype=np.double)\n",
        "        if stats.get_cls_count() == 0: return log_probs\n",
        "        lps, lp_max = [], float('-inf')\n",
        "\n",
        "        for cls_idx in range(stats.num_cls):\n",
        "            log_prob = CalculationsUtils.log(stats.get_cls_count(cls_idx) / stats.get_cls_count()) if use_prior else 0.0\n",
        "\n",
        "            for att_idx in stats.atts:\n",
        "                pr = stats.get_estimator(att_idx, cls_idx).get_pdf(x[att_idx])\n",
        "                log_prob += (CalculationsUtils.log(pr) if not np.isnan(pr) else 0.0)\n",
        "\n",
        "            lps.append(log_prob)\n",
        "            lp_max = max(lp_max, log_prob)\n",
        "            log_probs[cls_idx] = log_prob\n",
        "\n",
        "        # https://stats.stackexchange.com/questions/105602/example-of-how-the-log-sum-exp-trick-works-in-naive-bayes/253319#253319\n",
        "        lps_sum = 0.0\n",
        "        zero_prob_indices = []\n",
        "        for i, lp in enumerate(lps):\n",
        "            if lp != float('-inf'):\n",
        "                lps_sum += math.exp(lp - lp_max)\n",
        "            else:\n",
        "                zero_prob_indices.append(i)\n",
        "\n",
        "        if not (np.isfinite(lps_sum) and np.isfinite(lp_max)):\n",
        "            return np.zeros(stats.num_cls)\n",
        "\n",
        "        lps_sum = math.log(lps_sum)\n",
        "        lps_sum += lp_max\n",
        "\n",
        "        probs = np.exp(log_probs - lps_sum)\n",
        "        probs[zero_prob_indices] = 0.0\n",
        "\n",
        "        return probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "C74H3wfo9fta"
      },
      "outputs": [],
      "source": [
        "# ht.py Hoeffding Tree main code\n",
        "import math\n",
        "from scipy.stats import entropy\n",
        "import numpy as np\n",
        "\n",
        "# from core.clearn import ContinualLearner\n",
        "# from utils.cls_utils import ClassificationUtils as cu\n",
        "# from utils.stat_utils import Statistics, GaussianEstimator\n",
        "\n",
        "\n",
        "class HoeffdingTree(ContinualLearner):\n",
        "    def __init__(self, split_step=0.1, split_wait=100, hb_delta=0.01, tie_thresh=0.05, rnd=False, subspaces=False,\n",
        "                 att_split_est=False, log_prob=True, num_atts=0, num_cls=0):\n",
        "        super().__init__()\n",
        "        self.root = TreeNode(split_step, split_wait, hb_delta, tie_thresh, rnd, subspaces, None, None, att_split_est, log_prob,\n",
        "                             num_atts, num_cls)\n",
        "\n",
        "    def predict(self, x_batch):\n",
        "        return np.array([np.argmax(ya) for ya in self.predict_prob(x_batch)])\n",
        "\n",
        "    def predict_prob(self, x_batch):\n",
        "        return np.array([self.find_leaf(x).predict_prob(x) for x in x_batch], dtype=object)\n",
        "\n",
        "    def update(self, x_batch, y_batch, **kwargs):\n",
        "        weights = kwargs.get('weights', np.ones(len(y_batch)))\n",
        "        y_batch = y_batch.astype(int) if isinstance(y_batch, np.ndarray) else y_batch.int()\n",
        "\n",
        "        for x, y, w in zip(x_batch, y_batch, weights):\n",
        "            leaf = self.find_leaf(x)\n",
        "            leaf.update(x, y, w if w > 0.0 else 1.0)\n",
        "            leaf.attempt_split()\n",
        "\n",
        "    def find_leaf(self, x):\n",
        "        node = self.root\n",
        "        while not node.is_leaf:\n",
        "            att, thresh = node.split\n",
        "            node = node.left if x[att] <= thresh else node.right\n",
        "\n",
        "        return node\n",
        "\n",
        "\n",
        "class TreeNode:\n",
        "    def __init__(self, split_step=0.1, split_wait=100, hb_delta=0.01, tie_thresh=0.05, rnd=False, subspaces=False,\n",
        "                 split_atts=None, stats=None, att_split_est=False, log_prob=True, num_atts=0, num_cls=0):\n",
        "        self.is_leaf = True\n",
        "        self.left = None\n",
        "        self.right = None\n",
        "        self.split = (None, None)\n",
        "        self.split_step = split_step\n",
        "        self.split_wait = split_wait\n",
        "        self.last_split_try = 0.0\n",
        "        self.cnt = 0.0\n",
        "        self.hb_delta = hb_delta\n",
        "        self.tie_thresh = tie_thresh\n",
        "\n",
        "        self.mc_correct = 0.0\n",
        "        self.nb_correct = 0.0\n",
        "\n",
        "        self.rnd = rnd\n",
        "        self.subspaces = subspaces\n",
        "        self.split_atts = split_atts\n",
        "        self.att_split_est = att_split_est\n",
        "        self.log_prob = log_prob\n",
        "        self.nb_pred = ClassificationUtils.naive_bayes_log_prob if self.log_prob else ClassificationUtils.naive_bayes_prob\n",
        "\n",
        "        if num_atts > 0:\n",
        "            self.init(num_atts, num_cls, stats)\n",
        "        else:\n",
        "            self.num_atts = 0\n",
        "            self.num_cls = 0\n",
        "            self.split_atts = None\n",
        "            self.stat_atts = []\n",
        "            self.att_map = None\n",
        "            self.stats = None\n",
        "\n",
        "    def init(self, num_atts, num_cls, stats):\n",
        "        self.num_atts = num_atts\n",
        "        self.num_cls = num_cls\n",
        "\n",
        "        if self.rnd or (self.subspaces and self.split_atts is None):\n",
        "            self.split_atts = np.random.permutation(num_atts)[:int(math.sqrt(num_atts)) + 1]\n",
        "        elif not self.subspaces:\n",
        "            self.split_atts = np.arange(0, num_atts)\n",
        "\n",
        "        self.stat_atts = self.split_atts if not self.att_split_est else np.arange(0, num_atts)\n",
        "\n",
        "        if stats is not None:\n",
        "            s = stats.get_stats()\n",
        "            self.stats = Statistics(self.stat_atts, self.num_cls, GaussianEstimator, self.att_split_est, *s)\n",
        "        else:\n",
        "            self.stats = Statistics(self.stat_atts, self.num_cls, GaussianEstimator, self.att_split_est)\n",
        "\n",
        "    def update(self, x, y: int, w: float):\n",
        "        if not self.stats:\n",
        "            self.init(len(x), y + 1, None)\n",
        "\n",
        "        self.mc_correct += w * (np.argmax(self.stats.cls_counts) == y)\n",
        "        self.nb_correct += w * (np.argmax(self.nb_pred(x, self.stats)) == y)\n",
        "        self.cnt += w\n",
        "        self.stats.update(x, y, w)\n",
        "        self.num_cls = self.stats.num_cls\n",
        "\n",
        "    def predict_prob(self, x):\n",
        "        if not self.stats:\n",
        "            return np.zeros(1)\n",
        "        else:\n",
        "            maj_probs = ClassificationUtils.majority_class_prob(self.stats.cls_counts, self.stats.get_cls_count())\n",
        "            if self.mc_correct >= self.nb_correct:\n",
        "                return maj_probs\n",
        "\n",
        "            nb_probs = self.nb_pred(x, self.stats)\n",
        "            return nb_probs if np.any(nb_probs) else maj_probs\n",
        "\n",
        "    def attempt_split(self):\n",
        "        if self.cnt > 0 and self.cnt - self.last_split_try >= self.split_wait:\n",
        "            best_split = self.__find_best_att_split()\n",
        "            self.__try_best_split(best_split)\n",
        "\n",
        "    def __find_best_att_split(self):\n",
        "        best_split = (float('inf'), None, None, [], [])  # entropy, att idx, thresh val, left prob, right prob\n",
        "\n",
        "        for att_idx in self.split_atts:\n",
        "            mi, mx = np.around(self.stats.get_att_extr(att_idx), decimals=10)\n",
        "            step = (mx - mi) * self.split_step\n",
        "\n",
        "            s = mi + step\n",
        "            while s < mx:\n",
        "                ent, l_prob, r_prob = Statistics.calc_split_weighted_entropy(self.stats, att_idx, s, self.num_cls)\n",
        "                if ent < best_split[0]:\n",
        "                    best_split = [ent, att_idx, s, l_prob, r_prob]\n",
        "\n",
        "                s += step\n",
        "\n",
        "        return best_split\n",
        "\n",
        "    def __try_best_split(self, best_split):\n",
        "        if best_split[1] is None: return\n",
        "        n = self.stats.get_cls_count()\n",
        "        curr_entropy = entropy(self.stats.cls_counts / n)\n",
        "        hb = self.hb(math.log(self.num_cls), self.hb_delta, n)\n",
        "\n",
        "        if curr_entropy - best_split[0] > hb or hb < self.tie_thresh:\n",
        "            _, att_idx, thresh, l_prob, r_prob = best_split\n",
        "            self.split = (att_idx, thresh)\n",
        "\n",
        "            l_stats, r_stats = self.stats.split(att_idx, thresh, l_prob, r_prob)\n",
        "\n",
        "            self.left = TreeNode(self.split_step, self.split_wait, self.hb_delta, self.tie_thresh, self.rnd, self.subspaces,\n",
        "                                 self.split_atts, l_stats, self.att_split_est, self.log_prob, self.num_atts, self.num_cls)\n",
        "            self.right = TreeNode(self.split_step, self.split_wait, self.hb_delta, self.tie_thresh, self.rnd, self.subspaces,\n",
        "                                  self.split_atts, r_stats, self.att_split_est, self.log_prob, self.num_atts, self.num_cls)\n",
        "\n",
        "            self.is_leaf = False\n",
        "            self.stats = None\n",
        "\n",
        "        self.last_split_try = self.cnt\n",
        "\n",
        "    @staticmethod\n",
        "    def hb(r, delta, n):\n",
        "        return math.sqrt((r * r * math.log(1.0 / delta)) / (2.0 * n))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjpaBiOg9oZU"
      },
      "source": [
        "irf.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "3InvUrzs9maE"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import random\n",
        "from collections import Counter\n",
        "\n",
        "from skmultiflow.drift_detection import ADWIN\n",
        "import numpy as np\n",
        "import ray\n",
        "\n",
        "# from core.clearn import ContinualLearner\n",
        "# from learners.ht import HoeffdingTree\n",
        "# from utils.calc_utils import CalculationsUtils\n",
        "# from utils.coll_utils import CollectionUtils\n",
        "\n",
        "\n",
        "class IncrementalRandomForest(ContinualLearner):\n",
        "\n",
        "    def __init__(self, size: int, lambda_val=5.0, split_step=0.1, split_wait=100, hb_delta=0.01, tie_thresh=0.05,\n",
        "                 rnd=True, subspaces=False, att_split_est=False, log_prob=True, num_atts=0, num_cls=0, num_workers=1):\n",
        "        super().__init__()\n",
        "        self.size = size\n",
        "        self.lambda_val = lambda_val\n",
        "        self.tree_groups = []\n",
        "        self.num_par_groups = num_workers\n",
        "        self.par = self.num_par_groups > 1\n",
        "        self.init_tree_groups([0, split_step, split_wait, hb_delta, tie_thresh, rnd, subspaces, att_split_est, log_prob,\n",
        "                               num_atts, num_cls])\n",
        "\n",
        "    def init_tree_groups(self, tree_params: list):\n",
        "        trees_per_group, r = math.ceil(self.size / self.num_par_groups), self.size\n",
        "        while r > 0:\n",
        "            tree_params[0] = min(r, trees_per_group)\n",
        "            self.tree_groups.append(RemoteTreeGroupWrapper(*tree_params) if self.par else TreeGroup(*tree_params))\n",
        "            r -= trees_per_group\n",
        "\n",
        "    def predict(self, x_batch):\n",
        "        return np.array([np.argmax(ya) for ya in self.predict_prob(x_batch)])\n",
        "\n",
        "    def predict_prob(self, x_batch):\n",
        "        weights = self.fetch([tg.get_weights() for tg in self.tree_groups])\n",
        "        ws = sum([sum(w) for w in weights])\n",
        "\n",
        "        probs = self.fetch([tg.predict_prob(x_batch) for tg in self.tree_groups])\n",
        "        trees_batch_probs = CollectionUtils.flatten_list(probs)\n",
        "        probs_sum = [CalculationsUtils.sum_arrays([tree_probs[i] for tree_probs in trees_batch_probs]) for i in range(len(x_batch))]\n",
        "\n",
        "        return np.array(probs_sum, dtype=object) / ws\n",
        "\n",
        "    def update(self, x_batch, y_batch, **kwargs):\n",
        "        weights = kwargs.get('weights', np.ones(len(y_batch)))\n",
        "\n",
        "        for tree_group in self.tree_groups:\n",
        "            tree_group.update_trees(x_batch, y_batch, self.lambda_val, weights)\n",
        "\n",
        "    def get_tree_group(self, idx):\n",
        "        return self.tree_groups[idx].get_trees()\n",
        "\n",
        "    def fetch(self, obj):\n",
        "        return obj if not self.par else ray.get(obj)\n",
        "\n",
        "\n",
        "class TreeGroup:\n",
        "\n",
        "    def __init__(self, size: int, split_step=0.1, split_wait=100, hb_delta=0.01, tie_thresh=0.05, rnd=True, subspaces=False,\n",
        "                 att_split_est=False, log_prob=True, num_atts=0, num_cls=0):\n",
        "        self.trees = [\n",
        "            ForestHoeffdingTree(split_step, split_wait, hb_delta, tie_thresh, rnd, subspaces, att_split_est, log_prob, num_atts, num_cls)\n",
        "            for _ in range(size)\n",
        "        ]\n",
        "\n",
        "    def get_weights(self):\n",
        "        return [tree.get_weight() for tree in self.trees]\n",
        "\n",
        "    def predict_prob(self, x_batch):\n",
        "        return [tree.predict_prob(x_batch) for tree in self.trees]\n",
        "\n",
        "    def update_trees(self, x_batch, y_batch, lambda_val, weights):\n",
        "        for tree in self.trees:\n",
        "            k = np.random.poisson(lambda_val, len(x_batch))\n",
        "            tree.update(x_batch, y_batch, weights=np.multiply(weights, k))\n",
        "\n",
        "    def get_trees(self):\n",
        "        return self.trees\n",
        "\n",
        "\n",
        "class ForestHoeffdingTree(HoeffdingTree):\n",
        "\n",
        "    def __init__(self, split_step=0.1, split_wait=100, hb_delta=0.01, tie_thresh=0.05, rnd=True, subspaces=False, att_split_est=False,\n",
        "                 log_prob=True, num_atts=0, num_cls=0):\n",
        "        super().__init__(split_step, split_wait, hb_delta, tie_thresh, rnd, subspaces, att_split_est, log_prob, num_atts, num_cls)\n",
        "        self.quality = ADWIN()\n",
        "\n",
        "    def update(self, x_batch, y_batch, **kwargs):\n",
        "        preds = super().predict(x_batch)\n",
        "        for p, y in zip(preds, y_batch): self.quality.add_element(int(int(p) == int(y)))\n",
        "        super().update(x_batch, y_batch, **kwargs)\n",
        "\n",
        "    def predict_prob(self, x_batch):\n",
        "        return self.get_weight() * np.array([self.find_leaf(x).predict_prob(x) for x in x_batch], dtype=object)\n",
        "\n",
        "    def get_weight(self):\n",
        "        return self.quality.estimation if self.quality.total > 0 else 1.0\n",
        "\n",
        "\n",
        "@ray.remote\n",
        "class RemoteTreeGroup(TreeGroup):\n",
        "\n",
        "    def __init__(self, size: int, split_step=0.1, split_wait=100, hb_delta=0.01, tie_thresh=0.05, bag=False, subspaces=False,\n",
        "                 att_split_est=False, log_prob=True, num_atts=0, num_cls=0):\n",
        "        super().__init__(size, split_step, split_wait, hb_delta, tie_thresh, bag, subspaces, att_split_est, log_prob, num_atts, num_cls)\n",
        "\n",
        "\n",
        "class RemoteTreeGroupWrapper:\n",
        "\n",
        "    def __init__(self, *remote_tree_group_args):\n",
        "        self.remote_tree_group = RemoteTreeGroup.remote(*remote_tree_group_args)\n",
        "\n",
        "    def get_weights(self):\n",
        "        return self.remote_tree_group.get_weights.remote()\n",
        "\n",
        "    def predict_prob(self, x_batch):\n",
        "        return self.remote_tree_group.predict_prob.remote(x_batch)\n",
        "\n",
        "    def update_trees(self, x_batch, y_batch, lambda_val, weights):\n",
        "        self.remote_tree_group.update_trees.remote(x_batch, y_batch, lambda_val, weights)\n",
        "\n",
        "    def get_trees(self):\n",
        "        return self.remote_tree_group.get_trees.remote()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "MlG7nscr8jWF"
      },
      "outputs": [],
      "source": [
        "#utils/coll_utils.py /\n",
        "\n",
        "import itertools\n",
        "from functools import reduce\n",
        "from typing import Callable\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class CollectionUtils:\n",
        "\n",
        "    @staticmethod\n",
        "    def ensure_arr_size(arr: np.ndarray, y: int):\n",
        "        if len(arr.shape) == 1:\n",
        "            return np.hstack((arr, np.zeros(y - len(arr) + 1))) if len(arr) - 1 < y else arr\n",
        "        else:\n",
        "            return np.hstack((arr, np.zeros((arr.shape[0], y - arr.shape[1] + 1, arr.shape[2])))) if arr.shape[1] - 1 < y else arr\n",
        "\n",
        "    @staticmethod\n",
        "    def ensure_list2d_size(lst: list, y: int, element_creator: Callable[[], any]):\n",
        "        if len(lst[0]) > y:\n",
        "            return lst\n",
        "\n",
        "        for l in lst:\n",
        "            l_len = len(l) - 1\n",
        "            for _ in range(y - l_len):\n",
        "                l.append(element_creator())\n",
        "\n",
        "        return lst\n",
        "\n",
        "    @staticmethod\n",
        "    def split_list(lst, chunk_size: int):\n",
        "        return [lst[i:i + chunk_size] for i in range(0, len(lst), chunk_size)]\n",
        "\n",
        "    @staticmethod\n",
        "    def flatten_list(lst):\n",
        "        return list(itertools.chain.from_iterable(lst))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DdA4olC--May"
      },
      "outputs": [],
      "source": [
        "# # data_labels.py\n",
        "\n",
        "# import csv\n",
        "\n",
        "# from torch.utils.data import Dataset\n",
        "\n",
        "# #import data.data_collection as data_col\n",
        "\n",
        "\n",
        "# class DataLabelsUtils:\n",
        "\n",
        "#     @staticmethod\n",
        "#     def get_dataset_labels(dataset: Dataset):\n",
        "#         return dataset.classes if hasattr(dataset, 'classes') else None\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "# cls_names = {\n",
        "#     'FASHION': lambda: ['T-shirt/top', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot'],\n",
        "#     'CIFAR10': lambda: DataLabelsUtils.get_dataset_labels(data_collection.get('CIFAR10-TRAIN')),\n",
        "#     'CIFAR20C': lambda: DataLabelsUtils.get_dataset_labels(data_collection.get('CIFAR20C-TRAIN')),\n",
        "#     'CIFAR100': lambda: DataLabelsUtils.get_dataset_labels(data_collection.get('CIFAR100-TRAIN')),\n",
        "    \n",
        "# }\n",
        "\n",
        "\n",
        "# def get_cls_names(name: str):\n",
        "#     return cls_names[name]()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "_Dsx9WiD5Ay9"
      },
      "outputs": [],
      "source": [
        "#stream.py\n",
        "import random\n",
        "from typing import Dict\n",
        "import numpy as np\n",
        "from numpy.random.mtrand import RandomState\n",
        "from torch.utils.data import Dataset, Subset\n",
        "from abc import ABC\n",
        "\n",
        "# from data.data_utils import IndexDataset, DataUtils\n",
        "# from utils.coll_utils import CollectionUtils\n",
        "\n",
        "\n",
        "class Stream(ABC):\n",
        "    def __init__(self, cls_names: list = None):\n",
        "        self.cls_names = cls_names if cls_names is not None else []\n",
        "\n",
        "\n",
        "class InstanceStream(Stream):\n",
        "\n",
        "    def __init__(self, dataset: Dataset, order=None, frac=1.0, shuffle=False, cls_names: list = None, init_frac: float = 0.0):\n",
        "        super().__init__(cls_names)\n",
        "        if order:\n",
        "            data_indices = order\n",
        "        else:\n",
        "            data_indices = list(RandomState(0).permutation(len(dataset))) if shuffle else np.arange(len(dataset))\n",
        "\n",
        "        if frac < 1.0:\n",
        "            indices = random.sample(range(len(data_indices)), int(frac * len(data_indices)))\n",
        "            data_indices = [data_indices[i] for i in sorted(indices)]\n",
        "\n",
        "        init_indices = []\n",
        "        if init_frac > 0.0:\n",
        "            f = int(init_frac * len(data_indices))\n",
        "            init_indices, data_indices = data_indices[:f], data_indices[f:]\n",
        "\n",
        "        self.init_data = Subset(dataset, init_indices)\n",
        "        self.data = Subset(dataset, data_indices)\n",
        "\n",
        "    def get_init_data(self):\n",
        "        return self.init_data\n",
        "\n",
        "    def get_data(self):\n",
        "        return self.data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "class ClassStream(Stream):\n",
        "\n",
        "    def __init__(self, train_dataset: Dataset, test_dataset: Dataset=None, class_size: int=1, class_frac: float=1.0,\n",
        "                 class_batch_seq: list=None, test_frac: float=0.2, max_cls_num=-1, cls_names: list=None, init_data: Dict=None):\n",
        "        super().__init__(cls_names)\n",
        "\n",
        "        if not test_dataset:\n",
        "            indices = list(RandomState(0).permutation(len(train_dataset)))\n",
        "            f = int(test_frac * len(indices))\n",
        "            test_dataset = Subset(train_dataset, indices[:f])\n",
        "            train_dataset = Subset(train_dataset, indices[f:])\n",
        "\n",
        "        train_class_batch = self.create_class_batches(train_dataset, class_size, class_batch_seq, max_cls_num)\n",
        "\n",
        "        init_indices, init_class_concept_mapping = [], {}\n",
        "        cf = class_frac\n",
        "        random.seed(0)\n",
        "\n",
        "        if init_data is not None:\n",
        "            for class_batch_idx, frac in init_data.items():\n",
        "                class_idx, class_batch_indices, class_concept_mapping = train_class_batch[class_batch_idx]\n",
        "\n",
        "                f = int(frac * len(class_batch_indices))\n",
        "                train_class_batch[class_batch_idx] = (class_idx, class_batch_indices[f:], class_concept_mapping)\n",
        "\n",
        "                init_indices.extend(class_batch_indices[:f])\n",
        "                init_class_concept_mapping.update(class_concept_mapping)\n",
        "\n",
        "        self.init_data = (init_class_concept_mapping, Subset(train_dataset, init_indices if cf == 1.0 else random.sample(init_indices, int(cf * len(init_indices)))))\n",
        "\n",
        "        self.train_data = [(class_idx, Subset(train_dataset, indices if cf == 1.0 else random.sample(indices, int(cf * len(indices)))), class_concept_mapping)\n",
        "                           for class_idx, indices, class_concept_mapping in train_class_batch]\n",
        "\n",
        "        test_class_batch = self.create_class_batches(test_dataset, class_size, class_batch_seq, -1)\n",
        "        self.test_data = [(class_idx, Subset(test_dataset, indices if cf == 1.0 else random.sample(indices, int(cf * len(indices)))), class_concept_mapping)\n",
        "                          for class_idx, indices, class_concept_mapping in test_class_batch]\n",
        "\n",
        "    def get_init_data(self):\n",
        "        return self.init_data\n",
        "\n",
        "    def get_train_data(self):\n",
        "        return self.train_data\n",
        "\n",
        "    def get_test_data(self):\n",
        "        return self.test_data\n",
        "\n",
        "    @staticmethod\n",
        "    def create_class_batches(dataset, class_size, class_batch_seq, max_cls_num):\n",
        "        indices_per_class = DataUtils.get_class_indices(IndexDataset(dataset))\n",
        "\n",
        "        if not class_batch_seq:\n",
        "            input_classes = sorted(list(indices_per_class.keys()))\n",
        "            class_batch_seq = CollectionUtils.split_list(input_classes, class_size)\n",
        "\n",
        "            for i, subclasses in enumerate(class_batch_seq):\n",
        "                class_batch_seq[i] = (i, subclasses, {c: i for c in subclasses})\n",
        "\n",
        "        indices_per_class_batch = [(class_idx, CollectionUtils.flatten_list([indices_per_class[cls] for cls in classes]), concept_mapping)\n",
        "                                   for i, (class_idx, classes, concept_mapping) in enumerate(class_batch_seq)]\n",
        "\n",
        "        if max_cls_num > -1:\n",
        "            for i, b in enumerate(indices_per_class_batch):\n",
        "                indices_per_class_batch[i] = (b[0], b[1][:max_cls_num], b[2])\n",
        "\n",
        "        return indices_per_class_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "KzptPmRx-nm8"
      },
      "outputs": [],
      "source": [
        "# plt_utils.py \n",
        "import matplotlib.pyplot as plt\n",
        "import io\n",
        "import tensorflow as tf\n",
        "import itertools\n",
        "import numpy as np\n",
        "import matplotlib.colors as mcolors\n",
        "\n",
        "\n",
        "class PlotUtils:\n",
        "\n",
        "    @staticmethod\n",
        "    def create_image_grid(images, labels, cls_names):\n",
        "        figure = plt.figure(figsize=(20, 20))\n",
        "        rows, cols = (10, 10) if len(images) == 100 else (5, 5)\n",
        "\n",
        "        for i in range(min(rows * cols, len(images))):\n",
        "            cls_idx = labels[i].item()\n",
        "            plt.subplot(rows, cols, i + 1, title=cls_names[cls_idx] if len(cls_names) > cls_idx else cls_idx)\n",
        "            plt.xticks([])\n",
        "            plt.yticks([])\n",
        "            plt.grid(False)\n",
        "            plt.imshow(images[i])\n",
        "\n",
        "        return figure\n",
        "\n",
        "    @staticmethod\n",
        "    def fig_to_image(figure):\n",
        "        buf = io.BytesIO()\n",
        "        plt.savefig(buf, format='png')\n",
        "        plt.close(figure)\n",
        "\n",
        "        buf.seek(0)\n",
        "        image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
        "        image = tf.expand_dims(image, 0)\n",
        "\n",
        "        return image\n",
        "\n",
        "    @staticmethod\n",
        "    def create_confusion_matrix(cm, class_names, title=None):\n",
        "        figure = plt.figure(figsize=(8, 8))\n",
        "\n",
        "        colors = plt.cm.Blues(np.linspace(0, 1, 128))\n",
        "        cmap = mcolors.LinearSegmentedColormap.from_list('colormap', colors)\n",
        "\n",
        "        plt.imshow(cm, interpolation='nearest', cmap=cmap if len(cm) > 1 else plt.cm.Blues_r)\n",
        "        if title: plt.title(title, fontsize=24, pad=16)\n",
        "\n",
        "        tick_marks = np.arange(len(class_names))\n",
        "        plt.xticks(tick_marks, class_names, rotation=45, fontsize=12)\n",
        "        plt.yticks(tick_marks, class_names, fontsize=12)\n",
        "\n",
        "        labels = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
        "\n",
        "        threshold = cm.max() / 2.\n",
        "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "            color = 'white' if cm[i, j] > threshold else 'black'\n",
        "            plt.text(j, i, labels[i, j], horizontalalignment='center', color=color)\n",
        "\n",
        "        plt.ylabel('True label', fontsize=16, labelpad=20)\n",
        "        plt.xlabel('Predicted label', fontsize=16, labelpad=20)\n",
        "\n",
        "        return figure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "RpySj3iQ-0n_"
      },
      "outputs": [],
      "source": [
        "# tf_writers.py\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import sklearn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "#from utils.plt_utils import PlotUtils as pu\n",
        "\n",
        "\n",
        "class TBScalars:\n",
        "\n",
        "    @staticmethod\n",
        "    def write_epoch_result(tasks_acc, epoch, stream_label, i):\n",
        "        tf.summary.scalar(f'{stream_label}#EPOCHS/C{i}', sum(tasks_acc) / len(tasks_acc), epoch,\n",
        "                          description='x=epochs, y=overall accuracy')\n",
        "        tf.summary.flush()\n",
        "\n",
        "    @staticmethod\n",
        "    def write_tasks_results(stream_label, tasks_acc, i):\n",
        "        for j, acc in enumerate(tasks_acc):\n",
        "            tf.summary.scalar(f'{stream_label}/C{j}', acc, i,\n",
        "                              description='x=class ids, y=accuracy for a given Ci')  # todo: add configurable class-aggregation?\n",
        "\n",
        "        tf.summary.scalar(f'ALL/{stream_label}', sum(tasks_acc) / len(tasks_acc), i,\n",
        "                          description='x=class ids, y=overall accuracy')\n",
        "        tf.summary.flush()\n",
        "\n",
        "\n",
        "class TBImages:\n",
        "\n",
        "    @staticmethod\n",
        "    def write_test_data(data: Dataset, i: int, stream_label: str, cls_names: list):\n",
        "        loader = DataLoader(data, batch_size=100, shuffle=True)\n",
        "\n",
        "        images, labels = next(iter(loader))\n",
        "        images = np.transpose(images.reshape(*images.shape), (0, 2, 3, 1))\n",
        "        figure = PlotUtils.create_image_grid(images, labels, cls_names)\n",
        "\n",
        "        tf.summary.image(f'{stream_label}#EXAMPLES', PlotUtils.fig_to_image(figure), step=i)\n",
        "        tf.summary.flush()\n",
        "\n",
        "    @staticmethod\n",
        "    def write_confusion_matrices(labels, preds, i, stream_label):\n",
        "        cm = sklearn.metrics.confusion_matrix(labels, preds)\n",
        "        cm[np.isnan(cm)] = 0.0\n",
        "\n",
        "        figure = PlotUtils.create_confusion_matrix(cm, class_names=[f'C{k}' for k in range(len(cm))])\n",
        "\n",
        "        tf.summary.image(f'{stream_label}#CONF-MATS', PlotUtils.fig_to_image(figure), step=i)\n",
        "        tf.summary.flush()\n",
        "\n",
        "        return cm\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "9RZ25J_l-_Rz"
      },
      "outputs": [],
      "source": [
        "# eval.py\n",
        "import collections\n",
        "import copy\n",
        "import os\n",
        "\n",
        "import torch\n",
        "from typing import Callable\n",
        "from abc import ABC, abstractmethod\n",
        "from skmultiflow.drift_detection import ADWIN\n",
        "from torch import Tensor\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import torch.utils.tensorboard as tb\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "#from core.clearn import ContinualLearner\n",
        "#from data.stream import Stream, InstanceStream, ClassStream\n",
        "#from eval.tf_writers import TBScalars, TBImages\n",
        "\n",
        "\n",
        "class Evaluator(ABC):\n",
        "\n",
        "    @abstractmethod\n",
        "    def evaluate(self, model_creator: (str, Callable[[], ContinualLearner]), data_creator: (str, Callable[[], Stream])):\n",
        "        pass\n",
        "\n",
        "\n",
        "class InstanceStreamEvaluator(Evaluator):\n",
        "\n",
        "    def __init__(self, batch_size: int, shuffle=False, init_skip_frac=0.05, numpy=False, logdir_root: str='runs'):\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.init_skip_frac = init_skip_frac\n",
        "        self.numpy = numpy\n",
        "        self.logdir_root = logdir_root\n",
        "\n",
        "    def evaluate(self, model_creator: (str, Callable[[], ContinualLearner]), data_creator: (str, Callable[[], Stream])):\n",
        "        model_label, model_creator = model_creator\n",
        "        stream_label, stream_creator = data_creator\n",
        "\n",
        "        print('[1/3] Preparing data')\n",
        "        instance_stream: InstanceStream = stream_creator()\n",
        "        instance_stream_loader = DataLoader(instance_stream.get_data(), batch_size=self.batch_size, shuffle=self.shuffle)\n",
        "\n",
        "        print('[2/3] Preparing model')\n",
        "        model = model_creator()\n",
        "\n",
        "        init_data = instance_stream.get_init_data()\n",
        "        n = len(init_data)\n",
        "        if n > 0:\n",
        "            print(f'Initializing model with {n} instances')\n",
        "            init_data_loader = DataLoader(init_data, batch_size=n, shuffle=self.shuffle)\n",
        "            inputs_batch, labels_batch = next(iter(init_data_loader))\n",
        "            if self.numpy: inputs_batch, labels_batch = inputs_batch.numpy(), labels_batch.numpy()\n",
        "            model.initialize(inputs_batch, labels_batch)\n",
        "\n",
        "        print('[3/3] Preparing metrics')\n",
        "        per_class_acc = {}\n",
        "        acc = ADWIN()\n",
        "        correct = 0.0\n",
        "        all = 0.0\n",
        "        init_skip_num = self.init_skip_frac * len(instance_stream)\n",
        "\n",
        "        logdir = f'{self.logdir_root}/{model_label}'\n",
        "        tb_writer = tb.SummaryWriter(logdir)\n",
        "\n",
        "        print('Evaluating...')\n",
        "        i = 0\n",
        "        for inputs_batch, labels_batch in tqdm(instance_stream_loader):\n",
        "            if self.numpy: inputs_batch, labels_batch = inputs_batch.numpy(), labels_batch.numpy()\n",
        "\n",
        "            i += len(inputs_batch)\n",
        "            preds = model.predict(inputs_batch)\n",
        "            model.update(inputs_batch, labels_batch)\n",
        "\n",
        "            results = [int(int(p) == int(y)) for p, y in zip(preds, labels_batch)]\n",
        "            correct += sum(results)\n",
        "            all += len(inputs_batch)\n",
        "\n",
        "            for r, l in zip(results, labels_batch):\n",
        "                acc.add_element(float(r))\n",
        "                l = int(l)\n",
        "\n",
        "                if l not in per_class_acc:\n",
        "                    per_class_acc[l] = ADWIN()\n",
        "                per_class_acc[l].add_element(float(r))\n",
        "\n",
        "            if i > init_skip_num:\n",
        "                tb_writer.add_scalar(f'ALL/{stream_label}', acc.estimation, i)\n",
        "\n",
        "                for c, c_acc in per_class_acc.items():\n",
        "                    tb_writer.add_scalar(f'{stream_label}/{stream_label}-C{c}', c_acc.estimation, i)\n",
        "\n",
        "\n",
        "class ClassStreamEvaluator(Evaluator):\n",
        "\n",
        "    def __init__(self, batch_size: int, shuffle: bool, num_epochs: int, num_workers: int, numpy=False, vis=True, logdir_root: str='runs'):\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.num_epochs = num_epochs\n",
        "        self.num_workers = num_workers\n",
        "        self.numpy = numpy\n",
        "        self.vis = vis\n",
        "        self.logdir_root = logdir_root\n",
        "\n",
        "    def evaluate(self, model_creator: (str, Callable[[], ContinualLearner]), data_creator: (str, Callable[[], Stream])):\n",
        "        model_label, model_creator = model_creator\n",
        "        stream_label, stream_creator = data_creator\n",
        "\n",
        "        print('[1/3] Preparing data')\n",
        "        class_stream: ClassStream = stream_creator()\n",
        "        train_class_stream = class_stream.get_train_data()\n",
        "        test_class_stream = iter(class_stream.get_test_data())\n",
        "\n",
        "        print('[2/3] Preparing model')\n",
        "        model = model_creator()\n",
        "\n",
        "        init_class_concept_mapping, init_data = class_stream.get_init_data()\n",
        "        n = len(init_data)\n",
        "        if n > 0:\n",
        "            print(f'Initializing model with {n} instances')\n",
        "            init_data_loader = DataLoader(init_data, batch_size=n, num_workers=self.num_workers, shuffle=self.shuffle)\n",
        "            inputs_batch, labels_batch = next(iter(init_data_loader))\n",
        "            labels_batch = Tensor([init_class_concept_mapping[int(cls.item())] for cls in labels_batch])\n",
        "            if self.numpy: inputs_batch, labels_batch = inputs_batch.numpy(), labels_batch.numpy()\n",
        "            model.initialize(inputs_batch, labels_batch)\n",
        "\n",
        "        print('[3/3] Preparing metrics')\n",
        "        logdir = f'{self.logdir_root}/{model_label}'\n",
        "        tb_file_writer = tf.summary.create_file_writer(logdir)\n",
        "        tb_file_writer.set_as_default()\n",
        "        classes_test_data = {}\n",
        "        class_test_concept_mapping = {}\n",
        "        results = collections.defaultdict(list)\n",
        "        cms = []\n",
        "\n",
        "        print('Evaluating...')\n",
        "        for i, class_batch_data in enumerate(tqdm(train_class_stream)):\n",
        "            (class_idx, class_batch_train_data, class_concept_mapping) = class_batch_data\n",
        "            (test_class_idx, class_batch_test_data, test_class_concept_mapping) = next(test_class_stream)\n",
        "\n",
        "            assert class_idx == test_class_idx and class_concept_mapping == test_class_concept_mapping\n",
        "            class_test_concept_mapping.update(class_concept_mapping)\n",
        "\n",
        "            classes_test_data[class_idx] = DataLoader(class_batch_test_data, batch_size=self.batch_size, num_workers=self.num_workers)  # todo: subclasses\n",
        "            if self.vis: TBImages.write_test_data(class_batch_test_data, i, stream_label, class_stream.cls_names)\n",
        "\n",
        "            for j in range(self.num_epochs):\n",
        "                train_data_loader = DataLoader(class_batch_train_data, batch_size=self.batch_size, num_workers=self.num_workers, shuffle=self.shuffle)\n",
        "                for inputs_batch, labels_batch in tqdm(train_data_loader):\n",
        "                    labels_batch = Tensor([class_concept_mapping[int(cls.item())] for cls in labels_batch])\n",
        "                    if self.numpy: inputs_batch, labels_batch = inputs_batch.numpy(), labels_batch.numpy()\n",
        "                    model.update(inputs_batch, labels_batch)\n",
        "\n",
        "                # tasks_acc, _ = evaluate_tasks(model, classes_test_data, class_test_concept_mapping, self.numpy)\n",
        "                # TBScalars.write_epoch_result(tasks_acc, j, stream_label, i)\n",
        "\n",
        "            tasks_acc, (task_targets, task_preds) = evaluate_tasks(model, classes_test_data, class_test_concept_mapping, self.numpy)\n",
        "\n",
        "            for k, task_acc in enumerate(tasks_acc): results[k + 1].append(task_acc)\n",
        "            results[0].append(sum(tasks_acc) / len(tasks_acc))\n",
        "\n",
        "            TBScalars.write_tasks_results(stream_label, tasks_acc, i)\n",
        "            cm = TBImages.write_confusion_matrices(task_targets, task_preds, i, stream_label)\n",
        "            if (i + 1) % 10 == 0: cms.append(cm)\n",
        "\n",
        "        write_result_to_file(model_label, stream_label, results, cms)\n",
        "\n",
        "\n",
        "class OfflineClassStreamEvaluator(Evaluator):\n",
        "\n",
        "    def __init__(self, batch_size: int, num_epochs: int, num_workers: int, numpy=False, vis=True, logdir_root: str='runs',\n",
        "                 model_path: str=None):\n",
        "        self.batch_size = batch_size\n",
        "        self.num_epochs = num_epochs\n",
        "        self.num_workers = num_workers\n",
        "        self.numpy = numpy\n",
        "        self.vis = vis\n",
        "        self.logdir_root = logdir_root\n",
        "        self.model_path = model_path\n",
        "\n",
        "    def evaluate(self, model_creator: (str, Callable[[], ContinualLearner]), data_creator: (str, Callable[[], Stream])):\n",
        "        model_label, model_creator = model_creator\n",
        "        stream_label, stream_creator = data_creator\n",
        "        model = None\n",
        "\n",
        "        print('[1/2] Preparing data')\n",
        "        class_stream: ClassStream = stream_creator()\n",
        "        train_class_stream = class_stream.get_train_data()\n",
        "        test_class_stream = iter(class_stream.get_test_data())\n",
        "\n",
        "        print('[2/2] Preparing metrics')\n",
        "        logdir = f'{self.logdir_root}/{model_label}'\n",
        "        tb_file_writer = tf.summary.create_file_writer(logdir)\n",
        "        tb_file_writer.set_as_default()\n",
        "        all_train_data = None\n",
        "        classes_test_data = {}\n",
        "        class_test_concept_mapping = {}\n",
        "        results = collections.defaultdict(list)\n",
        "        cms = []\n",
        "\n",
        "        print('Evaluating...')\n",
        "        for i, class_batch_data in enumerate(tqdm(train_class_stream)):\n",
        "            (class_idx, class_batch_train_data, class_concept_mapping) = class_batch_data\n",
        "            (test_class_idx, class_batch_test_data, test_class_concept_mapping) = next(test_class_stream)\n",
        "\n",
        "            assert class_idx == test_class_idx and class_concept_mapping == test_class_concept_mapping\n",
        "            class_test_concept_mapping.update(class_concept_mapping)\n",
        "\n",
        "            all_train_data = all_train_data + class_batch_train_data if all_train_data is not None else class_batch_train_data\n",
        "            all_train_data_loader = DataLoader(all_train_data, batch_size=self.batch_size, num_workers=self.num_workers,\n",
        "                                               shuffle=True)\n",
        "\n",
        "            classes_test_data[class_idx] = DataLoader(class_batch_test_data, batch_size=self.batch_size, num_workers=self.num_workers,\n",
        "                                             shuffle=True)\n",
        "            if self.vis: TBImages.write_test_data(class_batch_test_data, i, stream_label, class_stream.cls_names)\n",
        "\n",
        "            model = model_creator()\n",
        "\n",
        "            for j in tqdm(range(self.num_epochs)):\n",
        "                for inputs_batch, labels_batch in all_train_data_loader:\n",
        "                    labels_batch = Tensor([class_test_concept_mapping[int(cls.item())] for cls in labels_batch])\n",
        "                    if self.numpy: inputs_batch, labels_batch = inputs_batch.numpy(), labels_batch.numpy()\n",
        "                    model.update(inputs_batch, labels_batch)\n",
        "\n",
        "                if hasattr(model, 'scheduler') and model.scheduler is not None:\n",
        "                    model.scheduler.step()\n",
        "\n",
        "                tasks_acc, _ = evaluate_tasks(model, classes_test_data, class_test_concept_mapping, self.numpy)\n",
        "                TBScalars.write_epoch_result(tasks_acc, j, stream_label, i)\n",
        "\n",
        "            tasks_acc, (task_targets, task_preds) = evaluate_tasks(model, classes_test_data, class_test_concept_mapping, self.numpy)\n",
        "\n",
        "            for k, task_acc in enumerate(tasks_acc): results[k + 1].append(task_acc)\n",
        "            results[0].append(sum(tasks_acc) / len(tasks_acc))\n",
        "\n",
        "            TBScalars.write_tasks_results(stream_label, tasks_acc, i)\n",
        "            cm = TBImages.write_confusion_matrices(task_targets, task_preds, i, stream_label)\n",
        "            if (i + 1) % 10 == 0: cms.append(cm)\n",
        "\n",
        "        write_result_to_file(model_label, stream_label, results, cms)\n",
        "\n",
        "        if self.model_path:\n",
        "            print(f'Saving model: {self.model_path}')\n",
        "            torch.save(model.get_net().state_dict(), self.model_path)\n",
        "\n",
        "\n",
        "def evaluate_tasks(model: ContinualLearner, classes_test_data, class_test_concept_mapping, numpy):\n",
        "    classes_acc, class_targets, class_preds = [], [], []\n",
        "\n",
        "    for j, class_test_data in classes_test_data.items():\n",
        "        correct, all = 0.0, 0.0\n",
        "\n",
        "        for inputs_batch, labels_batch in class_test_data:\n",
        "            labels_batch = Tensor([class_test_concept_mapping[int(cls.item())] for cls in labels_batch.long()])\n",
        "            if numpy: inputs_batch, labels_batch = inputs_batch.numpy(), labels_batch.numpy()\n",
        "\n",
        "            preds_batch = model.predict(inputs_batch)\n",
        "            results = [p == y for p, y in zip(preds_batch, labels_batch)]\n",
        "            correct += sum(results)\n",
        "            all += len(inputs_batch)\n",
        "\n",
        "            class_targets += list(labels_batch)\n",
        "            class_preds += list(preds_batch)\n",
        "\n",
        "        acc = correct / all\n",
        "        classes_acc.append(acc)  # todo: add per subclass\n",
        "\n",
        "    return classes_acc, (class_targets, class_preds)\n",
        "\n",
        "\n",
        "def write_result_to_file(model_label, stream_label, results, cms):\n",
        "    os.makedirs('results', exist_ok=True)\n",
        "    path = f'results/{model_label}#{stream_label}.csv'\n",
        "    print('Writing results to file ', path)\n",
        "\n",
        "    num_tasks = len(results[0])\n",
        "\n",
        "    f = open(path, 'w')\n",
        "    for task_id, values in results.items():\n",
        "        ext = [0.0] * (num_tasks - len(values))\n",
        "        values = ext + values\n",
        "        values = [str(f.item() if torch.is_tensor(f) else str(f)) for f in values]\n",
        "        vals = ','.join(values)\n",
        "        f.write(f'{task_id},{vals}\\n')\n",
        "    f.close()\n",
        "\n",
        "    path = f'results/{model_label}#{stream_label}_cms.npy'\n",
        "    print(f'Writing {len(cms)} confusion matrices to file ', path)\n",
        "    np.save(path, np.array(cms, dtype=object))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "VD_tR6Cr_NA1"
      },
      "outputs": [],
      "source": [
        "#experiment.py\n",
        "\n",
        "# from core.clearn import ContinualLearner\n",
        "# from data.stream import Stream\n",
        "# from eval.eval import Evaluator\n",
        "\n",
        "import itertools\n",
        "from abc import ABC, abstractmethod\n",
        "from typing import List, Dict, Callable\n",
        "\n",
        "\n",
        "class Experiment(ABC):\n",
        "\n",
        "    def __init__(self):\n",
        "        self.algorithms: Dict[str, Callable[[], ContinualLearner]] = {}\n",
        "        self.streams: Dict[str, Callable[[], Stream]] = {}\n",
        "        self.evaluators: Dict[str, Callable[[], Evaluator]] = {}\n",
        "\n",
        "    def run(self, algorithms: List[str] = None, streams: List[str] = None, evaluators: List[str] = None):\n",
        "        self.prepare()\n",
        "        algorithms = self.algorithms.keys() if not algorithms else algorithms\n",
        "        streams = self.streams.keys() if not streams else streams\n",
        "        evaluators = self.evaluators.keys() if not evaluators else evaluators\n",
        "\n",
        "        for a, s, e, in itertools.product(algorithms, streams, evaluators):\n",
        "            print(f'Running for: {a}, {s}, {e}')\n",
        "            self.evaluators[e]().evaluate((a, self.algorithms[a]), (s, self.streams[s]))\n",
        "\n",
        "    def add_algorithm_creator(self, label: str, algorithm: Callable[[], ContinualLearner]):\n",
        "        self.algorithms[label] = algorithm\n",
        "\n",
        "    def add_data_creator(self, label: str, stream: Callable[[], Stream]):\n",
        "        self.streams[label] = stream\n",
        "\n",
        "    def add_evaluator_creator(self, label: str, evaluator: Callable[[], Evaluator]):\n",
        "        self.evaluators[label] = evaluator\n",
        "\n",
        "    @abstractmethod\n",
        "    def prepare(self):\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "LMkh4DD__RbQ"
      },
      "outputs": [],
      "source": [
        "class RiverWrapper(ContinualLearner):\n",
        "    \n",
        "    def __init__(self, classifier: Classifier):\n",
        "        super().__init__()\n",
        "        self.classifier = classifier\n",
        "\n",
        "    def predict(self, x_batch):\n",
        "        preds = np.zeros(len(x_batch))\n",
        "\n",
        "        for i, x in enumerate(x_batch):\n",
        "            xd = {k: x[k] for k in range(len(x))}\n",
        "            preds[i] = self.classifier.predict_one(xd)\n",
        "\n",
        "        return preds\n",
        "\n",
        "    def predict_prob(self, x_batch):\n",
        "        pass\n",
        "\n",
        "    def update(self, x_batch, y_batch, **kwargs):\n",
        "        weights = kwargs.get('weights', np.ones(len(y_batch)))\n",
        "        y_batch = y_batch.astype(int) if isinstance(y_batch, np.ndarray) else y_batch.int()\n",
        "\n",
        "        for x, y, w in zip(x_batch, y_batch, weights):\n",
        "            xd = {k: x[k] for k in range(len(x))}\n",
        "            self.classifier.learn_one(xd, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qmRrtMfr_bui",
        "outputId": "6d3ac99d-e2a3-4bb6-c962-bd29245cc02c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "fhtV8E2Y_Y4J"
      },
      "outputs": [],
      "source": [
        "result = '/content/drive/MyDrive/pth files/ll_dt_tree'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6uB1AcjAgoS"
      },
      "source": [
        "lldt_runner.py "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "ZJHYF1mTuk_Y"
      },
      "outputs": [],
      "source": [
        "import multiprocessing\n",
        "import os\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "from skmultiflow.trees import HoeffdingTreeClassifier\n",
        "from river.ensemble import AdaptiveRandomForestClassifier\n",
        "from river.tree import HoeffdingTreeClassifier\n",
        "from river.multiclass.ovr import OneVsRestClassifier\n",
        "\n",
        "# import data.data_collection as data_col\n",
        "# from data.stream import ClassStream\n",
        "# from eval.eval import ClassStreamEvaluator\n",
        "# from eval.experiment import Experiment\n",
        "# from learners.ht import HoeffdingTree\n",
        "# from learners.irf import IncrementalRandomForest\n",
        "# from utils.cls_utils import RiverWrapper\n",
        "import ray\n",
        "\n",
        "\n",
        "# num_cores = multiprocessing.cpu_count()\n",
        "# ray.init(num_cpus=num_cores, ignore_reinit_error=True)\n",
        "\n",
        "\n",
        "class ExperimentLifelongTree(Experiment):\n",
        "    def prepare(self):\n",
        "        logdir_root = result\n",
        "\n",
        "        self.add_algorithm_creator('HT', lambda: HoeffdingTree(att_split_est=False))\n",
        "        # self.add_algorithm_creator('HT-s10', lambda: HoeffdingTree(att_split_est=False, split_wait=10))\n",
        "        # self.add_algorithm_creator('HT-ae', lambda: HoeffdingTree(att_split_est=True, log_prob=True))\n",
        "        # self.add_algorithm_creator('HT-ae-s10', lambda: HoeffdingTree(att_split_est=True, split_wait=10, log_prob=True))\n",
        "\n",
        "        self.add_algorithm_creator('IRF40', lambda: IncrementalRandomForest(size=40, num_workers=10, att_split_est=False))\n",
        "        # self.add_algorithm_creator('IRF40-s10', lambda: IncrementalRandomForest(size=40, split_wait=10, num_workers=10, att_split_est=False))\n",
        "        # self.add_algorithm_creator('IRF40-ae', lambda: IncrementalRandomForest(size=40, num_workers=10, att_split_est=True))\n",
        "        # self.add_algorithm_creator('IRF40-ae-s10', lambda: IncrementalRandomForest(size=40, split_wait=10, num_workers=10, att_split_est=True))\n",
        "\n",
        "        # self.add_algorithm_creator('ARF40', lambda: RiverWrapper(AdaptiveRandomForestClassifier(split_confidence=0.01, n_models=40)))\n",
        "        # self.add_algorithm_creator('BAG40', lambda: IncrementalRandomForest(size=40, num_workers=10, att_split_est=False, rnd=False, subspaces=False))\n",
        "        # self.add_algorithm_creator('RSP40', lambda: IncrementalRandomForest(size=40, num_workers=10, att_split_est=False, rnd=False, subspaces=True))\n",
        "        # self.add_algorithm_creator('OVR', lambda: RiverWrapper(OneVsRestClassifier(HoeffdingTreeClassifier(split_confidence=0.01))))\n",
        "\n",
        "        # self.add_data_creator('MNIST-CI-FLAT',\n",
        "        #                       lambda: ClassStream(data_collection.get('MNIST-TRAIN-FLAT'), data_collection.get('MNIST-TEST-FLAT'), class_size=1))\n",
        "        # self.add_data_creator('FASHION-CI-FLAT',\n",
        "        #                       lambda: ClassStream(data_collection.get('FASHION-TRAIN-FLAT'), data_collection.get('FASHION-TEST-FLAT'), class_size=1))\n",
        "        self.add_data_creator('SVHN-TENSOR-CI',\n",
        "                              lambda: ClassStream(data_collection.get('SVHN-TRAIN-TENSOR'), data_collection.get('SVHN-TEST-TENSOR'), class_size=1, max_cls_num=4658))\n",
        "        # self.add_data_creator('CIFAR20C-TENSOR-CI',\n",
        "        #                       lambda: ClassStream(data_collection.get('CIFAR20C-TRAIN-TENSOR'), data_collection.get('CIFAR20C-TEST-TENSOR'), class_size=1))\n",
        "        # self.add_data_creator('IMAGENET20A-TENSOR-CI',\n",
        "        #                       lambda: ClassStream(data_collection.get('IMAGENET20A-TRAIN-TENSOR'), data_collection.get('IMAGENET20A-TEST-TENSOR'), class_size=1))\n",
        "        # self.add_data_creator('IMAGENET20B-TENSOR-CI',\n",
        "        #                       lambda: ClassStream(data_collection.get('IMAGENET20B-TRAIN-TENSOR'), data_collection.get('IMAGENET20B-TEST-TENSOR'), class_size=1))\n",
        "\n",
        "        self.add_evaluator_creator('IncEval-shallow', lambda: ClassStreamEvaluator(batch_size=256, shuffle=True, num_epochs=1, num_workers=8,\n",
        "                                                               logdir_root=logdir_root, numpy=True, vis=False))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "f-4un-b3KdiU",
        "outputId": "13153451-d60e-42ff-b6cc-420696bb8e17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running for: HT, SVHN-TENSOR-CI, IncEval-shallow\n",
            "[1/3] Preparing data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2/3] Preparing model\n",
            "[3/3] Preparing metrics\n",
            "Evaluating...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0%|          | 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "  5%|▌         | 1/19 [00:04<01:13,  4.09s/it]\u001b[A\n",
            " 11%|█         | 2/19 [00:07<01:05,  3.83s/it]\u001b[A\n",
            " 16%|█▌        | 3/19 [00:11<00:58,  3.65s/it]\u001b[A\n",
            " 21%|██        | 4/19 [00:15<00:56,  3.75s/it]\u001b[A\n",
            " 26%|██▋       | 5/19 [00:18<00:50,  3.62s/it]\u001b[A\n",
            " 32%|███▏      | 6/19 [00:22<00:47,  3.63s/it]\u001b[A\n",
            " 37%|███▋      | 7/19 [00:26<00:44,  3.74s/it]\u001b[A\n",
            " 42%|████▏     | 8/19 [00:30<00:41,  3.80s/it]\u001b[A\n",
            " 47%|████▋     | 9/19 [00:33<00:37,  3.76s/it]\u001b[A\n",
            " 53%|█████▎    | 10/19 [00:37<00:33,  3.73s/it]\u001b[A\n",
            " 58%|█████▊    | 11/19 [00:40<00:28,  3.62s/it]\u001b[A\n",
            " 63%|██████▎   | 12/19 [00:44<00:25,  3.69s/it]\u001b[A\n",
            " 68%|██████▊   | 13/19 [00:47<00:21,  3.58s/it]\u001b[A\n",
            " 74%|███████▎  | 14/19 [00:51<00:18,  3.65s/it]\u001b[A\n",
            " 79%|███████▉  | 15/19 [00:55<00:14,  3.56s/it]\u001b[A\n",
            " 84%|████████▍ | 16/19 [00:58<00:10,  3.49s/it]\u001b[A\n",
            " 89%|████████▉ | 17/19 [01:02<00:07,  3.60s/it]\u001b[A\n",
            " 95%|█████████▍| 18/19 [01:05<00:03,  3.55s/it]\u001b[A\n",
            "100%|██████████| 19/19 [01:06<00:00,  3.50s/it]\n",
            " 10%|█         | 1/10 [01:07<10:08, 67.62s/it]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0%|          | 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "  5%|▌         | 1/19 [00:05<01:30,  5.04s/it]\u001b[A\n",
            " 11%|█         | 2/19 [00:10<01:25,  5.02s/it]\u001b[A\n",
            " 16%|█▌        | 3/19 [00:14<01:17,  4.82s/it]\u001b[A\n",
            " 21%|██        | 4/19 [00:18<01:09,  4.63s/it]\u001b[A\n",
            " 26%|██▋       | 5/19 [00:23<01:04,  4.59s/it]\u001b[A\n",
            " 32%|███▏      | 6/19 [00:28<01:00,  4.66s/it]\u001b[A\n",
            " 37%|███▋      | 7/19 [00:32<00:53,  4.44s/it]\u001b[A\n",
            " 42%|████▏     | 8/19 [00:36<00:49,  4.49s/it]\u001b[A\n",
            " 47%|████▋     | 9/19 [00:41<00:45,  4.51s/it]\u001b[A\n",
            " 53%|█████▎    | 10/19 [00:45<00:40,  4.49s/it]\u001b[A\n",
            " 58%|█████▊    | 11/19 [00:50<00:35,  4.39s/it]\u001b[A\n",
            " 63%|██████▎   | 12/19 [00:54<00:30,  4.31s/it]\u001b[A\n",
            " 68%|██████▊   | 13/19 [00:58<00:26,  4.46s/it]\u001b[A\n",
            " 74%|███████▎  | 14/19 [01:03<00:22,  4.44s/it]\u001b[A\n",
            " 79%|███████▉  | 15/19 [01:07<00:17,  4.43s/it]\u001b[A\n",
            " 84%|████████▍ | 16/19 [01:12<00:13,  4.66s/it]\u001b[A\n",
            " 89%|████████▉ | 17/19 [01:17<00:09,  4.56s/it]\u001b[A\n",
            " 95%|█████████▍| 18/19 [01:21<00:04,  4.33s/it]\u001b[A\n",
            "100%|██████████| 19/19 [01:22<00:00,  4.33s/it]\n",
            " 20%|██        | 2/10 [02:48<11:37, 87.21s/it]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0%|          | 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "  5%|▌         | 1/19 [00:06<01:55,  6.43s/it]\u001b[A\n",
            " 11%|█         | 2/19 [00:12<01:42,  6.00s/it]\u001b[A\n",
            " 16%|█▌        | 3/19 [00:16<01:27,  5.44s/it]\u001b[A\n",
            " 21%|██        | 4/19 [00:22<01:21,  5.42s/it]\u001b[A\n",
            " 26%|██▋       | 5/19 [00:27<01:15,  5.42s/it]\u001b[A\n",
            " 32%|███▏      | 6/19 [00:33<01:10,  5.40s/it]\u001b[A\n",
            " 37%|███▋      | 7/19 [00:38<01:06,  5.54s/it]\u001b[A\n",
            " 42%|████▏     | 8/19 [00:44<00:59,  5.40s/it]\u001b[A\n",
            " 47%|████▋     | 9/19 [00:49<00:55,  5.51s/it]\u001b[A\n",
            " 53%|█████▎    | 10/19 [00:54<00:48,  5.39s/it]\u001b[A\n",
            " 58%|█████▊    | 11/19 [00:59<00:42,  5.26s/it]\u001b[A\n",
            " 63%|██████▎   | 12/19 [01:05<00:37,  5.33s/it]\u001b[A\n",
            " 68%|██████▊   | 13/19 [01:10<00:31,  5.28s/it]\u001b[A\n",
            " 74%|███████▎  | 14/19 [01:16<00:27,  5.42s/it]\u001b[A\n",
            " 79%|███████▉  | 15/19 [01:21<00:21,  5.45s/it]\u001b[A\n",
            " 84%|████████▍ | 16/19 [01:27<00:16,  5.54s/it]\u001b[A\n",
            " 89%|████████▉ | 17/19 [01:32<00:10,  5.36s/it]\u001b[A\n",
            " 95%|█████████▍| 18/19 [01:37<00:05,  5.25s/it]\u001b[A\n",
            "100%|██████████| 19/19 [01:38<00:00,  5.19s/it]\n",
            " 30%|███       | 3/10 [05:16<13:26, 115.16s/it]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0%|          | 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "  5%|▌         | 1/19 [00:05<01:45,  5.88s/it]\u001b[A\n",
            " 11%|█         | 2/19 [00:12<01:46,  6.24s/it]\u001b[A\n",
            " 16%|█▌        | 3/19 [00:18<01:38,  6.17s/it]\u001b[A\n",
            " 21%|██        | 4/19 [00:24<01:32,  6.19s/it]\u001b[A\n",
            " 26%|██▋       | 5/19 [00:30<01:25,  6.14s/it]\u001b[A\n",
            " 32%|███▏      | 6/19 [00:37<01:23,  6.40s/it]\u001b[A\n",
            " 37%|███▋      | 7/19 [00:43<01:13,  6.14s/it]\u001b[A\n",
            " 42%|████▏     | 8/19 [00:50<01:10,  6.36s/it]\u001b[A\n",
            " 47%|████▋     | 9/19 [00:56<01:02,  6.24s/it]\u001b[A\n",
            " 53%|█████▎    | 10/19 [01:01<00:54,  6.06s/it]\u001b[A\n",
            " 58%|█████▊    | 11/19 [01:07<00:48,  6.07s/it]\u001b[A\n",
            " 63%|██████▎   | 12/19 [01:13<00:42,  6.03s/it]\u001b[A\n",
            " 68%|██████▊   | 13/19 [01:19<00:36,  6.01s/it]\u001b[A\n",
            " 74%|███████▎  | 14/19 [01:25<00:29,  5.99s/it]\u001b[A\n",
            " 79%|███████▉  | 15/19 [01:31<00:23,  5.93s/it]\u001b[A\n",
            " 84%|████████▍ | 16/19 [01:37<00:17,  5.91s/it]\u001b[A\n",
            " 89%|████████▉ | 17/19 [01:43<00:11,  5.87s/it]\u001b[A\n",
            " 95%|█████████▍| 18/19 [01:48<00:05,  5.85s/it]\u001b[A\n",
            "100%|██████████| 19/19 [01:50<00:00,  5.79s/it]\n",
            " 40%|████      | 4/10 [09:24<16:44, 167.46s/it]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0%|          | 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "  5%|▌         | 1/19 [00:07<02:19,  7.73s/it]\u001b[A\n",
            " 11%|█         | 2/19 [00:14<02:01,  7.14s/it]\u001b[A\n",
            " 16%|█▌        | 3/19 [00:22<01:57,  7.35s/it]\u001b[A\n",
            " 21%|██        | 4/19 [00:28<01:47,  7.15s/it]\u001b[A\n",
            " 26%|██▋       | 5/19 [00:36<01:39,  7.14s/it]\u001b[A\n",
            " 32%|███▏      | 6/19 [00:42<01:30,  6.95s/it]\u001b[A\n",
            " 37%|███▋      | 7/19 [00:50<01:25,  7.15s/it]\u001b[A\n",
            " 42%|████▏     | 8/19 [00:56<01:15,  6.86s/it]\u001b[A\n",
            " 47%|████▋     | 9/19 [01:03<01:09,  6.96s/it]\u001b[A\n",
            " 53%|█████▎    | 10/19 [01:10<01:02,  6.97s/it]\u001b[A\n",
            " 58%|█████▊    | 11/19 [01:17<00:55,  6.89s/it]\u001b[A\n",
            " 63%|██████▎   | 12/19 [01:23<00:46,  6.66s/it]\u001b[A\n",
            " 68%|██████▊   | 13/19 [01:30<00:40,  6.74s/it]\u001b[A\n",
            " 74%|███████▎  | 14/19 [01:36<00:33,  6.67s/it]\u001b[A\n",
            " 79%|███████▉  | 15/19 [01:43<00:26,  6.60s/it]\u001b[A\n",
            " 84%|████████▍ | 16/19 [01:50<00:20,  6.71s/it]\u001b[A\n",
            " 89%|████████▉ | 17/19 [01:58<00:14,  7.07s/it]\u001b[A\n",
            " 95%|█████████▍| 18/19 [02:04<00:06,  6.99s/it]\u001b[A\n",
            "100%|██████████| 19/19 [02:06<00:00,  6.65s/it]\n",
            " 50%|█████     | 5/10 [15:02<19:04, 228.98s/it]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0%|          | 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "  5%|▌         | 1/19 [00:08<02:30,  8.38s/it]\u001b[A\n",
            " 11%|█         | 2/19 [00:15<02:12,  7.78s/it]\u001b[A\n",
            " 16%|█▌        | 3/19 [00:23<02:04,  7.78s/it]\u001b[A\n",
            " 21%|██        | 4/19 [00:31<01:57,  7.84s/it]\u001b[A\n",
            " 26%|██▋       | 5/19 [00:39<01:48,  7.76s/it]\u001b[A\n",
            " 32%|███▏      | 6/19 [00:47<01:42,  7.88s/it]\u001b[A\n",
            " 37%|███▋      | 7/19 [00:54<01:33,  7.76s/it]\u001b[A\n",
            " 42%|████▏     | 8/19 [01:02<01:26,  7.87s/it]\u001b[A\n",
            " 47%|████▋     | 9/19 [01:10<01:17,  7.75s/it]\u001b[A\n",
            " 53%|█████▎    | 10/19 [01:17<01:08,  7.62s/it]\u001b[A\n",
            " 58%|█████▊    | 11/19 [01:25<01:01,  7.74s/it]\u001b[A\n",
            " 63%|██████▎   | 12/19 [01:34<00:55,  7.95s/it]\u001b[A\n",
            " 68%|██████▊   | 13/19 [01:42<00:48,  8.03s/it]\u001b[A\n",
            " 74%|███████▎  | 14/19 [01:49<00:39,  7.87s/it]\u001b[A\n",
            " 79%|███████▉  | 15/19 [01:57<00:31,  7.87s/it]\u001b[A\n",
            " 84%|████████▍ | 16/19 [02:04<00:22,  7.64s/it]\u001b[A\n",
            " 89%|████████▉ | 17/19 [02:11<00:14,  7.38s/it]\u001b[A\n",
            " 95%|█████████▍| 18/19 [02:19<00:07,  7.43s/it]\u001b[A\n",
            "100%|██████████| 19/19 [02:20<00:00,  7.40s/it]\n",
            " 60%|██████    | 6/10 [22:25<20:06, 301.74s/it]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0%|          | 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "  5%|▌         | 1/19 [00:09<02:50,  9.45s/it]\u001b[A\n",
            " 11%|█         | 2/19 [00:17<02:28,  8.73s/it]\u001b[A\n",
            " 16%|█▌        | 3/19 [00:26<02:17,  8.58s/it]\u001b[A\n",
            " 21%|██        | 4/19 [00:34<02:08,  8.56s/it]\u001b[A\n",
            " 26%|██▋       | 5/19 [00:42<01:57,  8.43s/it]\u001b[A\n",
            " 32%|███▏      | 6/19 [00:52<01:54,  8.81s/it]\u001b[A\n",
            " 37%|███▋      | 7/19 [00:59<01:40,  8.36s/it]\u001b[A\n",
            " 42%|████▏     | 8/19 [01:07<01:29,  8.18s/it]\u001b[A\n",
            " 47%|████▋     | 9/19 [01:15<01:21,  8.14s/it]\u001b[A\n",
            " 53%|█████▎    | 10/19 [01:24<01:15,  8.41s/it]\u001b[A\n",
            " 58%|█████▊    | 11/19 [01:33<01:09,  8.65s/it]\u001b[A\n",
            " 63%|██████▎   | 12/19 [01:43<01:01,  8.81s/it]\u001b[A\n",
            " 68%|██████▊   | 13/19 [01:51<00:52,  8.82s/it]\u001b[A\n",
            " 74%|███████▎  | 14/19 [02:00<00:43,  8.64s/it]\u001b[A\n",
            " 79%|███████▉  | 15/19 [02:08<00:34,  8.60s/it]\u001b[A\n",
            " 84%|████████▍ | 16/19 [02:16<00:25,  8.35s/it]\u001b[A\n",
            " 89%|████████▉ | 17/19 [02:24<00:16,  8.41s/it]\u001b[A\n",
            " 95%|█████████▍| 18/19 [02:33<00:08,  8.33s/it]\u001b[A\n",
            "100%|██████████| 19/19 [02:34<00:00,  8.15s/it]\n",
            " 70%|███████   | 7/10 [31:33<19:06, 382.05s/it]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0%|          | 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "  5%|▌         | 1/19 [00:10<03:16, 10.94s/it]\u001b[A\n",
            " 11%|█         | 2/19 [00:19<02:44,  9.70s/it]\u001b[A\n",
            " 16%|█▌        | 3/19 [00:29<02:35,  9.73s/it]\u001b[A\n",
            " 21%|██        | 4/19 [00:38<02:21,  9.44s/it]\u001b[A\n",
            " 26%|██▋       | 5/19 [00:46<02:05,  8.99s/it]\u001b[A\n",
            " 32%|███▏      | 6/19 [00:55<01:54,  8.84s/it]\u001b[A\n",
            " 37%|███▋      | 7/19 [01:03<01:43,  8.60s/it]\u001b[A\n",
            " 42%|████▏     | 8/19 [01:11<01:33,  8.52s/it]\u001b[A\n",
            " 47%|████▋     | 9/19 [01:20<01:24,  8.50s/it]\u001b[A\n",
            " 53%|█████▎    | 10/19 [01:29<01:17,  8.63s/it]\u001b[A\n",
            " 58%|█████▊    | 11/19 [01:37<01:07,  8.45s/it]\u001b[A\n",
            " 63%|██████▎   | 12/19 [01:45<00:59,  8.46s/it]\u001b[A\n",
            " 68%|██████▊   | 13/19 [01:54<00:51,  8.55s/it]\u001b[A\n",
            " 74%|███████▎  | 14/19 [02:03<00:43,  8.69s/it]\u001b[A\n",
            " 79%|███████▉  | 15/19 [02:12<00:35,  8.76s/it]\u001b[A\n",
            " 84%|████████▍ | 16/19 [02:22<00:27,  9.16s/it]\u001b[A\n",
            " 89%|████████▉ | 17/19 [02:31<00:18,  9.16s/it]\u001b[A\n",
            " 95%|█████████▍| 18/19 [02:40<00:09,  9.05s/it]\u001b[A\n",
            "100%|██████████| 19/19 [02:42<00:00,  8.55s/it]\n",
            " 80%|████████  | 8/10 [42:00<15:20, 460.22s/it]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0%|          | 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "  5%|▌         | 1/19 [00:10<03:08, 10.45s/it]\u001b[A\n",
            " 11%|█         | 2/19 [00:19<02:47,  9.88s/it]\u001b[A\n",
            " 16%|█▌        | 3/19 [00:29<02:37,  9.87s/it]\u001b[A\n",
            " 21%|██        | 4/19 [00:40<02:33, 10.26s/it]\u001b[A\n",
            " 26%|██▋       | 5/19 [00:50<02:20, 10.04s/it]\u001b[A\n",
            " 32%|███▏      | 6/19 [00:59<02:04,  9.59s/it]\u001b[A\n",
            " 37%|███▋      | 7/19 [01:08<01:53,  9.49s/it]\u001b[A\n",
            " 42%|████▏     | 8/19 [01:17<01:44,  9.50s/it]\u001b[A\n",
            " 47%|████▋     | 9/19 [01:27<01:36,  9.64s/it]\u001b[A\n",
            " 53%|█████▎    | 10/19 [01:36<01:24,  9.38s/it]\u001b[A\n",
            " 58%|█████▊    | 11/19 [01:46<01:15,  9.46s/it]\u001b[A\n",
            " 63%|██████▎   | 12/19 [01:55<01:05,  9.43s/it]\u001b[A\n",
            " 68%|██████▊   | 13/19 [02:04<00:56,  9.40s/it]\u001b[A\n",
            " 74%|███████▎  | 14/19 [02:14<00:47,  9.52s/it]\u001b[A\n",
            " 79%|███████▉  | 15/19 [02:24<00:38,  9.64s/it]\u001b[A\n",
            " 84%|████████▍ | 16/19 [02:34<00:29,  9.82s/it]\u001b[A\n",
            " 89%|████████▉ | 17/19 [02:44<00:19,  9.91s/it]\u001b[A\n",
            " 95%|█████████▍| 18/19 [02:54<00:09,  9.75s/it]\u001b[A\n",
            "100%|██████████| 19/19 [02:56<00:00,  9.28s/it]\n",
            " 90%|█████████ | 9/10 [54:55<09:18, 558.68s/it]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0%|          | 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "  5%|▌         | 1/19 [00:11<03:30, 11.70s/it]\u001b[A\n",
            " 11%|█         | 2/19 [00:21<03:03, 10.80s/it]\u001b[A\n",
            " 16%|█▌        | 3/19 [00:32<02:48, 10.56s/it]\u001b[A\n",
            " 21%|██        | 4/19 [00:42<02:34, 10.32s/it]\u001b[A\n",
            " 26%|██▋       | 5/19 [00:52<02:24, 10.33s/it]\u001b[A\n",
            " 32%|███▏      | 6/19 [01:02<02:11, 10.08s/it]\u001b[A\n",
            " 37%|███▋      | 7/19 [01:11<01:58,  9.91s/it]\u001b[A\n",
            " 42%|████▏     | 8/19 [01:22<01:51, 10.10s/it]\u001b[A\n",
            " 47%|████▋     | 9/19 [01:31<01:40, 10.03s/it]\u001b[A\n",
            " 53%|█████▎    | 10/19 [01:42<01:32, 10.25s/it]\u001b[A\n",
            " 58%|█████▊    | 11/19 [01:52<01:22, 10.25s/it]\u001b[A\n",
            " 63%|██████▎   | 12/19 [02:04<01:13, 10.56s/it]\u001b[A\n",
            " 68%|██████▊   | 13/19 [02:14<01:02, 10.42s/it]\u001b[A\n",
            " 74%|███████▎  | 14/19 [02:24<00:52, 10.46s/it]\u001b[A\n",
            " 79%|███████▉  | 15/19 [02:35<00:42, 10.55s/it]\u001b[A\n",
            " 84%|████████▍ | 16/19 [02:46<00:32, 10.70s/it]\u001b[A\n",
            " 89%|████████▉ | 17/19 [02:56<00:21, 10.54s/it]\u001b[A\n",
            " 95%|█████████▍| 18/19 [03:07<00:10, 10.46s/it]\u001b[A\n",
            "100%|██████████| 19/19 [03:09<00:00,  9.96s/it]\n",
            "100%|██████████| 10/10 [1:09:24<00:00, 416.41s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing results to file  results/HT#SVHN-TENSOR-CI.csv\n",
            "Writing 1 confusion matrices to file  results/HT#SVHN-TENSOR-CI_cms.npy\n",
            "Running for: IRF40, SVHN-TENSOR-CI, IncEval-shallow\n",
            "[1/3] Preparing data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2/3] Preparing model\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-6d22bdc06866>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# img_seqs = ['IMAGENET20A-TENSOR-CI', 'IMAGENET20B-TENSOR-CI']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mExperimentLifelongTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malgorithms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'HT'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'IRF40'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstreams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'IncEval-shallow'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m# ExperimentLifelongTree().run(algorithms=['HT-s10', 'IRF40-s10'], streams=img_seqs, evaluators=['IncEval-shallow'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-77a2a463aa1f>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, algorithms, streams, evaluators)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malgorithms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstreams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Running for: {a}, {s}, {e}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstreams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd_algorithm_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mContinualLearner\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-c9ccd0217b41>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, model_creator, data_creator)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[2/3] Preparing model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0minit_class_concept_mapping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_stream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_init_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-42eecc59966e>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# self.add_algorithm_creator('HT-ae-s10', lambda: HoeffdingTree(att_split_est=True, split_wait=10, log_prob=True))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_algorithm_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'IRF40'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIncrementalRandomForest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matt_split_est\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;31m# self.add_algorithm_creator('IRF40-s10', lambda: IncrementalRandomForest(size=40, split_wait=10, num_workers=10, att_split_est=False))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m# self.add_algorithm_creator('IRF40-ae', lambda: IncrementalRandomForest(size=40, num_workers=10, att_split_est=True))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-e4745844baeb>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, size, lambda_val, split_step, split_wait, hb_delta, tie_thresh, rnd, subspaces, att_split_est, log_prob, num_atts, num_cls, num_workers)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_par_groups\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         self.init_tree_groups([0, split_step, split_wait, hb_delta, tie_thresh, rnd, subspaces, att_split_est, log_prob,\n\u001b[0;32m---> 26\u001b[0;31m                                num_atts, num_cls])\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minit_tree_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree_params\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-e4745844baeb>\u001b[0m in \u001b[0;36minit_tree_groups\u001b[0;34m(self, tree_params)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mtree_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrees_per_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_groups\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRemoteTreeGroupWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtree_params\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpar\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mTreeGroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtree_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mtrees_per_group\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-e4745844baeb>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *remote_tree_group_args)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mremote_tree_group_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremote_tree_group\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRemoteTreeGroup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mremote_tree_group_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ray/actor.py\u001b[0m in \u001b[0;36mremote\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    538\u001b[0m             \u001b[0mA\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mnewly\u001b[0m \u001b[0mcreated\u001b[0m \u001b[0mactor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m         \"\"\"\n\u001b[0;32m--> 540\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_remote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m     def options(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ray/util/tracing/tracing_helper.py\u001b[0m in \u001b[0;36m_invocation_actor_class_remote_span\u001b[0;34m(self, args, kwargs, *_args, **_kwargs)\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_tracing_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m\"_ray_trace_ctx\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0m_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0mclass_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__ray_metadata__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ray/actor.py\u001b[0m in \u001b[0;36m_remote\u001b[0;34m(self, args, kwargs, num_cpus, num_gpus, memory, object_store_memory, resources, accelerator_type, max_concurrency, max_restarts, max_task_retries, name, namespace, lifetime, placement_group, placement_group_bundle_index, placement_group_capture_child_tasks, runtime_env, max_pending_calls, scheduling_strategy)\u001b[0m\n\u001b[1;32m    741\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"max_concurrency must be >= 1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 743\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mclient_mode_should_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauto_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    744\u001b[0m             return client_mode_convert_actor(\n\u001b[1;32m    745\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ray/_private/client_mode_hook.py\u001b[0m in \u001b[0;36mclient_mode_should_convert\u001b[0;34m(auto_init)\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         ):\n\u001b[0;32m--> 124\u001b[0;31m             \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;31m# `is_client_mode_enabled_by_default` is used for testing with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ray/_private/client_mode_hook.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"init\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_client_mode_enabled_by_default\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ray/worker.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(address, num_cpus, num_gpus, resources, object_store_memory, local_mode, ignore_reinit_error, include_dashboard, dashboard_host, dashboard_port, job_config, configure_logging, logging_level, logging_format, log_to_driver, namespace, runtime_env, storage, _enable_object_reconstruction, _redis_max_memory, _plasma_directory, _node_ip_address, _driver_object_store_memory, _memory, _redis_password, _temp_dir, _metrics_export_port, _system_config, _tracing_startup_hook, **kwargs)\u001b[0m\n\u001b[1;32m   1021\u001b[0m         \u001b[0;31m# isn't called.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m         _global_node = ray.node.Node(\n\u001b[0;32m-> 1023\u001b[0;31m             \u001b[0mhead\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshutdown_at_exit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspawn_reaper\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mray_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mray_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1024\u001b[0m         )\n\u001b[1;32m   1025\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ray/node.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, ray_params, head, shutdown_at_exit, spawn_reaper, connect_only)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mconnect_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_ray_processes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m             \u001b[0;31m# we should update the address info after the node has been started\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ray/node.py\u001b[0m in \u001b[0;36mstart_ray_processes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         \u001b[0;31m# Make sure we don't call `determine_plasma_store_config` multiple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m         \u001b[0;31m# times to avoid printing multiple warnings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1130\u001b[0;31m         \u001b[0mresource_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_resource_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         (\n\u001b[1;32m   1132\u001b[0m             \u001b[0mplasma_directory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ray/node.py\u001b[0m in \u001b[0;36mget_resource_spec\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    479\u001b[0m                 \u001b[0mresources\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ray_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mredis_max_memory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 481\u001b[0;31m             ).resolve(is_head=self.head, node_ip_address=self.node_ip_address)\n\u001b[0m\u001b[1;32m    482\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resource_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ray/_private/resource_spec.py\u001b[0m in \u001b[0;36mresolve\u001b[0;34m(self, is_head, node_ip_address)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;31m# Choose a default object store size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0msystem_memory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_private\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_system_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0mavail_memory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_private\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimate_available_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mobject_store_memory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject_store_memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ray/_private/utils.py\u001b[0m in \u001b[0;36mget_system_memory\u001b[0;34m()\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemory_limit_filename_v2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemory_limit_filename_v2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m             \u001b[0mdocker_limit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[0;31m# Use psutil if it is available.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'max\\n'"
          ]
        }
      ],
      "source": [
        "\n",
        "# seqs = ['MNIST-CI-FLAT', 'FASHION-CI-FLAT', 'SVHN-TENSOR-CI', 'CIFAR20C-TENSOR-CI']\n",
        "# img_seqs = ['IMAGENET20A-TENSOR-CI', 'IMAGENET20B-TENSOR-CI']\n",
        "seqs = ['SVHN-TENSOR-CI']\n",
        "# img_seqs = ['IMAGENET20A-TENSOR-CI', 'IMAGENET20B-TENSOR-CI']\n",
        "\n",
        "ExperimentLifelongTree().run(algorithms=['HT', 'IRF40'], streams=seqs, evaluators=['IncEval-shallow'])\n",
        "# ExperimentLifelongTree().run(algorithms=['HT-s10', 'IRF40-s10'], streams=img_seqs, evaluators=['IncEval-shallow'])\n",
        "\n",
        "ExperimentLifelongTree().run(algorithms=['HT-ae', 'IRF40-ae'], streams=seqs, evaluators=['IncEval-shallow'])\n",
        "# ExperimentLifelongTree().run(algorithms=['HT-ae-s10', 'IRF40-ae-s10'], streams=img_seqs, evaluators=['IncEval-shallow'])\n",
        "\n",
        "# ExperimentLifelongTree().run(algorithms=['ARF40', 'BAG40', 'RSP40', 'OVR'], streams=seqs + img_seqs, evaluators=['IncEval-shallow'])\n",
        "\n",
        "#/content/drive/MyDrive/pth files/svhn10-2-train.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6bXZPEJ4jWdk"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CYuBKDKLi5o9"
      },
      "outputs": [],
      "source": [
        "#GA\n",
        "import random\n",
        "\n",
        "POPULATION_SIZE = 50\n",
        "\n",
        "# GENES = '1234567890'\n",
        "# TARGET = '321592'\n",
        "GENES = old weight\n",
        "TARGET = new weight\n",
        "\n",
        "class Individual(object):\n",
        "\n",
        "    def __init__(self, chromosome):\n",
        "        self.chromosome = chromosome\n",
        "        self.fitness = self.cal_fitness()\n",
        "\n",
        "    @classmethod\n",
        "    def mutated_genes(self):\n",
        "        global GENES\n",
        "        gene = random.choice(GENES)\n",
        "        return gene\n",
        "\n",
        "    @classmethod\n",
        "    def create_chromosome(self):\n",
        "        global TARGET\n",
        "        chromosome_len = len(TARGET)\n",
        "        return [self.mutated_genes() for _ in range(chromosome_len)]\n",
        "\n",
        "    def mate(self, other_parent):\n",
        "        child_chromosome = []\n",
        "        for gp1, gp2 in zip(self.chromosome, other_parent.chromosome):\n",
        "\n",
        "            prob = random.random()\n",
        "\n",
        "            if prob < 0.25:\n",
        "                child_chromosome.append(gp1)\n",
        "\n",
        "            elif prob < 0.96:\n",
        "                child_chromosome.append(gp2)\n",
        "\n",
        "\n",
        "            else:\n",
        "                child_chromosome.append(self.mutated_genes())\n",
        "\n",
        "        return Individual(child_chromosome)\n",
        "\n",
        "    def cal_fitness(self):\n",
        "        global TARGET\n",
        "        fitness = 0\n",
        "        for i, j in zip(self.chromosome, TARGET):\n",
        "            if i != j:\n",
        "                fitness += 1\n",
        "        return fitness\n",
        "\n",
        "\n",
        "def GA():\n",
        "    global POPULATION_SIZE\n",
        "\n",
        "    generation = 1\n",
        "\n",
        "    found = False\n",
        "    population = []\n",
        "\n",
        "    for i in range(POPULATION_SIZE):\n",
        "        gnome = Individual.create_chromosome()\n",
        "        population.append(Individual(gnome))\n",
        "\n",
        "    while not found:\n",
        "\n",
        "        population = sorted(population, key=lambda x: x.fitness)\n",
        "\n",
        "        if population[0].fitness <= 0:\n",
        "            found = True\n",
        "            break\n",
        "\n",
        "        new_generation = []\n",
        "\n",
        "        s = int((10 * POPULATION_SIZE) / 100)\n",
        "        new_generation.extend(population[:s])\n",
        "\n",
        "        s = int((90 * POPULATION_SIZE) / 100)\n",
        "        for _ in range(s):\n",
        "            parent1 = random.choice(population[:25])  # fittest ratio for next gen\n",
        "            parent2 = random.choice(population[:25])  # take first 50th element from list\n",
        "            child = parent1.mate(parent2)\n",
        "            new_generation.append(child)\n",
        "\n",
        "        population = new_generation\n",
        "\n",
        "        print(\"Generation: {}\\tIntermediate String: {}\\tFitness: {}\". \\\n",
        "              format(generation,\n",
        "                     \"\".join(population[0].chromosome),\n",
        "                     population[0].fitness))\n",
        "\n",
        "        generation += 1\n",
        "\n",
        "    print(\"Generation: {}\\tModified String: {}\\tFitness: {}\". \\\n",
        "          format(generation,\n",
        "                 \"\".join(population[0].chromosome),\n",
        "                 population[0].fitness))\n",
        "\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "#     main()\n",
        "GA()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "LL(2nd try).ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP97Oy6aRV2KN7iCTuwdC/k",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "eb07ac80c1584d5f8dce177777867265": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_92cc0e98c41f41839a31da83b7d3c82b",
              "IPY_MODEL_ccfe7fcb47524079bcfa2bb12f2b20ec",
              "IPY_MODEL_c728a22baf424159875fc35939903bfc"
            ],
            "layout": "IPY_MODEL_dab51c34a87f4430bed1ef675b519653"
          }
        },
        "92cc0e98c41f41839a31da83b7d3c82b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e93465e670b94ea195f3bb53fe3a78bd",
            "placeholder": "​",
            "style": "IPY_MODEL_b2b8199e917e44ceabe3068483a7bf77",
            "value": ""
          }
        },
        "ccfe7fcb47524079bcfa2bb12f2b20ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5470947e4524295aab5c9195939992c",
            "max": 182040794,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2460148f13a849458ed8a3b05cb37c02",
            "value": 182040794
          }
        },
        "c728a22baf424159875fc35939903bfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d88b1077024649b7ad945f38c46c9a04",
            "placeholder": "​",
            "style": "IPY_MODEL_f7132c5d5e244d4e83ba396410fed282",
            "value": " 182041600/? [00:04&lt;00:00, 57387898.79it/s]"
          }
        },
        "dab51c34a87f4430bed1ef675b519653": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e93465e670b94ea195f3bb53fe3a78bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2b8199e917e44ceabe3068483a7bf77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e5470947e4524295aab5c9195939992c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2460148f13a849458ed8a3b05cb37c02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d88b1077024649b7ad945f38c46c9a04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7132c5d5e244d4e83ba396410fed282": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "87af4ba23efb4ec1ac5d453fad24ead6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_915945a9b19c4155bf4c4ae4e9357efc",
              "IPY_MODEL_b156e123cc3d4d7a94cbaa3f84cf4ddd",
              "IPY_MODEL_17cff304bbfe4d368bde6ce2f3d08bd3"
            ],
            "layout": "IPY_MODEL_3b2ee8e30d374c8a8f121b8d8bc0f35b"
          }
        },
        "915945a9b19c4155bf4c4ae4e9357efc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_234a083c01b148bbaa27a0ba5f9f455e",
            "placeholder": "​",
            "style": "IPY_MODEL_e8f22f5170e8473aa214f84444084280",
            "value": ""
          }
        },
        "b156e123cc3d4d7a94cbaa3f84cf4ddd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18f089b2536c463183e5708c23d38aa3",
            "max": 64275384,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_de9b8ace5e9542fe8448aa246c769093",
            "value": 64275384
          }
        },
        "17cff304bbfe4d368bde6ce2f3d08bd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b8a2066269e4b2ea2f6477f16ca8d26",
            "placeholder": "​",
            "style": "IPY_MODEL_a0a3318057e14d20999797927f827a73",
            "value": " 64275456/? [00:04&lt;00:00, 20167627.18it/s]"
          }
        },
        "3b2ee8e30d374c8a8f121b8d8bc0f35b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "234a083c01b148bbaa27a0ba5f9f455e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8f22f5170e8473aa214f84444084280": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18f089b2536c463183e5708c23d38aa3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de9b8ace5e9542fe8448aa246c769093": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2b8a2066269e4b2ea2f6477f16ca8d26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0a3318057e14d20999797927f827a73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}